{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEMlcPASCMkLuoJz9E+XLh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabriziobasso/kaggle/blob/main/congestion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time Series Studies: Tabular Playground Series - Mar 2022\n",
        "\n",
        "[Link](https://www.kaggle.com/competitions/tabular-playground-series-mar-2022/data)\n",
        "\n",
        "Based on the following Notebooks:\n",
        "1. [TFT Model](https://www.kaggle.com/code/abdulravoofshaik/private-lb-top-2-google-s-tft)\n",
        "2. [Competition Winner](https://www.kaggle.com/competitions/tabular-playground-series-mar-2022/discussion/316271)\n",
        "\n",
        "### Dataset Description\n",
        "In this competition, you'll forecast twelve-hours of traffic flow in a major U.S. metropolitan area. Time, space, and directional features give you the chance to model interactions across a network of roadways.\n",
        "\n",
        "\n",
        "Files and Field Descriptions\n",
        "\n",
        "* **train.csv** - the training set, comprising measurements of traffic congestion across 65 roadways from April through September of 1991.\n",
        "  * row_id - a unique identifier for this instance\n",
        "  * time - the 20-minute period in which each measurement was taken\n",
        "  * x - the east-west midpoint coordinate of the roadway\n",
        "  * y - the north-south midpoint coordinate of the roadway\n",
        "  * direction - the direction of travel of the roadway. EB indicates \"eastbound\" travel, for example, while SW indicates a \"southwest\" direction of travel.\n",
        "congestion - congestion levels for the roadway during each hour; the target. The congestion measurements have been normalized to the range 0 to 100.\n",
        "\n",
        "* **test.csv** - the test set; you will make hourly predictions for roadways identified by a coordinate location and a direction of travel on the day of 1991-09-30.\n",
        "* **sample_submission.csv** - a sample submission file in the correct format"
      ],
      "metadata": {
        "id": "WH9iM0pLB4rq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7wvddu4riye"
      },
      "source": [
        "## 1.0 Install Packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NssaJaAQngVv"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install tensorflow-addons\n",
        "#!pip install shap\n",
        "#!pip install eli5\n",
        "#!pip install tf-nightly\n",
        "#!pip install -U scikit-learn==1.2.0\n",
        "#!pip install catboost\n",
        "#!pip install haversine\n",
        "#!pip install umap-learn\n",
        "#!pip install reverse_geocoder\n",
        "#!pip install --upgrade protobuf\n",
        "!pip install colorama\n",
        "!pip install imbalanced-learn\n",
        "!pip install optuna\n",
        "!pip install optuna-integration\n",
        "#!pip install pygam\n",
        "!pip install keras-tuner --upgrade\n",
        "#!pip install pycaret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aEn1w28Dxbh"
      },
      "source": [
        "## **2.0 Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "remwXrYBDxbh",
        "outputId": "c4dc89d3-0d6d-4611-99cf-3519e22f2125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importing started...\n",
            "Done, All the required modules are imported. Time elapsed: 0.012916088104248047 sec\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#importing modules\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import time\n",
        "t = time.time()\n",
        "\n",
        "print('Importing started...')\n",
        "\n",
        "# basic moduele\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "#from scipy import stats\n",
        "from random import randint\n",
        "import random\n",
        "import math\n",
        "import os\n",
        "import gc\n",
        "import pickle\n",
        "from glob import glob\n",
        "from IPython import display as ipd\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from joblib import dump, load\n",
        "import sklearn as sk\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from functools import partial\n",
        "import itertools\n",
        "from itertools import combinations\n",
        "import IPython\n",
        "import IPython.display\n",
        "\n",
        "# visualization moduels\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.patches as mpatches\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "import imblearn\n",
        "\n",
        "# Palette Setup\n",
        "colors = ['#FB5B68','#FFEB48','#2676A1','#FFBDB0',]\n",
        "colormap_0 = mpl.colors.LinearSegmentedColormap.from_list(\"\",colors)\n",
        "palette_1 = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
        "palette_2 = sns.color_palette(\"YlOrBr\", as_cmap=True)\n",
        "palette_3 = sns.light_palette(\"red\", as_cmap=True)\n",
        "palette_4 = sns.color_palette(\"viridis\", as_cmap=True)\n",
        "palette_5 = sns.color_palette(\"rocket\", as_cmap=True)\n",
        "palette_6 = sns.color_palette(\"GnBu\", as_cmap=True)\n",
        "palette_7 = sns.color_palette(\"tab20c\", as_cmap=False)\n",
        "palette_8 = sns.color_palette(\"Set2\", as_cmap=False)\n",
        "\n",
        "palette_custom = ['#fbb4ae','#b3cde3','#ccebc5','#decbe4','#fed9a6','#ffffcc','#e5d8bd','#fddaec','#f2f2f2']\n",
        "palette_9 = sns.color_palette(palette_custom, as_cmap=False)\n",
        "\n",
        "sns.set_style(\"whitegrid\",{\"grid.linestyle\":\"--\", 'grid.linewidth':0.2, 'grid.alpha':0.5})\n",
        "sns.despine(left=True, bottom=True, top=False, right=False)\n",
        "\n",
        "mpl.rcParams['axes.spines.left'] = True\n",
        "mpl.rcParams['axes.spines.right'] = False\n",
        "mpl.rcParams['axes.spines.top'] = False\n",
        "mpl.rcParams['axes.spines.bottom'] = True\n",
        "\n",
        "# Style Import\n",
        "from colorama import Style, Fore\n",
        "red = Style.BRIGHT + Fore.RED\n",
        "blu = Style.BRIGHT + Fore.BLUE\n",
        "mgt = Style.BRIGHT + Fore.MAGENTA\n",
        "gld = Style.BRIGHT + Fore.YELLOW\n",
        "res = Style.RESET_ALL\n",
        "\n",
        "# preprocessing modules\n",
        "from sklearn.model_selection import (train_test_split,\n",
        "                                     KFold,\n",
        "                                     StratifiedKFold,\n",
        "                                     cross_val_score,\n",
        "                                     GroupKFold,\n",
        "                                     GridSearchCV,\n",
        "                                     RepeatedStratifiedKFold)\n",
        "\n",
        "from sklearn.preprocessing import (LabelEncoder,\n",
        "                                   StandardScaler,\n",
        "                                   MinMaxScaler,\n",
        "                                   OrdinalEncoder,\n",
        "                                   RobustScaler,\n",
        "                                   PowerTransformer,\n",
        "                                   OneHotEncoder,\n",
        "                                   LabelEncoder,\n",
        "                                   OrdinalEncoder,\n",
        "                                   PolynomialFeatures)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "\n",
        "# metrics\n",
        "from sklearn.metrics import (mean_squared_error,\n",
        "                             r2_score,\n",
        "                             mean_absolute_error,\n",
        "                             mean_absolute_percentage_error,\n",
        "                             classification_report,\n",
        "                             confusion_matrix,\n",
        "                             ConfusionMatrixDisplay,\n",
        "                             multilabel_confusion_matrix,\n",
        "                             accuracy_score,\n",
        "                             roc_auc_score,\n",
        "                             auc,\n",
        "                             roc_curve,\n",
        "                             log_loss)\n",
        "\n",
        "\n",
        "# modeling algos\n",
        "from sklearn.linear_model import (LogisticRegression,\n",
        "                                  Lasso,\n",
        "                                  ridge_regression,\n",
        "                                  LinearRegression,\n",
        "                                  Ridge,\n",
        "                                  RidgeCV,\n",
        "                                  ElasticNet,\n",
        "                                  BayesianRidge,\n",
        "                                  TweedieRegressor,\n",
        "                                  ARDRegression,\n",
        "                                  PoissonRegressor,\n",
        "                                  GammaRegressor)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "\n",
        "from sklearn.ensemble import (AdaBoostRegressor,\n",
        "                              RandomForestRegressor,\n",
        "                              RandomForestClassifier,\n",
        "                              VotingRegressor,\n",
        "                              GradientBoostingRegressor,\n",
        "                              StackingRegressor,\n",
        "                              HistGradientBoostingClassifier,\n",
        "                              ExtraTreesClassifier)\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Other Models\n",
        "#from pygam import LogisticGAM, s, te\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from lightgbm import (LGBMRegressor,\n",
        "                      LGBMClassifier,\n",
        "                      early_stopping,\n",
        "                      record_evaluation,\n",
        "                      log_evaluation)\n",
        "\n",
        "#import catboost as cat\n",
        "#from catboost import CatBoost, CatBoostRegressor\n",
        "#from catboost import CatBoostClassifier\n",
        "\n",
        "#from catboost.utils import get_roc_curve\n",
        "\n",
        "from lightgbm import early_stopping\n",
        "# check installed version\n",
        "#import pycaret\n",
        "\n",
        "from sklearn.base import clone ## sklearn base models for stacked ensemble model\n",
        "from sklearn.calibration import CalibratedClassifierCV, CalibrationDisplay\n",
        "\n",
        "#Interpretiability of the model\n",
        "#import shap\n",
        "#import eli5\n",
        "#from eli5.sklearn import PermutationImportance\n",
        "\n",
        "\n",
        "## miss\n",
        "from sklearn.pipeline import (make_pipeline,\n",
        "                              Pipeline)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow_addons as tfa\n",
        "from keras.utils import FeatureSpace\n",
        "\n",
        "# Import libraries for Hypertuning\n",
        "import kerastuner as kt\n",
        "from kerastuner.tuners import RandomSearch, GridSearch, BayesianOptimization\n",
        "# Model Tuning tools:\n",
        "import optuna\n",
        "from optuna.integration import TFKerasPruningCallback\n",
        "from optuna.trial import TrialState\n",
        "from optuna.visualization import plot_intermediate_values\n",
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.visualization import plot_param_importances\n",
        "from optuna.visualization import plot_contour\n",
        "\n",
        "SEED = 1984\n",
        "N_SPLITS = 10\n",
        "\n",
        "print('Done, All the required modules are imported. Time elapsed: {} sec'.format(time.time()-t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAB1kcdZDxbi",
        "outputId": "e0853bb5-75e0-4d9e-a93f-c70813a6ddad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHECK VERSIONS:\n",
            "sns: 0.12.2\n",
            "mpl: 3.7.1\n",
            "tensorflow: 2.12.0\n",
            "pandas: 1.5.3\n",
            "numpy: 1.23.5\n",
            "scikit-learn: 1.2.2\n",
            "missingno: 0.5.2\n",
            "Inbalance_Learning: 0.10.1\n",
            "XGBoost: 1.7.6\n"
          ]
        }
      ],
      "source": [
        "# Check Versions:\n",
        "print(\"CHECK VERSIONS:\")\n",
        "print(f\"sns: {sns.__version__}\")\n",
        "print(f\"mpl: {mpl.__version__}\")\n",
        "print(f\"tensorflow: {tf.__version__}\")\n",
        "print(f\"pandas: {pd.__version__}\")\n",
        "print(f\"numpy: {np.__version__}\")\n",
        "print(f\"scikit-learn: {sk.__version__}\")\n",
        "#print(f\"statsmodels: {stm.__version__}\")\n",
        "print(f\"missingno: {msno.__version__}\")\n",
        "#print(f\"TF-addon: {tfa.__version__}\")\n",
        "print(f\"Inbalance_Learning: {imblearn.__version__}\")\n",
        "print(f\"XGBoost: {xgb.__version__}\")\n",
        "#print(f\"CatBoost: {cat.__version__}\")\n",
        "#print(f\"PyCaret: {pycaret.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFAGryGDDxbi"
      },
      "source": [
        "**Settings:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3Yv_lYmRDxbi"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(42)\n",
        "\n",
        "SEED = 42\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    tf.compat.v1.set_random_seed(seed)\n",
        "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "    tf.compat.v1.keras.backend.set_session(sess)\n",
        "\n",
        "seed_everything(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iq6efrlWTWc5"
      },
      "outputs": [],
      "source": [
        "input_seq_length = 48\n",
        "output_seq_length = 24\n",
        "\n",
        "lr = 0.001\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "hidden_size = 32\n",
        "num_gru_layers = 1\n",
        "grad_clip = 1.0\n",
        "scheduled_sampling_decay = 10\n",
        "dropout = 0.25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STsF4sfaDxbj"
      },
      "source": [
        "### **2.1 Connect Drives**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D_HgNN1Dxbj"
      },
      "source": [
        "Verify System:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nucekKRDxbj",
        "outputId": "da67a8c5-7e75-447f-b28b-62b56fd2914c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xwI9dKRDxbj"
      },
      "source": [
        "Connect to Google Drive:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XnZHOmpDDxbj"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Connect to Colab:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcufbAJ7JLTp",
        "outputId": "c7b4d570-a2b9-40f6-e9be-a4ab405f7997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Exercises/Time_Series_Studies/Data/congestion_data already exists\n",
            "/content/drive/MyDrive/Exercises/Time_Series_Studies/Models/congestion_data/TS_Study_0 already exists\n",
            "/content/drive/MyDrive/Exercises/Time_Series_Studies/Models/TS_Study_0/congestion_data/neural_networks/ already exists\n"
          ]
        }
      ],
      "source": [
        "folder_data = \"/content/drive/MyDrive/Exercises/Time_Series_Studies/Data/congestion_data\"\n",
        "folder_train_valid = \"/content/drive/MyDrive/Exercises/Time_Series_Studies/Data/congestion_data/train_valid_data\"\n",
        "models_folders = \"/content/drive/MyDrive/Exercises/Time_Series_Studies/Models/congestion_data/TS_Study_0\"\n",
        "folders_nn = \"/content/drive/MyDrive/Exercises/Time_Series_Studies/Models/TS_Study_0/congestion_data/neural_networks/\"\n",
        "\n",
        "list_directories = [folder_data,folder_train_valid,models_folders,folders_nn]\n",
        "\n",
        "for path in list_directories:\n",
        "  try:\n",
        "      os.mkdir(path)\n",
        "  except OSError as error:\n",
        "      print(f\"{path} already exists\")\n",
        "\n",
        "\n",
        "os.chdir(folder_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZMgLEzYu_9ZY"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('train.csv', index_col=\"row_id\", parse_dates=['time'])\n",
        "df_test = pd.read_csv('test.csv', index_col=\"row_id\", parse_dates=['time'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape,df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8SBuhu3Lj5f",
        "outputId": "edfcfc53-618d-461f-fa57-916720be15e0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((848835, 5), (2340, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nzIhZ-5JLsux"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}