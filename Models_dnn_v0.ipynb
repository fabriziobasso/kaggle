{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4e7b09d4602844f78fbc00d1a72e9b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4da8c405f374a70b1d61288d9b2ca08",
              "IPY_MODEL_0dc12204ae7c41078696860c9b34bba1",
              "IPY_MODEL_d1a2d6e4d1f842358193df9c39b0f179"
            ],
            "layout": "IPY_MODEL_910982c8c76d4a4993158d4c3888b71f"
          }
        },
        "d4da8c405f374a70b1d61288d9b2ca08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91fa00491a4f40549e62cd4f31a7518e",
            "placeholder": "​",
            "style": "IPY_MODEL_fbca1ebdb5a74353b7dad4272dd1350e",
            "value": "Best trial: 2. Best value: 0.887023: 100%"
          }
        },
        "0dc12204ae7c41078696860c9b34bba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b33c49b555604c95a395c4692c10f7cb",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99bb684ea3574eeab76cf08d17501cf6",
            "value": 10
          }
        },
        "d1a2d6e4d1f842358193df9c39b0f179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dad4e08181794591a7acd3498892945c",
            "placeholder": "​",
            "style": "IPY_MODEL_f39717b8199342b0b8e191e91c2ca57b",
            "value": " 10/10 [5:37:31&lt;00:00, 930.39s/it]"
          }
        },
        "910982c8c76d4a4993158d4c3888b71f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91fa00491a4f40549e62cd4f31a7518e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbca1ebdb5a74353b7dad4272dd1350e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b33c49b555604c95a395c4692c10f7cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99bb684ea3574eeab76cf08d17501cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dad4e08181794591a7acd3498892945c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f39717b8199342b0b8e191e91c2ca57b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabriziobasso/kaggle/blob/main/Models_dnn_v0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cleRFSI670J6"
      },
      "source": [
        "# **S4E1 BANK CHURN**\n",
        "\n",
        "##### About Dataset\n",
        "The bank customer churn dataset is a commonly used dataset for predicting customer churn in the banking industry. It contains information on bank customers who either left the bank or continue to be a customer. The dataset includes the following attributes:\n",
        "\n",
        "* Customer ID: A unique identifier for each customer\n",
        "* Surname: The customer's surname or last name\n",
        "* Credit Score: A numerical value representing the customer's credit score\n",
        "* Geography: The country where the customer resides (France, Spain or Germany)\n",
        "* Gender: The customer's gender (Male or Female)\n",
        "* Age: The customer's age.\n",
        "* Tenure: The number of years the customer has been with the bank\n",
        "* Balance: The customer's account balance\n",
        "* NumOfProducts: The number of bank products the customer uses (e.g., savings account, credit card)\n",
        "* HasCrCard: Whether the customer has a credit card (1 = yes, 0 = no)\n",
        "* IsActiveMember: Whether the customer is an active member (1 = yes, 0 = no)\n",
        "* EstimatedSalary: The estimated salary of the customer\n",
        "* Exited: Whether the customer has churned (1 = yes, 0 = no)\n",
        "\n",
        "##### Evaluation\n",
        "Submissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\n",
        "\n",
        "\n",
        "The submitted probabilities for a given row are not required to sum to one because they are rescaled prior to being scored (each row is divided by the row sum). In order to avoid the extremes of the log function, predicted probabilities are replaced with\n",
        ".\n",
        "\n",
        "#### **Files:**\n",
        "* train.csv - the training dataset; Hardness is the continuous target\n",
        "* test.csv - the test dataset; your objective is to predict the value of Hardness\n",
        "* sample_submission.csv - a sample submission file in the correct format\n",
        "* Churn_Modelling.csv - Original Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_tuNI_58oDU"
      },
      "source": [
        "## 1.0 Workbook Set-up and Libraries:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiXajJZIpDRW"
      },
      "source": [
        "#### 1.0 Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4dbXrH095unC"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install tensorflow-addons\n",
        "#!pip install shap\n",
        "#!pip install eli5\n",
        "#!pip install tf-nightly\n",
        "#!pip install -U scikit-learn==1.2.0\n",
        "!pip install catboost\n",
        "#!pip install haversine\n",
        "#!pip install pytorch-forecasting\n",
        "!pip install umap-learn\n",
        "#!pip install reverse_geocoder\n",
        "#!pip install --upgrade protobuf\n",
        "!pip install colorama\n",
        "!pip install imbalanced-learn\n",
        "!pip install optuna\n",
        "!pip install optuna-integration\n",
        "#!pip install pygam\n",
        "!pip install keras-tuner --upgrade\n",
        "#!pip install pycaret\n",
        "#!pip install lightning==2.0.1\n",
        "!pip install keras-nlp\n",
        "#!pip install MiniSom\n",
        "!pip install BorutaShap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "81y_MZuE8zTt",
        "outputId": "8afa2a3c-758f-485d-d631-6395fc3d3a88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importing started...\n",
            "Using TensorFlow backend\n",
            "Done, All the required modules are imported. Time elapsed: 14.343761682510376 sec\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#importing modules\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import time\n",
        "t = time.time()\n",
        "\n",
        "print('Importing started...')\n",
        "\n",
        "# basic moduele\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "#from scipy import stats\n",
        "from random import randint\n",
        "import random\n",
        "import math\n",
        "import os\n",
        "import gc\n",
        "import pickle\n",
        "from glob import glob\n",
        "from IPython import display as ipd\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from joblib import dump, load\n",
        "import sklearn as sk\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from functools import partial\n",
        "import itertools\n",
        "import joblib\n",
        "from itertools import combinations\n",
        "import IPython\n",
        "import statsmodels.api as sm\n",
        "import IPython.display\n",
        "from IPython.display import clear_output\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "# visualization moduels\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib_venn import venn2_unweighted\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "import imblearn\n",
        "import scipy.stats as stats\n",
        "from scipy.special import boxcox, boxcox1p\n",
        "\n",
        "\n",
        "# Palette Setup\n",
        "colors = ['#FB5B68','#FFEB48','#2676A1','#FFBDB0',]\n",
        "colormap_0 = mpl.colors.LinearSegmentedColormap.from_list(\"\",colors)\n",
        "palette_1 = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
        "palette_2 = sns.color_palette(\"YlOrBr\", as_cmap=True)\n",
        "palette_3 = sns.light_palette(\"red\", as_cmap=True)\n",
        "palette_4 = sns.color_palette(\"viridis\", as_cmap=True)\n",
        "palette_5 = sns.color_palette(\"rocket\", as_cmap=True)\n",
        "palette_6 = sns.color_palette(\"GnBu\", as_cmap=True)\n",
        "palette_7 = sns.color_palette(\"tab20c\", as_cmap=False)\n",
        "palette_8 = sns.color_palette(\"Set2\", as_cmap=False)\n",
        "\n",
        "palette_custom = ['#fbb4ae','#b3cde3','#ccebc5','#decbe4','#fed9a6','#ffffcc','#e5d8bd','#fddaec','#f2f2f2']\n",
        "palette_9 = sns.color_palette(palette_custom, as_cmap=False)\n",
        "\n",
        "sns.set_style(\"whitegrid\",{\"grid.linestyle\":\"--\", 'grid.linewidth':0.2, 'grid.alpha':0.5})\n",
        "#sns.set_theme(style=\"ticks\", context=\"notebook\")\n",
        "sns.despine(left=True, bottom=True, top=False, right=False)\n",
        "\n",
        "mpl.rcParams['axes.spines.left'] = True\n",
        "mpl.rcParams['axes.spines.right'] = False\n",
        "mpl.rcParams['axes.spines.top'] = False\n",
        "mpl.rcParams['axes.spines.bottom'] = True\n",
        "\n",
        "# Style Import\n",
        "from colorama import Style, Fore\n",
        "red = Style.BRIGHT + Fore.RED\n",
        "blu = Style.BRIGHT + Fore.BLUE\n",
        "mgt = Style.BRIGHT + Fore.MAGENTA\n",
        "gld = Style.BRIGHT + Fore.YELLOW\n",
        "res = Style.RESET_ALL\n",
        "\n",
        "# preprocessing modules\n",
        "from sklearn.model_selection import (train_test_split,\n",
        "                                     KFold,\n",
        "                                     StratifiedKFold,\n",
        "                                     cross_val_score,\n",
        "                                     GroupKFold,\n",
        "                                     GridSearchCV,\n",
        "                                     RepeatedStratifiedKFold)\n",
        "\n",
        "from sklearn.preprocessing import (LabelEncoder,\n",
        "                                   StandardScaler,\n",
        "                                   MinMaxScaler,\n",
        "                                   OrdinalEncoder,\n",
        "                                   RobustScaler,\n",
        "                                   PowerTransformer,\n",
        "                                   OneHotEncoder,\n",
        "                                   LabelEncoder,\n",
        "                                   OrdinalEncoder,\n",
        "                                   QuantileTransformer,\n",
        "                                   PolynomialFeatures)\n",
        "\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "\n",
        "# metrics\n",
        "from sklearn.metrics import (mean_squared_error,\n",
        "                             r2_score,\n",
        "                             mean_absolute_error,\n",
        "                             mean_absolute_percentage_error,\n",
        "                             classification_report,\n",
        "                             confusion_matrix,\n",
        "                             ConfusionMatrixDisplay,\n",
        "                             multilabel_confusion_matrix,\n",
        "                             accuracy_score,\n",
        "                             roc_auc_score,\n",
        "                             auc,\n",
        "                             roc_curve,\n",
        "                             log_loss)\n",
        "\n",
        "\n",
        "# modeling algos\n",
        "from sklearn.linear_model import (LogisticRegression,\n",
        "                                  Lasso,\n",
        "                                  ridge_regression,\n",
        "                                  LinearRegression,\n",
        "                                  Ridge,\n",
        "                                  RidgeCV,\n",
        "                                  ElasticNet,\n",
        "                                  BayesianRidge,\n",
        "                                  TweedieRegressor,\n",
        "                                  ARDRegression,\n",
        "                                  PoissonRegressor,\n",
        "                                  GammaRegressor)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "\n",
        "from sklearn.ensemble import (AdaBoostRegressor,\n",
        "                              RandomForestRegressor,\n",
        "                              RandomForestClassifier,\n",
        "                              VotingRegressor,\n",
        "                              GradientBoostingRegressor,\n",
        "                              GradientBoostingClassifier,\n",
        "                              StackingRegressor,\n",
        "                              HistGradientBoostingClassifier,\n",
        "                              ExtraTreesClassifier)\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Other Models\n",
        "#from pygam import LogisticGAM, s, te\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from lightgbm import (LGBMRegressor,\n",
        "                      LGBMClassifier,\n",
        "                      early_stopping,\n",
        "                      record_evaluation,\n",
        "                      log_evaluation)\n",
        "\n",
        "#import catboost as cat\n",
        "from catboost import CatBoost, CatBoostRegressor\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "#from catboost.utils import get_roc_curve\n",
        "\n",
        "from lightgbm import early_stopping\n",
        "# check installed version\n",
        "#import pycaret\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#from minisom import MiniSom\n",
        "\n",
        "from sklearn.base import clone ## sklearn base models for stacked ensemble model\n",
        "from sklearn.calibration import CalibratedClassifierCV, CalibrationDisplay\n",
        "\n",
        "#Interpretiability of the model\n",
        "#import shap\n",
        "#import eli5\n",
        "#from eli5.sklearn import PermutationImportance\n",
        "\n",
        "\n",
        "## miss\n",
        "from sklearn.pipeline import (make_pipeline,\n",
        "                              Pipeline)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "# Only the TensorFlow backend supports string inputs.\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "import keras\n",
        "from keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "from keras.utils import FeatureSpace\n",
        "import keras_nlp\n",
        "\n",
        "# Import libraries for Hypertuning\n",
        "import kerastuner as kt\n",
        "from kerastuner.tuners import RandomSearch, GridSearch, BayesianOptimization\n",
        "# Model Tuning tools:\n",
        "import optuna\n",
        "from optuna.integration import TFKerasPruningCallback\n",
        "from optuna.integration import LightGBMPruningCallback, XGBoostPruningCallback\n",
        "from optuna.trial import TrialState\n",
        "from optuna.visualization import plot_intermediate_values\n",
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.visualization import plot_param_importances\n",
        "from optuna.visualization import plot_contour\n",
        "# Feature selection\n",
        "from BorutaShap import BorutaShap\n",
        "%matplotlib inline\n",
        "SEED = 1984\n",
        "N_SPLITS = 10\n",
        "\n",
        "print('Done, All the required modules are imported. Time elapsed: {} sec'.format(time.time()-t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXoRiAxUiOlO",
        "outputId": "2b7ce197-df10-4449-cd26-48a711f4a7e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHECK VERSIONS:\n",
            "sns: 0.13.1\n",
            "mpl: 3.7.1\n",
            "tensorflow: 2.15.0\n",
            "pandas: 1.5.3\n",
            "numpy: 1.23.5\n",
            "scikit-learn: 1.2.2\n",
            "statsmodels: 0.14.1\n",
            "missingno: 0.5.2\n",
            "Inbalance_Learning: 0.10.1\n",
            "XGBoost: 2.0.3\n"
          ]
        }
      ],
      "source": [
        "# Check Versions:\n",
        "print(\"CHECK VERSIONS:\")\n",
        "print(f\"sns: {sns.__version__}\")\n",
        "print(f\"mpl: {mpl.__version__}\")\n",
        "print(f\"tensorflow: {tf.__version__}\")\n",
        "print(f\"pandas: {pd.__version__}\")\n",
        "print(f\"numpy: {np.__version__}\")\n",
        "print(f\"scikit-learn: {sk.__version__}\")\n",
        "print(f\"statsmodels: {sm.__version__}\")\n",
        "print(f\"missingno: {msno.__version__}\")\n",
        "#print(f\"TF-addon: {tfa.__version__}\")\n",
        "print(f\"Inbalance_Learning: {imblearn.__version__}\")\n",
        "print(f\"XGBoost: {xgb.__version__}\")\n",
        "#print(f\"CatBoost: {cat.__version__}\")\n",
        "#print(f\"PyCaret: {pycaret.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "C7dVTxMy_Mxd"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed,\n",
        "                    tensorflow_init=True,\n",
        "                    pytorch_init=True):\n",
        "    \"\"\"\n",
        "    Seeds basic parameters for reproducibility of results\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    if tensorflow_init is True:\n",
        "        tf.random.set_seed(seed)\n",
        "    if pytorch_init is True:\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "seed_everything(42,tensorflow_init=True,pytorch_init=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIHRomd6iXg5"
      },
      "source": [
        "### **1.1 Utility Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umgqGNosjTMi"
      },
      "source": [
        "#### Graph Functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AMxcvC4qiSCK"
      },
      "outputs": [],
      "source": [
        "def summary(df):\n",
        "    print(f'data shape: {df.shape}')\n",
        "    summ = pd.DataFrame(df.dtypes, columns=['data type'])\n",
        "    summ['#missing'] = df.isnull().sum().values\n",
        "    summ['%missing'] = df.isnull().sum().values / len(df)* 100\n",
        "    summ['#unique'] = df.nunique().values\n",
        "    desc = pd.DataFrame(df.describe(include='all').transpose())\n",
        "    summ['min'] = desc['min'].values\n",
        "    summ['max'] = desc['max'].values\n",
        "    summ['median'] = desc['50%'].values\n",
        "    summ['mean'] = desc['mean'].values\n",
        "    return summ\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, labels):\n",
        "    \"\"\"\n",
        "    This function plots:\n",
        "        1. Confusion matrix\n",
        "        2. Precision matrix\n",
        "        3. Recall matrix\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    `y_true`: ground truth (or actual) values\n",
        "    `y_pred`: predicted values\n",
        "    `labels`: integer encoded target values\n",
        "\n",
        "    Returns none.\n",
        "    \"\"\"\n",
        "    cmat = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=labels)\n",
        "    pmat = cmat / cmat.sum(axis=0)\n",
        "    print(\"Column sum of precision matrix: {}\".format(pmat.sum(axis=0)))\n",
        "    rmat = ((cmat.T) / (cmat.sum(axis=1).T)).T\n",
        "    print(\"Row sum of recall matrix:       {}\".format(rmat.sum(axis=1)))\n",
        "\n",
        "    plt.figure(figsize=(15, 3))\n",
        "    plt.subplot(131)\n",
        "    plot_heatmap(matrix=cmat, title='Confusion Matrix', labels=labels)\n",
        "    plt.subplot(132)\n",
        "    plot_heatmap(matrix=pmat, title='Precision Matrix', labels=labels)\n",
        "    plt.subplot(133)\n",
        "    plot_heatmap(matrix=rmat, title='Recall Matrix', labels=labels)\n",
        "    plt.show()\n",
        "\n",
        "def plot_heatmap(matrix, title, labels):\n",
        "    \"\"\"\n",
        "    This function plots the heatmap.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    `matrix`: 2D array\n",
        "    `title`: title\n",
        "    `labels`: integer encoded target values\n",
        "\n",
        "    Returns none.\n",
        "    \"\"\"\n",
        "    sns.heatmap(data=matrix, annot=True, fmt='.2f', linewidths=0.1,\n",
        "                xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel(xlabel='Predicted Class')\n",
        "    plt.ylabel(ylabel='Actual Class')\n",
        "    plt.title(label=title, fontsize=10)\n",
        "\n",
        "def plot_training_session(history):\n",
        "  # Plot training and validation loss scores\n",
        "  # against the number of epochs.\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.plot(history.history['loss'], label='Train')\n",
        "  plt.plot(history.history['val_loss'], label='Validation')\n",
        "  plt.grid(linestyle='--')\n",
        "  plt.ylabel('val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.title('Train-Validation Scores', pad=13)\n",
        "  plt.legend(loc='upper right');\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOo7obahqmNZ"
      },
      "source": [
        "#### NN Functions:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_inputs(inputs, list_categorical_nn, Cat_Feat_Entries, num_dense_exp=False, embedding_dims=8, name=\"enc\"):\n",
        "    encoded_categorical_feature_list = []\n",
        "    numerical_feature_list = []\n",
        "\n",
        "    for counter, feature_name in enumerate(inputs):\n",
        "        if feature_name in list_categorical_nn:\n",
        "\n",
        "          vocabulary = Cat_Feat_Entries[feature_name]\n",
        "\n",
        "          embedding = layers.Embedding(input_dim=vocabulary, output_dim=embedding_dims, name=f\"embedder_{counter}\")\n",
        "          # Convert the index values to embedding representations.\n",
        "          encoded_categorical_feature = embedding(inputs[feature_name])\n",
        "\n",
        "          encoded_categorical_feature_list.append(encoded_categorical_feature)\n",
        "\n",
        "        else:\n",
        "          # Use the numerical features as-is.\n",
        "          numerical_feature = tf.expand_dims(inputs[feature_name], -1) #inputs[feature_name] #tf.expand_dims(inputs[feature_name], -1)\n",
        "\n",
        "          if num_dense_exp:\n",
        "            numerical_feature = layers.Dense(embedding_dims, name=f\"dense_num_{counter}\")(numerical_feature)\n",
        "\n",
        "          numerical_feature_list.append(numerical_feature)\n",
        "\n",
        "    return encoded_categorical_feature_list, numerical_feature_list\n",
        "\n",
        "\n",
        "class dense_residual_block(keras.layers.Layer):\n",
        "    def __init__(self, units, dropout_rate=0.25, activation=\"relu\", kr=0, attention=False, name=\"drb\"):   #tf.keras.regularizers.L2(l2=0.01)\n",
        "        super(dense_residual_block, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "        self.linear_dense = tf.keras.layers.Dense(units, name=f\"lin_dense_0_{name}\")\n",
        "        self.project = tf.keras.layers.Dense(units, name=f\"lin_dense_prj_{name}\")\n",
        "\n",
        "        self.batchnorm_0 = tf.keras.layers.BatchNormalization(name=f\"bn_0_{name}\")\n",
        "        self.batchnorm_1 = tf.keras.layers.BatchNormalization(name=f\"bn_1_{name}\")\n",
        "        self.batchnorm_prj = tf.keras.layers.BatchNormalization(name=f\"bn_prj_{name}\")\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate,name=f\"do_0_{name}\")\n",
        "        self.layer_norm = tf.keras.layers.BatchNormalization(name=f\"bn_2_{name}\") #LayerNormalization()\n",
        "        self.add_layer = tf.keras.layers.Add(name=f\"add_0_{name}\")\n",
        "\n",
        "        self.attention=attention\n",
        "        self.attention_layer = tf.keras.layers.Attention(name=f\"attention_{name}\")\n",
        "\n",
        "        if activation==\"gelu\":\n",
        "          self.activation_0 = tf.keras.activations.gelu\n",
        "          self.activation_1 = tf.keras.activations.gelu\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "        if activation==\"relu\":\n",
        "          self.activation_0 = tf.keras.activations.relu\n",
        "          self.activation_1 = tf.keras.activations.relu\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "        if activation==\"elu\":\n",
        "          self.activation_0 = tf.keras.activations.elu\n",
        "          self.activation_1 = tf.keras.activations.elu\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "        if activation==\"swish\":\n",
        "          self.activation_0 = tf.keras.activations.swish\n",
        "          self.activation_1 = tf.keras.activations.swish\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "        if activation==\"selu\":\n",
        "          self.activation_0 = tf.keras.activations.selu\n",
        "          self.activation_1 = tf.keras.activations.selu\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"lecun_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "        if activation==\"leaky_relu\":\n",
        "          self.activation_0 = tf.keras.layers.LeakyReLU()\n",
        "          self.activation_1 = tf.keras.layers.LeakyReLU()\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "        if activation==\"prelu\":\n",
        "          self.activation_0 = tf.keras.layers.PReLU()\n",
        "          self.activation_1 = tf.keras.layers.PReLU()\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        if self.attention==True:\n",
        "          attention = self.attention_layer([inputs, inputs])\n",
        "        else:\n",
        "          attention = inputs\n",
        "\n",
        "        x = self.dense_0(attention)\n",
        "        x = self.batchnorm_0(x)\n",
        "        x = self.activation_0(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.linear_dense(x)\n",
        "        x = self.batchnorm_1(x)\n",
        "\n",
        "        if attention.shape[-1] != self.units:\n",
        "            inputs = self.project(attention)\n",
        "            inputs = self.batchnorm_prj(inputs)\n",
        "\n",
        "        return self.add_layer([x, inputs])\n",
        "\n",
        "class dense_block(keras.layers.Layer):\n",
        "    def __init__(self, units, dropout_rate=0.25, activation=\"relu\", kr=0, name=\"dense_block\"):   #tf.keras.regularizers.L2(l2=0.01)\n",
        "        super(dense_block, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "        self.linear_dense = tf.keras.layers.Dense(units, name=f\"lin_dense_0_{name}\")\n",
        "        self.project = tf.keras.layers.Dense(units, name=f\"lin_dense_prj_{name}\")\n",
        "\n",
        "        self.batchnorm_0 = tf.keras.layers.BatchNormalization(name=f\"bn_0_{name}\")\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate,name=f\"do_0_{name}\")\n",
        "        self.layer_norm = tf.keras.layers.BatchNormalization(name=f\"bn_2_{name}\") #LayerNormalization()\n",
        "        self.add_layer = tf.keras.layers.Add(name=f\"add_0_{name}\")\n",
        "\n",
        "        if activation==\"gelu\":\n",
        "          self.activation_0 = tf.keras.activations.gelu\n",
        "          self.activation_1 = tf.keras.activations.gelu\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "        if activation==\"relu\":\n",
        "          self.activation_0 = tf.keras.activations.relu\n",
        "          self.activation_1 = tf.keras.activations.relu\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "        if activation==\"elu\":\n",
        "          self.activation_0 = tf.keras.activations.elu\n",
        "          self.activation_1 = tf.keras.activations.elu\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "        if activation==\"swish\":\n",
        "          self.activation_0 = tf.keras.activations.swish\n",
        "          self.activation_1 = tf.keras.activations.swish\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "        if activation==\"selu\":\n",
        "          self.activation_0 = tf.keras.activations.selu\n",
        "          self.activation_1 = tf.keras.activations.selu\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"lecun_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "        if activation==\"leaky_relu\":\n",
        "          self.activation_0 = tf.keras.layers.LeakyReLU()\n",
        "          self.activation_1 = tf.keras.layers.LeakyReLU()\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "        if activation==\"prelu\":\n",
        "          self.activation_0 = tf.keras.layers.PReLU()\n",
        "          self.activation_1 = tf.keras.layers.PReLU()\n",
        "          self.dense_0 = tf.keras.layers.Dense(units, kernel_initializer=\"he_normal\", kernel_regularizer = tf.keras.regularizers.L2(l2=kr), name=f\"dense_0_{name}\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        x = self.dense_0(inputs)\n",
        "        x = self.batchnorm_0(x)\n",
        "        x = self.activation_0(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "nG1bkptZJqxY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STsF4sfaDxbj"
      },
      "source": [
        "### **1.2 Connect Drives**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nucekKRDxbj",
        "outputId": "a51d626b-cb73-4d3e-c1ed-25691426ebd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan 29 10:53:39 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xwI9dKRDxbj"
      },
      "source": [
        "Connect to Google Drive:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XnZHOmpDDxbj"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Connect to Colab:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_vZlWHwDxbj",
        "outputId": "db7efd64-3f89-4f39-cd79-47d7480bd430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S4E1_BankChurn already exists\n",
            "/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S4E1_BankChurn already exists\n",
            "/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S4E1_BankChurn/neural_networks/ already exists\n",
            "/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S4E1_BankChurn/trees_models/ already exists\n"
          ]
        }
      ],
      "source": [
        "folder_data = \"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S4E1_BankChurn\"\n",
        "models_folders = \"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S4E1_BankChurn\"\n",
        "folders_nn = \"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S4E1_BankChurn/neural_networks/\"\n",
        "folders_trees = \"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S4E1_BankChurn/trees_models/\"\n",
        "\n",
        "list_directories = [folder_data,models_folders,folders_nn,folders_trees]\n",
        "\n",
        "for path in list_directories:\n",
        "  try:\n",
        "      os.mkdir(path)\n",
        "  except OSError as error:\n",
        "      print(f\"{path} already exists\")\n",
        "\n",
        "\n",
        "os.chdir(folder_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2knHbDNp-sr"
      },
      "source": [
        "## 2.0 Create Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ipwvuscRjDhm"
      },
      "outputs": [],
      "source": [
        "#train = pd.read_csv('new_train_dnn_small_norm_cat.csv',index_col=0)\n",
        "train = pd.read_csv('new_train_dnn_boruta_norm_cat.csv',index_col=0)\n",
        "#old_train = pd.read_csv(\"Churn_Modelling.csv\")\n",
        "#test = pd.read_csv(\"new_test_dnn_small_norm_cat.csv\",index_col=0)\n",
        "test = pd.read_csv(\"new_test_dnn_boruta_norm_cat.csv\",index_col=0)\n",
        "\n",
        "ensemble = pd.read_csv(\"ensemble_new_data.csv\",index_col=0)\n",
        "\n",
        "duplicate_results_test_df = pd.read_csv(\"known_test_targets.csv\",index_col=0)\n",
        "sample_submission = pd.read_csv('sample_submission.csv',index_col=0)\n",
        "\n",
        "# Drop column id\n",
        "#train.drop('id',axis=1,inplace=True)\n",
        "#test.drop('id',axis=1,inplace=True)\n",
        "#old_train.dropna(inplace=True,axis=0)\n",
        "#old_train.rename({\"RowNumber\":\"id\"},axis=1,inplace=True)\n",
        "#old_train.set_index(\"id\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "7t8nv4Cqtef4",
        "outputId": "4fe20a8a-3af2-45b0-c34d-9ae3fefef3f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN DATA shape: (165034, 44)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Age_Category_enc  bs_nop_enc  act_nop  Surname_tfidf_1  bs_nop_count_label  \\\n",
              "0         -2.069623   -0.924451        1        -0.499230                   0   \n",
              "1         -0.906434   -0.306724        3         0.687939                   0   \n",
              "2         -0.137777   -2.566904        1        -1.449682                   0   \n",
              "\n",
              "   HasCrCard  IsActiveMember  Age_pca_comb  CreditScore_unimp_cluster_WOE  \\\n",
              "0          1               0     -0.555462                              0   \n",
              "1          1               1     -0.555462                              7   \n",
              "2          1               0      0.407442                              0   \n",
              "\n",
              "   Age-NumOfProducts_cat_count  ...  NumOfProducts_cat_count  Balance_Salary  \\\n",
              "0                    -0.953493  ...                    84291        1.833879   \n",
              "1                    -0.953493  ...                    84291        0.051452   \n",
              "2                    -0.308427  ...                    84291        2.028678   \n",
              "\n",
              "   bs_active_enc  act_nop_enc  CreditScore_pca_comb_final  \\\n",
              "0       0.297783    -0.149317                    1.254062   \n",
              "1      -1.890492    -1.151342                   -2.279961   \n",
              "2       0.553561    -0.253912                   -5.440209   \n",
              "\n",
              "   Balance_Range_count  Surname_tfidf_0  HasCrCard_enc  bs_age_enc  Exited  \n",
              "0                89648        -0.912774       0.261683   -0.966387     0.0  \n",
              "1                89648        -0.893908      -0.144951   -1.494328     0.0  \n",
              "2                89648         0.830234      -1.274168   -0.131707     0.0  \n",
              "\n",
              "[3 rows x 44 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf8d6132-1815-4f6a-b524-cf601112d754\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age_Category_enc</th>\n",
              "      <th>bs_nop_enc</th>\n",
              "      <th>act_nop</th>\n",
              "      <th>Surname_tfidf_1</th>\n",
              "      <th>bs_nop_count_label</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>Age_pca_comb</th>\n",
              "      <th>CreditScore_unimp_cluster_WOE</th>\n",
              "      <th>Age-NumOfProducts_cat_count</th>\n",
              "      <th>...</th>\n",
              "      <th>NumOfProducts_cat_count</th>\n",
              "      <th>Balance_Salary</th>\n",
              "      <th>bs_active_enc</th>\n",
              "      <th>act_nop_enc</th>\n",
              "      <th>CreditScore_pca_comb_final</th>\n",
              "      <th>Balance_Range_count</th>\n",
              "      <th>Surname_tfidf_0</th>\n",
              "      <th>HasCrCard_enc</th>\n",
              "      <th>bs_age_enc</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-2.069623</td>\n",
              "      <td>-0.924451</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.499230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.555462</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.953493</td>\n",
              "      <td>...</td>\n",
              "      <td>84291</td>\n",
              "      <td>1.833879</td>\n",
              "      <td>0.297783</td>\n",
              "      <td>-0.149317</td>\n",
              "      <td>1.254062</td>\n",
              "      <td>89648</td>\n",
              "      <td>-0.912774</td>\n",
              "      <td>0.261683</td>\n",
              "      <td>-0.966387</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.906434</td>\n",
              "      <td>-0.306724</td>\n",
              "      <td>3</td>\n",
              "      <td>0.687939</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.555462</td>\n",
              "      <td>7</td>\n",
              "      <td>-0.953493</td>\n",
              "      <td>...</td>\n",
              "      <td>84291</td>\n",
              "      <td>0.051452</td>\n",
              "      <td>-1.890492</td>\n",
              "      <td>-1.151342</td>\n",
              "      <td>-2.279961</td>\n",
              "      <td>89648</td>\n",
              "      <td>-0.893908</td>\n",
              "      <td>-0.144951</td>\n",
              "      <td>-1.494328</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.137777</td>\n",
              "      <td>-2.566904</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.449682</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.407442</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.308427</td>\n",
              "      <td>...</td>\n",
              "      <td>84291</td>\n",
              "      <td>2.028678</td>\n",
              "      <td>0.553561</td>\n",
              "      <td>-0.253912</td>\n",
              "      <td>-5.440209</td>\n",
              "      <td>89648</td>\n",
              "      <td>0.830234</td>\n",
              "      <td>-1.274168</td>\n",
              "      <td>-0.131707</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 44 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf8d6132-1815-4f6a-b524-cf601112d754')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bf8d6132-1815-4f6a-b524-cf601112d754 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bf8d6132-1815-4f6a-b524-cf601112d754');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c78e6124-2a15-4ab8-b14a-a544c039c2ff\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c78e6124-2a15-4ab8-b14a-a544c039c2ff')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c78e6124-2a15-4ab8-b14a-a544c039c2ff button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST DATA: (110023, 43)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Age_Category_enc  bs_nop_enc  act_nop  Surname_tfidf_1  bs_nop_count_label  \\\n",
              "0         -1.279208   -1.236768        3        -0.877196                   0   \n",
              "1          1.059063    1.959783        0         0.036391                   2   \n",
              "2         -0.496432   -0.963318        1         0.036391                   0   \n",
              "\n",
              "   HasCrCard  IsActiveMember  Age_pca_comb  CreditScore_unimp_cluster_WOE  \\\n",
              "0          0               1     -2.131682                              1   \n",
              "1          1               0      0.997920                              0   \n",
              "2          1               0     -0.408805                              7   \n",
              "\n",
              "   Age-NumOfProducts_cat_count  ...  Balance_pca_comb  \\\n",
              "0                    -2.345158  ...          5.199338   \n",
              "1                     1.166919  ...          5.199338   \n",
              "2                    -0.840906  ...          5.199338   \n",
              "\n",
              "   NumOfProducts_cat_count  Balance_Salary  bs_active_enc  act_nop_enc  \\\n",
              "0                    84291        1.187295      -0.945019    -0.748820   \n",
              "1                    77374        0.210348       0.450468     1.351334   \n",
              "2                    84291        0.851665       0.187291    -0.573484   \n",
              "\n",
              "   CreditScore_pca_comb_final  Balance_Range_count  Surname_tfidf_0  \\\n",
              "0                    0.109902                89648         0.432104   \n",
              "1                   -4.404257                89648        -0.235509   \n",
              "2                   -2.099692                89648        -0.235509   \n",
              "\n",
              "   HasCrCard_enc  bs_age_enc  \n",
              "0       0.399311   -1.200575  \n",
              "1      -0.526706    1.171625  \n",
              "2       0.577720   -0.738212  \n",
              "\n",
              "[3 rows x 43 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d651cec3-1b79-4e39-be05-5c327595f128\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age_Category_enc</th>\n",
              "      <th>bs_nop_enc</th>\n",
              "      <th>act_nop</th>\n",
              "      <th>Surname_tfidf_1</th>\n",
              "      <th>bs_nop_count_label</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>Age_pca_comb</th>\n",
              "      <th>CreditScore_unimp_cluster_WOE</th>\n",
              "      <th>Age-NumOfProducts_cat_count</th>\n",
              "      <th>...</th>\n",
              "      <th>Balance_pca_comb</th>\n",
              "      <th>NumOfProducts_cat_count</th>\n",
              "      <th>Balance_Salary</th>\n",
              "      <th>bs_active_enc</th>\n",
              "      <th>act_nop_enc</th>\n",
              "      <th>CreditScore_pca_comb_final</th>\n",
              "      <th>Balance_Range_count</th>\n",
              "      <th>Surname_tfidf_0</th>\n",
              "      <th>HasCrCard_enc</th>\n",
              "      <th>bs_age_enc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.279208</td>\n",
              "      <td>-1.236768</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.877196</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-2.131682</td>\n",
              "      <td>1</td>\n",
              "      <td>-2.345158</td>\n",
              "      <td>...</td>\n",
              "      <td>5.199338</td>\n",
              "      <td>84291</td>\n",
              "      <td>1.187295</td>\n",
              "      <td>-0.945019</td>\n",
              "      <td>-0.748820</td>\n",
              "      <td>0.109902</td>\n",
              "      <td>89648</td>\n",
              "      <td>0.432104</td>\n",
              "      <td>0.399311</td>\n",
              "      <td>-1.200575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.059063</td>\n",
              "      <td>1.959783</td>\n",
              "      <td>0</td>\n",
              "      <td>0.036391</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.997920</td>\n",
              "      <td>0</td>\n",
              "      <td>1.166919</td>\n",
              "      <td>...</td>\n",
              "      <td>5.199338</td>\n",
              "      <td>77374</td>\n",
              "      <td>0.210348</td>\n",
              "      <td>0.450468</td>\n",
              "      <td>1.351334</td>\n",
              "      <td>-4.404257</td>\n",
              "      <td>89648</td>\n",
              "      <td>-0.235509</td>\n",
              "      <td>-0.526706</td>\n",
              "      <td>1.171625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.496432</td>\n",
              "      <td>-0.963318</td>\n",
              "      <td>1</td>\n",
              "      <td>0.036391</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.408805</td>\n",
              "      <td>7</td>\n",
              "      <td>-0.840906</td>\n",
              "      <td>...</td>\n",
              "      <td>5.199338</td>\n",
              "      <td>84291</td>\n",
              "      <td>0.851665</td>\n",
              "      <td>0.187291</td>\n",
              "      <td>-0.573484</td>\n",
              "      <td>-2.099692</td>\n",
              "      <td>89648</td>\n",
              "      <td>-0.235509</td>\n",
              "      <td>0.577720</td>\n",
              "      <td>-0.738212</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 43 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d651cec3-1b79-4e39-be05-5c327595f128')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d651cec3-1b79-4e39-be05-5c327595f128 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d651cec3-1b79-4e39-be05-5c327595f128');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6fb695ad-d02b-4ff3-9358-a4a2e644f394\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6fb695ad-d02b-4ff3-9358-a4a2e644f394')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6fb695ad-d02b-4ff3-9358-a4a2e644f394 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(\"TRAIN DATA shape: {}\".format(train.shape))\n",
        "display(train.head(3))\n",
        "#print(\"OLD-TRAIN DATA: {}\".format(old_train.shape))\n",
        "#display(old_train.head(3))\n",
        "print(\"TEST DATA: {}\".format(test.shape))\n",
        "display(test.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#total = pd.concat([train,test],axis=0,ignore_index=True)\n",
        "#train = total.iloc[:len(train),:]\n",
        "#test = total.iloc[len(train):,:]\n",
        "#cat_col"
      ],
      "metadata": {
        "id": "ypj-0I4xRu9Q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.astype(\"float\")\n",
        "test = test.astype(\"float\")\n",
        "cat_col = [name for name in train.columns if train[name].nunique()<25]\n",
        "\n",
        "#train_=train.copy()\n",
        "train[cat_col] = train[cat_col].astype(\"int\")\n",
        "cat_col.remove(\"Exited\")\n",
        "test[cat_col] = test[cat_col].astype(\"int\")\n",
        "summary(train).style.background_gradient(cmap='Reds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kp0J8ADvN9Xc",
        "outputId": "807bb9c5-c39f-4780-ce2c-587f2df766e9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data shape: (165034, 44)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fb0581416f0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_9166e_row0_col1, #T_9166e_row0_col2, #T_9166e_row0_col5, #T_9166e_row1_col1, #T_9166e_row1_col2, #T_9166e_row1_col5, #T_9166e_row2_col1, #T_9166e_row2_col2, #T_9166e_row2_col3, #T_9166e_row2_col5, #T_9166e_row3_col1, #T_9166e_row3_col2, #T_9166e_row3_col5, #T_9166e_row4_col1, #T_9166e_row4_col2, #T_9166e_row4_col3, #T_9166e_row4_col5, #T_9166e_row5_col1, #T_9166e_row5_col2, #T_9166e_row5_col3, #T_9166e_row5_col5, #T_9166e_row6_col1, #T_9166e_row6_col2, #T_9166e_row6_col3, #T_9166e_row6_col5, #T_9166e_row7_col1, #T_9166e_row7_col2, #T_9166e_row7_col3, #T_9166e_row7_col5, #T_9166e_row8_col1, #T_9166e_row8_col2, #T_9166e_row8_col3, #T_9166e_row8_col5, #T_9166e_row9_col1, #T_9166e_row9_col2, #T_9166e_row9_col3, #T_9166e_row9_col5, #T_9166e_row10_col1, #T_9166e_row10_col2, #T_9166e_row10_col3, #T_9166e_row10_col5, #T_9166e_row11_col1, #T_9166e_row11_col2, #T_9166e_row11_col3, #T_9166e_row11_col4, #T_9166e_row11_col5, #T_9166e_row11_col6, #T_9166e_row11_col7, #T_9166e_row12_col1, #T_9166e_row12_col2, #T_9166e_row12_col5, #T_9166e_row13_col1, #T_9166e_row13_col2, #T_9166e_row13_col3, #T_9166e_row13_col5, #T_9166e_row14_col1, #T_9166e_row14_col2, #T_9166e_row14_col3, #T_9166e_row14_col5, #T_9166e_row15_col1, #T_9166e_row15_col2, #T_9166e_row16_col1, #T_9166e_row16_col2, #T_9166e_row16_col3, #T_9166e_row16_col5, #T_9166e_row17_col1, #T_9166e_row17_col2, #T_9166e_row17_col5, #T_9166e_row18_col1, #T_9166e_row18_col2, #T_9166e_row18_col3, #T_9166e_row18_col5, #T_9166e_row19_col1, #T_9166e_row19_col2, #T_9166e_row19_col3, #T_9166e_row19_col5, #T_9166e_row20_col1, #T_9166e_row20_col2, #T_9166e_row20_col3, #T_9166e_row20_col5, #T_9166e_row21_col1, #T_9166e_row21_col2, #T_9166e_row21_col3, #T_9166e_row21_col5, #T_9166e_row22_col1, #T_9166e_row22_col2, #T_9166e_row22_col5, #T_9166e_row23_col1, #T_9166e_row23_col2, #T_9166e_row23_col5, #T_9166e_row24_col1, #T_9166e_row24_col2, #T_9166e_row24_col5, #T_9166e_row25_col1, #T_9166e_row25_col2, #T_9166e_row25_col3, #T_9166e_row26_col1, #T_9166e_row26_col2, #T_9166e_row26_col5, #T_9166e_row27_col1, #T_9166e_row27_col2, #T_9166e_row27_col5, #T_9166e_row28_col1, #T_9166e_row28_col2, #T_9166e_row28_col5, #T_9166e_row29_col1, #T_9166e_row29_col2, #T_9166e_row29_col5, #T_9166e_row30_col1, #T_9166e_row30_col2, #T_9166e_row30_col5, #T_9166e_row31_col1, #T_9166e_row31_col2, #T_9166e_row31_col5, #T_9166e_row32_col1, #T_9166e_row32_col2, #T_9166e_row32_col5, #T_9166e_row33_col1, #T_9166e_row33_col2, #T_9166e_row33_col5, #T_9166e_row34_col1, #T_9166e_row34_col2, #T_9166e_row34_col3, #T_9166e_row35_col1, #T_9166e_row35_col2, #T_9166e_row35_col5, #T_9166e_row36_col1, #T_9166e_row36_col2, #T_9166e_row36_col5, #T_9166e_row37_col1, #T_9166e_row37_col2, #T_9166e_row37_col5, #T_9166e_row38_col1, #T_9166e_row38_col2, #T_9166e_row38_col3, #T_9166e_row38_col5, #T_9166e_row39_col1, #T_9166e_row39_col2, #T_9166e_row39_col3, #T_9166e_row40_col1, #T_9166e_row40_col2, #T_9166e_row40_col5, #T_9166e_row41_col1, #T_9166e_row41_col2, #T_9166e_row41_col5, #T_9166e_row42_col1, #T_9166e_row42_col2, #T_9166e_row42_col5, #T_9166e_row43_col1, #T_9166e_row43_col2, #T_9166e_row43_col3, #T_9166e_row43_col5 {\n",
              "  background-color: #fff5f0;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9166e_row0_col3, #T_9166e_row1_col3, #T_9166e_row12_col3, #T_9166e_row15_col4, #T_9166e_row15_col5, #T_9166e_row15_col6, #T_9166e_row15_col7, #T_9166e_row17_col3, #T_9166e_row22_col3, #T_9166e_row27_col3, #T_9166e_row28_col3, #T_9166e_row29_col3, #T_9166e_row32_col3, #T_9166e_row36_col3, #T_9166e_row37_col3, #T_9166e_row41_col3, #T_9166e_row42_col3 {\n",
              "  background-color: #67000d;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9166e_row0_col4, #T_9166e_row0_col6, #T_9166e_row0_col7, #T_9166e_row1_col4, #T_9166e_row1_col6, #T_9166e_row1_col7, #T_9166e_row2_col4, #T_9166e_row2_col6, #T_9166e_row2_col7, #T_9166e_row3_col3, #T_9166e_row3_col4, #T_9166e_row3_col6, #T_9166e_row3_col7, #T_9166e_row4_col4, #T_9166e_row4_col6, #T_9166e_row4_col7, #T_9166e_row5_col4, #T_9166e_row5_col6, #T_9166e_row5_col7, #T_9166e_row6_col4, #T_9166e_row6_col6, #T_9166e_row6_col7, #T_9166e_row7_col4, #T_9166e_row7_col6, #T_9166e_row7_col7, #T_9166e_row8_col4, #T_9166e_row8_col6, #T_9166e_row8_col7, #T_9166e_row9_col4, #T_9166e_row9_col6, #T_9166e_row9_col7, #T_9166e_row10_col4, #T_9166e_row10_col6, #T_9166e_row10_col7, #T_9166e_row12_col4, #T_9166e_row12_col6, #T_9166e_row12_col7, #T_9166e_row13_col4, #T_9166e_row13_col6, #T_9166e_row13_col7, #T_9166e_row14_col4, #T_9166e_row14_col6, #T_9166e_row14_col7, #T_9166e_row16_col4, #T_9166e_row16_col6, #T_9166e_row16_col7, #T_9166e_row17_col4, #T_9166e_row17_col6, #T_9166e_row17_col7, #T_9166e_row18_col4, #T_9166e_row18_col6, #T_9166e_row18_col7, #T_9166e_row19_col4, #T_9166e_row19_col6, #T_9166e_row19_col7, #T_9166e_row20_col4, #T_9166e_row20_col6, #T_9166e_row20_col7, #T_9166e_row21_col4, #T_9166e_row21_col6, #T_9166e_row21_col7, #T_9166e_row22_col4, #T_9166e_row22_col6, #T_9166e_row22_col7, #T_9166e_row23_col4, #T_9166e_row23_col6, #T_9166e_row23_col7, #T_9166e_row24_col3, #T_9166e_row24_col4, #T_9166e_row24_col6, #T_9166e_row24_col7, #T_9166e_row25_col4, #T_9166e_row25_col5, #T_9166e_row26_col3, #T_9166e_row26_col4, #T_9166e_row26_col6, #T_9166e_row26_col7, #T_9166e_row27_col4, #T_9166e_row27_col6, #T_9166e_row27_col7, #T_9166e_row28_col4, #T_9166e_row28_col6, #T_9166e_row28_col7, #T_9166e_row29_col4, #T_9166e_row29_col6, #T_9166e_row29_col7, #T_9166e_row30_col3, #T_9166e_row30_col4, #T_9166e_row30_col6, #T_9166e_row30_col7, #T_9166e_row31_col4, #T_9166e_row31_col6, #T_9166e_row31_col7, #T_9166e_row32_col4, #T_9166e_row32_col6, #T_9166e_row32_col7, #T_9166e_row33_col4, #T_9166e_row33_col6, #T_9166e_row33_col7, #T_9166e_row34_col4, #T_9166e_row34_col5, #T_9166e_row35_col4, #T_9166e_row35_col6, #T_9166e_row35_col7, #T_9166e_row36_col4, #T_9166e_row36_col6, #T_9166e_row36_col7, #T_9166e_row37_col4, #T_9166e_row37_col6, #T_9166e_row37_col7, #T_9166e_row38_col4, #T_9166e_row38_col6, #T_9166e_row38_col7, #T_9166e_row39_col4, #T_9166e_row39_col5, #T_9166e_row40_col3, #T_9166e_row40_col4, #T_9166e_row40_col6, #T_9166e_row40_col7, #T_9166e_row41_col4, #T_9166e_row41_col6, #T_9166e_row41_col7, #T_9166e_row42_col4, #T_9166e_row42_col6, #T_9166e_row42_col7, #T_9166e_row43_col4, #T_9166e_row43_col6, #T_9166e_row43_col7 {\n",
              "  background-color: #fff4ef;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9166e_row15_col3 {\n",
              "  background-color: #fedbcc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9166e_row23_col3 {\n",
              "  background-color: #fca082;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9166e_row25_col6, #T_9166e_row25_col7, #T_9166e_row34_col6, #T_9166e_row34_col7, #T_9166e_row39_col6, #T_9166e_row39_col7 {\n",
              "  background-color: #fff4ee;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9166e_row31_col3 {\n",
              "  background-color: #fcc3ab;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9166e_row33_col3 {\n",
              "  background-color: #fdd0bc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9166e_row35_col3 {\n",
              "  background-color: #f24633;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_9166e\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_9166e_level0_col0\" class=\"col_heading level0 col0\" >data type</th>\n",
              "      <th id=\"T_9166e_level0_col1\" class=\"col_heading level0 col1\" >#missing</th>\n",
              "      <th id=\"T_9166e_level0_col2\" class=\"col_heading level0 col2\" >%missing</th>\n",
              "      <th id=\"T_9166e_level0_col3\" class=\"col_heading level0 col3\" >#unique</th>\n",
              "      <th id=\"T_9166e_level0_col4\" class=\"col_heading level0 col4\" >min</th>\n",
              "      <th id=\"T_9166e_level0_col5\" class=\"col_heading level0 col5\" >max</th>\n",
              "      <th id=\"T_9166e_level0_col6\" class=\"col_heading level0 col6\" >median</th>\n",
              "      <th id=\"T_9166e_level0_col7\" class=\"col_heading level0 col7\" >mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row0\" class=\"row_heading level0 row0\" >Age_Category_enc</th>\n",
              "      <td id=\"T_9166e_row0_col0\" class=\"data row0 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row0_col1\" class=\"data row0 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row0_col3\" class=\"data row0 col3\" >165033</td>\n",
              "      <td id=\"T_9166e_row0_col4\" class=\"data row0 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row0_col5\" class=\"data row0 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row0_col6\" class=\"data row0 col6\" >-0.000014</td>\n",
              "      <td id=\"T_9166e_row0_col7\" class=\"data row0 col7\" >-0.000678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row1\" class=\"row_heading level0 row1\" >bs_nop_enc</th>\n",
              "      <td id=\"T_9166e_row1_col0\" class=\"data row1 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row1_col1\" class=\"data row1 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row1_col3\" class=\"data row1 col3\" >165025</td>\n",
              "      <td id=\"T_9166e_row1_col4\" class=\"data row1 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row1_col5\" class=\"data row1 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row1_col6\" class=\"data row1 col6\" >0.004491</td>\n",
              "      <td id=\"T_9166e_row1_col7\" class=\"data row1 col7\" >0.002825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row2\" class=\"row_heading level0 row2\" >act_nop</th>\n",
              "      <td id=\"T_9166e_row2_col0\" class=\"data row2 col0\" >int64</td>\n",
              "      <td id=\"T_9166e_row2_col1\" class=\"data row2 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row2_col2\" class=\"data row2 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row2_col3\" class=\"data row2 col3\" >5</td>\n",
              "      <td id=\"T_9166e_row2_col4\" class=\"data row2 col4\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row2_col5\" class=\"data row2 col5\" >4.000000</td>\n",
              "      <td id=\"T_9166e_row2_col6\" class=\"data row2 col6\" >2.000000</td>\n",
              "      <td id=\"T_9166e_row2_col7\" class=\"data row2 col7\" >1.574748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row3\" class=\"row_heading level0 row3\" >Surname_tfidf_1</th>\n",
              "      <td id=\"T_9166e_row3_col0\" class=\"data row3 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row3_col1\" class=\"data row3 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row3_col2\" class=\"data row3 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row3_col3\" class=\"data row3 col3\" >1007</td>\n",
              "      <td id=\"T_9166e_row3_col4\" class=\"data row3 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row3_col5\" class=\"data row3 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row3_col6\" class=\"data row3 col6\" >0.036391</td>\n",
              "      <td id=\"T_9166e_row3_col7\" class=\"data row3 col7\" >0.004019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row4\" class=\"row_heading level0 row4\" >bs_nop_count_label</th>\n",
              "      <td id=\"T_9166e_row4_col0\" class=\"data row4 col0\" >int64</td>\n",
              "      <td id=\"T_9166e_row4_col1\" class=\"data row4 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row4_col2\" class=\"data row4 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row4_col3\" class=\"data row4 col3\" >5</td>\n",
              "      <td id=\"T_9166e_row4_col4\" class=\"data row4 col4\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row4_col5\" class=\"data row4 col5\" >4.000000</td>\n",
              "      <td id=\"T_9166e_row4_col6\" class=\"data row4 col6\" >1.000000</td>\n",
              "      <td id=\"T_9166e_row4_col7\" class=\"data row4 col7\" >1.075778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row5\" class=\"row_heading level0 row5\" >HasCrCard</th>\n",
              "      <td id=\"T_9166e_row5_col0\" class=\"data row5 col0\" >int64</td>\n",
              "      <td id=\"T_9166e_row5_col1\" class=\"data row5 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row5_col2\" class=\"data row5 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row5_col3\" class=\"data row5 col3\" >2</td>\n",
              "      <td id=\"T_9166e_row5_col4\" class=\"data row5 col4\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
              "      <td id=\"T_9166e_row5_col6\" class=\"data row5 col6\" >1.000000</td>\n",
              "      <td id=\"T_9166e_row5_col7\" class=\"data row5 col7\" >0.753954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row6\" class=\"row_heading level0 row6\" >IsActiveMember</th>\n",
              "      <td id=\"T_9166e_row6_col0\" class=\"data row6 col0\" >int64</td>\n",
              "      <td id=\"T_9166e_row6_col1\" class=\"data row6 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row6_col2\" class=\"data row6 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row6_col3\" class=\"data row6 col3\" >2</td>\n",
              "      <td id=\"T_9166e_row6_col4\" class=\"data row6 col4\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row6_col5\" class=\"data row6 col5\" >1.000000</td>\n",
              "      <td id=\"T_9166e_row6_col6\" class=\"data row6 col6\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row6_col7\" class=\"data row6 col7\" >0.497770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row7\" class=\"row_heading level0 row7\" >Age_pca_comb</th>\n",
              "      <td id=\"T_9166e_row7_col0\" class=\"data row7 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row7_col1\" class=\"data row7 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row7_col2\" class=\"data row7 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row7_col3\" class=\"data row7 col3\" >74</td>\n",
              "      <td id=\"T_9166e_row7_col4\" class=\"data row7 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row7_col5\" class=\"data row7 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row7_col6\" class=\"data row7 col6\" >0.005018</td>\n",
              "      <td id=\"T_9166e_row7_col7\" class=\"data row7 col7\" >-0.004031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row8\" class=\"row_heading level0 row8\" >CreditScore_unimp_cluster_WOE</th>\n",
              "      <td id=\"T_9166e_row8_col0\" class=\"data row8 col0\" >int64</td>\n",
              "      <td id=\"T_9166e_row8_col1\" class=\"data row8 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row8_col2\" class=\"data row8 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row8_col3\" class=\"data row8 col3\" >10</td>\n",
              "      <td id=\"T_9166e_row8_col4\" class=\"data row8 col4\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row8_col5\" class=\"data row8 col5\" >9.000000</td>\n",
              "      <td id=\"T_9166e_row8_col6\" class=\"data row8 col6\" >5.000000</td>\n",
              "      <td id=\"T_9166e_row8_col7\" class=\"data row8 col7\" >4.177091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row9\" class=\"row_heading level0 row9\" >Age-NumOfProducts_cat_count</th>\n",
              "      <td id=\"T_9166e_row9_col0\" class=\"data row9 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row9_col1\" class=\"data row9 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row9_col2\" class=\"data row9 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row9_col3\" class=\"data row9 col3\" >197</td>\n",
              "      <td id=\"T_9166e_row9_col4\" class=\"data row9 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row9_col5\" class=\"data row9 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row9_col6\" class=\"data row9 col6\" >0.005018</td>\n",
              "      <td id=\"T_9166e_row9_col7\" class=\"data row9 col7\" >-0.000006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row10\" class=\"row_heading level0 row10\" >bs_nop</th>\n",
              "      <td id=\"T_9166e_row10_col0\" class=\"data row10 col0\" >int64</td>\n",
              "      <td id=\"T_9166e_row10_col1\" class=\"data row10 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row10_col2\" class=\"data row10 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row10_col3\" class=\"data row10 col3\" >5</td>\n",
              "      <td id=\"T_9166e_row10_col4\" class=\"data row10 col4\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row10_col5\" class=\"data row10 col5\" >4.000000</td>\n",
              "      <td id=\"T_9166e_row10_col6\" class=\"data row10 col6\" >2.000000</td>\n",
              "      <td id=\"T_9166e_row10_col7\" class=\"data row10 col7\" >1.720379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row11\" class=\"row_heading level0 row11\" >Geography_count_label-NumOfProducts_cat_count</th>\n",
              "      <td id=\"T_9166e_row11_col0\" class=\"data row11 col0\" >int64</td>\n",
              "      <td id=\"T_9166e_row11_col1\" class=\"data row11 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row11_col2\" class=\"data row11 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row11_col3\" class=\"data row11 col3\" >9</td>\n",
              "      <td id=\"T_9166e_row11_col4\" class=\"data row11 col4\" >-84291.000000</td>\n",
              "      <td id=\"T_9166e_row11_col5\" class=\"data row11 col5\" >-3367.000000</td>\n",
              "      <td id=\"T_9166e_row11_col6\" class=\"data row11 col6\" >-84289.000000</td>\n",
              "      <td id=\"T_9166e_row11_col7\" class=\"data row11 col7\" >-79395.477859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row12\" class=\"row_heading level0 row12\" >act_age_enc</th>\n",
              "      <td id=\"T_9166e_row12_col0\" class=\"data row12 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row12_col1\" class=\"data row12 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row12_col2\" class=\"data row12 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row12_col3\" class=\"data row12 col3\" >165030</td>\n",
              "      <td id=\"T_9166e_row12_col4\" class=\"data row12 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row12_col5\" class=\"data row12 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row12_col6\" class=\"data row12 col6\" >-0.003362</td>\n",
              "      <td id=\"T_9166e_row12_col7\" class=\"data row12 col7\" >-0.001506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row13\" class=\"row_heading level0 row13\" >act_age</th>\n",
              "      <td id=\"T_9166e_row13_col0\" class=\"data row13 col0\" >int64</td>\n",
              "      <td id=\"T_9166e_row13_col1\" class=\"data row13 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row13_col2\" class=\"data row13 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row13_col3\" class=\"data row13 col3\" >12</td>\n",
              "      <td id=\"T_9166e_row13_col4\" class=\"data row13 col4\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row13_col5\" class=\"data row13 col5\" >11.000000</td>\n",
              "      <td id=\"T_9166e_row13_col6\" class=\"data row13 col6\" >5.000000</td>\n",
              "      <td id=\"T_9166e_row13_col7\" class=\"data row13 col7\" >4.166566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row14\" class=\"row_heading level0 row14\" >Age_cat*NumOfProducts_cat_count_label</th>\n",
              "      <td id=\"T_9166e_row14_col0\" class=\"data row14 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row14_col1\" class=\"data row14 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row14_col2\" class=\"data row14 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row14_col3\" class=\"data row14 col3\" >111</td>\n",
              "      <td id=\"T_9166e_row14_col4\" class=\"data row14 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row14_col5\" class=\"data row14 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row14_col6\" class=\"data row14 col6\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row14_col7\" class=\"data row14 col7\" >-2.259368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row15\" class=\"row_heading level0 row15\" >CustomerId</th>\n",
              "      <td id=\"T_9166e_row15_col0\" class=\"data row15 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row15_col1\" class=\"data row15 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row15_col2\" class=\"data row15 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row15_col3\" class=\"data row15 col3\" >23221</td>\n",
              "      <td id=\"T_9166e_row15_col4\" class=\"data row15 col4\" >15565701.000000</td>\n",
              "      <td id=\"T_9166e_row15_col5\" class=\"data row15 col5\" >15815690.000000</td>\n",
              "      <td id=\"T_9166e_row15_col6\" class=\"data row15 col6\" >15690169.000000</td>\n",
              "      <td id=\"T_9166e_row15_col7\" class=\"data row15 col7\" >15692005.019026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row16\" class=\"row_heading level0 row16\" >Geography_count/NumOfProducts_cat_count_label</th>\n",
              "      <td id=\"T_9166e_row16_col0\" class=\"data row16 col0\" >int64</td>\n",
              "      <td id=\"T_9166e_row16_col1\" class=\"data row16 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row16_col2\" class=\"data row16 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row16_col3\" class=\"data row16 col3\" >5</td>\n",
              "      <td id=\"T_9166e_row16_col4\" class=\"data row16 col4\" >-5.000000</td>\n",
              "      <td id=\"T_9166e_row16_col5\" class=\"data row16 col5\" >1.000000</td>\n",
              "      <td id=\"T_9166e_row16_col6\" class=\"data row16 col6\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row16_col7\" class=\"data row16 col7\" >0.144946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row17\" class=\"row_heading level0 row17\" >IsActiveMember_enc</th>\n",
              "      <td id=\"T_9166e_row17_col0\" class=\"data row17 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row17_col1\" class=\"data row17 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row17_col2\" class=\"data row17 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row17_col3\" class=\"data row17 col3\" >165034</td>\n",
              "      <td id=\"T_9166e_row17_col4\" class=\"data row17 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row17_col5\" class=\"data row17 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row17_col6\" class=\"data row17 col6\" >0.000509</td>\n",
              "      <td id=\"T_9166e_row17_col7\" class=\"data row17 col7\" >0.001134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row18\" class=\"row_heading level0 row18\" >CreditScore_cat_pca_comb_final</th>\n",
              "      <td id=\"T_9166e_row18_col0\" class=\"data row18 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row18_col1\" class=\"data row18 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row18_col2\" class=\"data row18 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row18_col3\" class=\"data row18 col3\" >456</td>\n",
              "      <td id=\"T_9166e_row18_col4\" class=\"data row18 col4\" >-7.655587</td>\n",
              "      <td id=\"T_9166e_row18_col5\" class=\"data row18 col5\" >14.763312</td>\n",
              "      <td id=\"T_9166e_row18_col6\" class=\"data row18 col6\" >-0.146293</td>\n",
              "      <td id=\"T_9166e_row18_col7\" class=\"data row18 col7\" >0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row19\" class=\"row_heading level0 row19\" >bs_active</th>\n",
              "      <td id=\"T_9166e_row19_col0\" class=\"data row19 col0\" >int64</td>\n",
              "      <td id=\"T_9166e_row19_col1\" class=\"data row19 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row19_col2\" class=\"data row19 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row19_col3\" class=\"data row19 col3\" >4</td>\n",
              "      <td id=\"T_9166e_row19_col4\" class=\"data row19 col4\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row19_col5\" class=\"data row19 col5\" >3.000000</td>\n",
              "      <td id=\"T_9166e_row19_col6\" class=\"data row19 col6\" >2.000000</td>\n",
              "      <td id=\"T_9166e_row19_col7\" class=\"data row19 col7\" >1.645522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row20\" class=\"row_heading level0 row20\" >Age_pca_comb_pca_comb_final</th>\n",
              "      <td id=\"T_9166e_row20_col0\" class=\"data row20 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row20_col1\" class=\"data row20 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row20_col2\" class=\"data row20 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row20_col3\" class=\"data row20 col3\" >76</td>\n",
              "      <td id=\"T_9166e_row20_col4\" class=\"data row20 col4\" >-1.898036</td>\n",
              "      <td id=\"T_9166e_row20_col5\" class=\"data row20 col5\" >8.175671</td>\n",
              "      <td id=\"T_9166e_row20_col6\" class=\"data row20 col6\" >-0.768477</td>\n",
              "      <td id=\"T_9166e_row20_col7\" class=\"data row20 col7\" >-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row21\" class=\"row_heading level0 row21\" >Balance_Range</th>\n",
              "      <td id=\"T_9166e_row21_col0\" class=\"data row21 col0\" >int64</td>\n",
              "      <td id=\"T_9166e_row21_col1\" class=\"data row21 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row21_col2\" class=\"data row21 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row21_col3\" class=\"data row21 col3\" >5</td>\n",
              "      <td id=\"T_9166e_row21_col4\" class=\"data row21 col4\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row21_col5\" class=\"data row21 col5\" >4.000000</td>\n",
              "      <td id=\"T_9166e_row21_col6\" class=\"data row21 col6\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row21_col7\" class=\"data row21 col7\" >1.082310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row22\" class=\"row_heading level0 row22\" >bs_gender_enc</th>\n",
              "      <td id=\"T_9166e_row22_col0\" class=\"data row22 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row22_col1\" class=\"data row22 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row22_col2\" class=\"data row22 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row22_col3\" class=\"data row22 col3\" >165028</td>\n",
              "      <td id=\"T_9166e_row22_col4\" class=\"data row22 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row22_col5\" class=\"data row22 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row22_col6\" class=\"data row22 col6\" >0.003993</td>\n",
              "      <td id=\"T_9166e_row22_col7\" class=\"data row22 col7\" >0.003886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row23\" class=\"row_heading level0 row23\" >quant_EstimatedSalary</th>\n",
              "      <td id=\"T_9166e_row23_col0\" class=\"data row23 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row23_col1\" class=\"data row23 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row23_col2\" class=\"data row23 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row23_col3\" class=\"data row23 col3\" >55296</td>\n",
              "      <td id=\"T_9166e_row23_col4\" class=\"data row23 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row23_col5\" class=\"data row23 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row23_col6\" class=\"data row23 col6\" >-0.001255</td>\n",
              "      <td id=\"T_9166e_row23_col7\" class=\"data row23 col7\" >0.003334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row24\" class=\"row_heading level0 row24\" >Surname_tfidf_2</th>\n",
              "      <td id=\"T_9166e_row24_col0\" class=\"data row24 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row24_col1\" class=\"data row24 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row24_col2\" class=\"data row24 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row24_col3\" class=\"data row24 col3\" >1007</td>\n",
              "      <td id=\"T_9166e_row24_col4\" class=\"data row24 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row24_col5\" class=\"data row24 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row24_col6\" class=\"data row24 col6\" >0.062770</td>\n",
              "      <td id=\"T_9166e_row24_col7\" class=\"data row24 col7\" >0.027401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row25\" class=\"row_heading level0 row25\" >bs_nop_count</th>\n",
              "      <td id=\"T_9166e_row25_col0\" class=\"data row25 col0\" >int64</td>\n",
              "      <td id=\"T_9166e_row25_col1\" class=\"data row25 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row25_col2\" class=\"data row25 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row25_col3\" class=\"data row25 col3\" >5</td>\n",
              "      <td id=\"T_9166e_row25_col4\" class=\"data row25 col4\" >3369.000000</td>\n",
              "      <td id=\"T_9166e_row25_col5\" class=\"data row25 col5\" >64815.000000</td>\n",
              "      <td id=\"T_9166e_row25_col6\" class=\"data row25 col6\" >49112.000000</td>\n",
              "      <td id=\"T_9166e_row25_col7\" class=\"data row25 col7\" >47277.398294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row26\" class=\"row_heading level0 row26\" >Surname_tfidf_3</th>\n",
              "      <td id=\"T_9166e_row26_col0\" class=\"data row26 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row26_col1\" class=\"data row26 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row26_col2\" class=\"data row26 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row26_col3\" class=\"data row26 col3\" >1007</td>\n",
              "      <td id=\"T_9166e_row26_col4\" class=\"data row26 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row26_col5\" class=\"data row26 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row26_col6\" class=\"data row26 col6\" >-0.023839</td>\n",
              "      <td id=\"T_9166e_row26_col7\" class=\"data row26 col7\" >0.004221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row27\" class=\"row_heading level0 row27\" >Gender_enc</th>\n",
              "      <td id=\"T_9166e_row27_col0\" class=\"data row27 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row27_col1\" class=\"data row27 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row27_col2\" class=\"data row27 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row27_col3\" class=\"data row27 col3\" >165034</td>\n",
              "      <td id=\"T_9166e_row27_col4\" class=\"data row27 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row27_col5\" class=\"data row27 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row27_col6\" class=\"data row27 col6\" >-0.000711</td>\n",
              "      <td id=\"T_9166e_row27_col7\" class=\"data row27 col7\" >0.000660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row28\" class=\"row_heading level0 row28\" >Tenure_enc</th>\n",
              "      <td id=\"T_9166e_row28_col0\" class=\"data row28 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row28_col1\" class=\"data row28 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row28_col2\" class=\"data row28 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row28_col3\" class=\"data row28 col3\" >165033</td>\n",
              "      <td id=\"T_9166e_row28_col4\" class=\"data row28 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row28_col5\" class=\"data row28 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row28_col6\" class=\"data row28 col6\" >0.002775</td>\n",
              "      <td id=\"T_9166e_row28_col7\" class=\"data row28 col7\" >0.001260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row29\" class=\"row_heading level0 row29\" >Balance_Range_enc</th>\n",
              "      <td id=\"T_9166e_row29_col0\" class=\"data row29 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row29_col1\" class=\"data row29 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row29_col2\" class=\"data row29 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row29_col3\" class=\"data row29 col3\" >165032</td>\n",
              "      <td id=\"T_9166e_row29_col4\" class=\"data row29 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row29_col5\" class=\"data row29 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row29_col6\" class=\"data row29 col6\" >0.004943</td>\n",
              "      <td id=\"T_9166e_row29_col7\" class=\"data row29 col7\" >0.002971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row30\" class=\"row_heading level0 row30\" >Surname_tfidf_4</th>\n",
              "      <td id=\"T_9166e_row30_col0\" class=\"data row30 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row30_col1\" class=\"data row30 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row30_col2\" class=\"data row30 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row30_col3\" class=\"data row30 col3\" >1007</td>\n",
              "      <td id=\"T_9166e_row30_col4\" class=\"data row30 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row30_col5\" class=\"data row30 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row30_col6\" class=\"data row30 col6\" >-0.026349</td>\n",
              "      <td id=\"T_9166e_row30_col7\" class=\"data row30 col7\" >0.006103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row31\" class=\"row_heading level0 row31\" >Balance-NumOfProducts_cat_count_label</th>\n",
              "      <td id=\"T_9166e_row31_col0\" class=\"data row31 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row31_col1\" class=\"data row31 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row31_col2\" class=\"data row31 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row31_col3\" class=\"data row31 col3\" >36756</td>\n",
              "      <td id=\"T_9166e_row31_col4\" class=\"data row31 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row31_col5\" class=\"data row31 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row31_col6\" class=\"data row31 col6\" >0.469603</td>\n",
              "      <td id=\"T_9166e_row31_col7\" class=\"data row31 col7\" >-0.024350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row32\" class=\"row_heading level0 row32\" >Geo_Gender_enc</th>\n",
              "      <td id=\"T_9166e_row32_col0\" class=\"data row32 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row32_col1\" class=\"data row32 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row32_col2\" class=\"data row32 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row32_col3\" class=\"data row32 col3\" >165032</td>\n",
              "      <td id=\"T_9166e_row32_col4\" class=\"data row32 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row32_col5\" class=\"data row32 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row32_col6\" class=\"data row32 col6\" >0.001731</td>\n",
              "      <td id=\"T_9166e_row32_col7\" class=\"data row32 col7\" >0.001060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row33\" class=\"row_heading level0 row33\" >Balance_pca_comb</th>\n",
              "      <td id=\"T_9166e_row33_col0\" class=\"data row33 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row33_col1\" class=\"data row33 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row33_col2\" class=\"data row33 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row33_col3\" class=\"data row33 col3\" >30075</td>\n",
              "      <td id=\"T_9166e_row33_col4\" class=\"data row33 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row33_col5\" class=\"data row33 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row33_col6\" class=\"data row33 col6\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row33_col7\" class=\"data row33 col7\" >2.424983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row34\" class=\"row_heading level0 row34\" >NumOfProducts_cat_count</th>\n",
              "      <td id=\"T_9166e_row34_col0\" class=\"data row34 col0\" >int64</td>\n",
              "      <td id=\"T_9166e_row34_col1\" class=\"data row34 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row34_col2\" class=\"data row34 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row34_col3\" class=\"data row34 col3\" >3</td>\n",
              "      <td id=\"T_9166e_row34_col4\" class=\"data row34 col4\" >3369.000000</td>\n",
              "      <td id=\"T_9166e_row34_col5\" class=\"data row34 col5\" >84291.000000</td>\n",
              "      <td id=\"T_9166e_row34_col6\" class=\"data row34 col6\" >84291.000000</td>\n",
              "      <td id=\"T_9166e_row34_col7\" class=\"data row34 col7\" >79396.116667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row35\" class=\"row_heading level0 row35\" >Balance_Salary</th>\n",
              "      <td id=\"T_9166e_row35_col0\" class=\"data row35 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row35_col1\" class=\"data row35 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row35_col2\" class=\"data row35 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row35_col3\" class=\"data row35 col3\" >98045</td>\n",
              "      <td id=\"T_9166e_row35_col4\" class=\"data row35 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row35_col5\" class=\"data row35 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row35_col6\" class=\"data row35 col6\" >-0.005255</td>\n",
              "      <td id=\"T_9166e_row35_col7\" class=\"data row35 col7\" >-0.003172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row36\" class=\"row_heading level0 row36\" >bs_active_enc</th>\n",
              "      <td id=\"T_9166e_row36_col0\" class=\"data row36 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row36_col1\" class=\"data row36 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row36_col2\" class=\"data row36 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row36_col3\" class=\"data row36 col3\" >165030</td>\n",
              "      <td id=\"T_9166e_row36_col4\" class=\"data row36 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row36_col5\" class=\"data row36 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row36_col6\" class=\"data row36 col6\" >0.000378</td>\n",
              "      <td id=\"T_9166e_row36_col7\" class=\"data row36 col7\" >0.000620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row37\" class=\"row_heading level0 row37\" >act_nop_enc</th>\n",
              "      <td id=\"T_9166e_row37_col0\" class=\"data row37 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row37_col1\" class=\"data row37 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row37_col2\" class=\"data row37 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row37_col3\" class=\"data row37 col3\" >165032</td>\n",
              "      <td id=\"T_9166e_row37_col4\" class=\"data row37 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row37_col5\" class=\"data row37 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row37_col6\" class=\"data row37 col6\" >0.002421</td>\n",
              "      <td id=\"T_9166e_row37_col7\" class=\"data row37 col7\" >0.003010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row38\" class=\"row_heading level0 row38\" >CreditScore_pca_comb_final</th>\n",
              "      <td id=\"T_9166e_row38_col0\" class=\"data row38 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row38_col1\" class=\"data row38 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row38_col2\" class=\"data row38 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row38_col3\" class=\"data row38 col3\" >463</td>\n",
              "      <td id=\"T_9166e_row38_col4\" class=\"data row38 col4\" >-8.965207</td>\n",
              "      <td id=\"T_9166e_row38_col5\" class=\"data row38 col5\" >17.833923</td>\n",
              "      <td id=\"T_9166e_row38_col6\" class=\"data row38 col6\" >-0.542647</td>\n",
              "      <td id=\"T_9166e_row38_col7\" class=\"data row38 col7\" >0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row39\" class=\"row_heading level0 row39\" >Balance_Range_count</th>\n",
              "      <td id=\"T_9166e_row39_col0\" class=\"data row39 col0\" >int64</td>\n",
              "      <td id=\"T_9166e_row39_col1\" class=\"data row39 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row39_col2\" class=\"data row39 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row39_col3\" class=\"data row39 col3\" >5</td>\n",
              "      <td id=\"T_9166e_row39_col4\" class=\"data row39 col4\" >8974.000000</td>\n",
              "      <td id=\"T_9166e_row39_col5\" class=\"data row39 col5\" >89648.000000</td>\n",
              "      <td id=\"T_9166e_row39_col6\" class=\"data row39 col6\" >89648.000000</td>\n",
              "      <td id=\"T_9166e_row39_col7\" class=\"data row39 col7\" >58669.214622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row40\" class=\"row_heading level0 row40\" >Surname_tfidf_0</th>\n",
              "      <td id=\"T_9166e_row40_col0\" class=\"data row40 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row40_col1\" class=\"data row40 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row40_col2\" class=\"data row40 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row40_col3\" class=\"data row40 col3\" >1007</td>\n",
              "      <td id=\"T_9166e_row40_col4\" class=\"data row40 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row40_col5\" class=\"data row40 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row40_col6\" class=\"data row40 col6\" >-0.001255</td>\n",
              "      <td id=\"T_9166e_row40_col7\" class=\"data row40 col7\" >-0.005402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row41\" class=\"row_heading level0 row41\" >HasCrCard_enc</th>\n",
              "      <td id=\"T_9166e_row41_col0\" class=\"data row41 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row41_col1\" class=\"data row41 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row41_col2\" class=\"data row41 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row41_col3\" class=\"data row41 col3\" >165034</td>\n",
              "      <td id=\"T_9166e_row41_col4\" class=\"data row41 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row41_col5\" class=\"data row41 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row41_col6\" class=\"data row41 col6\" >-0.007454</td>\n",
              "      <td id=\"T_9166e_row41_col7\" class=\"data row41 col7\" >-0.008370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row42\" class=\"row_heading level0 row42\" >bs_age_enc</th>\n",
              "      <td id=\"T_9166e_row42_col0\" class=\"data row42 col0\" >float64</td>\n",
              "      <td id=\"T_9166e_row42_col1\" class=\"data row42 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row42_col2\" class=\"data row42 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row42_col3\" class=\"data row42 col3\" >165030</td>\n",
              "      <td id=\"T_9166e_row42_col4\" class=\"data row42 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9166e_row42_col5\" class=\"data row42 col5\" >5.199338</td>\n",
              "      <td id=\"T_9166e_row42_col6\" class=\"data row42 col6\" >0.006386</td>\n",
              "      <td id=\"T_9166e_row42_col7\" class=\"data row42 col7\" >0.002178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9166e_level0_row43\" class=\"row_heading level0 row43\" >Exited</th>\n",
              "      <td id=\"T_9166e_row43_col0\" class=\"data row43 col0\" >int64</td>\n",
              "      <td id=\"T_9166e_row43_col1\" class=\"data row43 col1\" >0</td>\n",
              "      <td id=\"T_9166e_row43_col2\" class=\"data row43 col2\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row43_col3\" class=\"data row43 col3\" >2</td>\n",
              "      <td id=\"T_9166e_row43_col4\" class=\"data row43 col4\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row43_col5\" class=\"data row43 col5\" >1.000000</td>\n",
              "      <td id=\"T_9166e_row43_col6\" class=\"data row43 col6\" >0.000000</td>\n",
              "      <td id=\"T_9166e_row43_col7\" class=\"data row43 col7\" >0.211599</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(test).style.background_gradient(cmap='Reds')"
      ],
      "metadata": {
        "id": "A6yLUdgNhS1E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1fe97284-6aca-41e7-d8dc-7d1272ba7753"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data shape: (110023, 43)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fb05814c0d0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_61751_row0_col1, #T_61751_row0_col2, #T_61751_row0_col5, #T_61751_row1_col1, #T_61751_row1_col2, #T_61751_row1_col5, #T_61751_row2_col1, #T_61751_row2_col2, #T_61751_row2_col3, #T_61751_row2_col5, #T_61751_row3_col1, #T_61751_row3_col2, #T_61751_row3_col5, #T_61751_row4_col1, #T_61751_row4_col2, #T_61751_row4_col3, #T_61751_row4_col5, #T_61751_row5_col1, #T_61751_row5_col2, #T_61751_row5_col3, #T_61751_row5_col5, #T_61751_row6_col1, #T_61751_row6_col2, #T_61751_row6_col3, #T_61751_row6_col5, #T_61751_row7_col1, #T_61751_row7_col2, #T_61751_row7_col3, #T_61751_row7_col5, #T_61751_row8_col1, #T_61751_row8_col2, #T_61751_row8_col3, #T_61751_row8_col5, #T_61751_row9_col1, #T_61751_row9_col2, #T_61751_row9_col3, #T_61751_row9_col5, #T_61751_row10_col1, #T_61751_row10_col2, #T_61751_row10_col3, #T_61751_row10_col5, #T_61751_row11_col1, #T_61751_row11_col2, #T_61751_row11_col3, #T_61751_row11_col4, #T_61751_row11_col5, #T_61751_row11_col6, #T_61751_row11_col7, #T_61751_row12_col1, #T_61751_row12_col2, #T_61751_row12_col5, #T_61751_row13_col1, #T_61751_row13_col2, #T_61751_row13_col3, #T_61751_row13_col5, #T_61751_row14_col1, #T_61751_row14_col2, #T_61751_row14_col3, #T_61751_row14_col5, #T_61751_row15_col1, #T_61751_row15_col2, #T_61751_row16_col1, #T_61751_row16_col2, #T_61751_row16_col3, #T_61751_row16_col5, #T_61751_row17_col1, #T_61751_row17_col2, #T_61751_row17_col5, #T_61751_row18_col1, #T_61751_row18_col2, #T_61751_row18_col5, #T_61751_row19_col1, #T_61751_row19_col2, #T_61751_row19_col3, #T_61751_row19_col5, #T_61751_row20_col1, #T_61751_row20_col2, #T_61751_row20_col3, #T_61751_row20_col5, #T_61751_row21_col1, #T_61751_row21_col2, #T_61751_row21_col3, #T_61751_row21_col5, #T_61751_row22_col1, #T_61751_row22_col2, #T_61751_row22_col5, #T_61751_row23_col1, #T_61751_row23_col2, #T_61751_row23_col5, #T_61751_row24_col1, #T_61751_row24_col2, #T_61751_row24_col5, #T_61751_row25_col1, #T_61751_row25_col2, #T_61751_row25_col3, #T_61751_row26_col1, #T_61751_row26_col2, #T_61751_row26_col5, #T_61751_row27_col1, #T_61751_row27_col2, #T_61751_row27_col5, #T_61751_row28_col1, #T_61751_row28_col2, #T_61751_row28_col5, #T_61751_row29_col1, #T_61751_row29_col2, #T_61751_row29_col5, #T_61751_row30_col1, #T_61751_row30_col2, #T_61751_row30_col5, #T_61751_row31_col1, #T_61751_row31_col2, #T_61751_row31_col5, #T_61751_row32_col1, #T_61751_row32_col2, #T_61751_row32_col5, #T_61751_row33_col1, #T_61751_row33_col2, #T_61751_row33_col5, #T_61751_row34_col1, #T_61751_row34_col2, #T_61751_row34_col3, #T_61751_row35_col1, #T_61751_row35_col2, #T_61751_row35_col5, #T_61751_row36_col1, #T_61751_row36_col2, #T_61751_row36_col5, #T_61751_row37_col1, #T_61751_row37_col2, #T_61751_row37_col5, #T_61751_row38_col1, #T_61751_row38_col2, #T_61751_row38_col5, #T_61751_row39_col1, #T_61751_row39_col2, #T_61751_row39_col3, #T_61751_row40_col1, #T_61751_row40_col2, #T_61751_row40_col5, #T_61751_row41_col1, #T_61751_row41_col2, #T_61751_row41_col5, #T_61751_row42_col1, #T_61751_row42_col2, #T_61751_row42_col5 {\n",
              "  background-color: #fff5f0;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_61751_row0_col3, #T_61751_row1_col3, #T_61751_row12_col3, #T_61751_row15_col4, #T_61751_row15_col5, #T_61751_row15_col6, #T_61751_row15_col7, #T_61751_row17_col3, #T_61751_row22_col3, #T_61751_row27_col3, #T_61751_row28_col3, #T_61751_row29_col3, #T_61751_row32_col3, #T_61751_row36_col3, #T_61751_row37_col3, #T_61751_row41_col3, #T_61751_row42_col3 {\n",
              "  background-color: #67000d;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_61751_row0_col4, #T_61751_row0_col6, #T_61751_row0_col7, #T_61751_row1_col4, #T_61751_row1_col6, #T_61751_row1_col7, #T_61751_row2_col4, #T_61751_row2_col6, #T_61751_row2_col7, #T_61751_row3_col4, #T_61751_row3_col6, #T_61751_row3_col7, #T_61751_row4_col4, #T_61751_row4_col6, #T_61751_row4_col7, #T_61751_row5_col4, #T_61751_row5_col6, #T_61751_row5_col7, #T_61751_row6_col4, #T_61751_row6_col6, #T_61751_row6_col7, #T_61751_row7_col4, #T_61751_row7_col6, #T_61751_row7_col7, #T_61751_row8_col4, #T_61751_row8_col6, #T_61751_row8_col7, #T_61751_row9_col4, #T_61751_row9_col6, #T_61751_row9_col7, #T_61751_row10_col4, #T_61751_row10_col6, #T_61751_row10_col7, #T_61751_row12_col4, #T_61751_row12_col6, #T_61751_row12_col7, #T_61751_row13_col4, #T_61751_row13_col6, #T_61751_row13_col7, #T_61751_row14_col4, #T_61751_row14_col6, #T_61751_row14_col7, #T_61751_row16_col4, #T_61751_row16_col6, #T_61751_row16_col7, #T_61751_row17_col4, #T_61751_row17_col6, #T_61751_row17_col7, #T_61751_row18_col3, #T_61751_row18_col4, #T_61751_row18_col6, #T_61751_row18_col7, #T_61751_row19_col4, #T_61751_row19_col6, #T_61751_row19_col7, #T_61751_row20_col4, #T_61751_row20_col6, #T_61751_row20_col7, #T_61751_row21_col4, #T_61751_row21_col6, #T_61751_row21_col7, #T_61751_row22_col4, #T_61751_row22_col6, #T_61751_row22_col7, #T_61751_row23_col4, #T_61751_row23_col6, #T_61751_row23_col7, #T_61751_row24_col4, #T_61751_row24_col6, #T_61751_row24_col7, #T_61751_row25_col4, #T_61751_row25_col5, #T_61751_row26_col4, #T_61751_row26_col6, #T_61751_row26_col7, #T_61751_row27_col4, #T_61751_row27_col6, #T_61751_row27_col7, #T_61751_row28_col4, #T_61751_row28_col6, #T_61751_row28_col7, #T_61751_row29_col4, #T_61751_row29_col6, #T_61751_row29_col7, #T_61751_row30_col4, #T_61751_row30_col6, #T_61751_row30_col7, #T_61751_row31_col4, #T_61751_row31_col6, #T_61751_row31_col7, #T_61751_row32_col4, #T_61751_row32_col6, #T_61751_row32_col7, #T_61751_row33_col4, #T_61751_row33_col6, #T_61751_row33_col7, #T_61751_row34_col4, #T_61751_row34_col5, #T_61751_row35_col4, #T_61751_row35_col6, #T_61751_row35_col7, #T_61751_row36_col4, #T_61751_row36_col6, #T_61751_row36_col7, #T_61751_row37_col4, #T_61751_row37_col6, #T_61751_row37_col7, #T_61751_row38_col3, #T_61751_row38_col4, #T_61751_row38_col6, #T_61751_row38_col7, #T_61751_row39_col4, #T_61751_row39_col5, #T_61751_row40_col4, #T_61751_row40_col6, #T_61751_row40_col7, #T_61751_row41_col4, #T_61751_row41_col6, #T_61751_row41_col7, #T_61751_row42_col4, #T_61751_row42_col6, #T_61751_row42_col7 {\n",
              "  background-color: #fff4ef;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_61751_row3_col3, #T_61751_row24_col3, #T_61751_row25_col6, #T_61751_row25_col7, #T_61751_row26_col3, #T_61751_row30_col3, #T_61751_row34_col6, #T_61751_row34_col7, #T_61751_row39_col6, #T_61751_row39_col7, #T_61751_row40_col3 {\n",
              "  background-color: #fff4ee;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_61751_row15_col3 {\n",
              "  background-color: #fdd1be;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_61751_row23_col3 {\n",
              "  background-color: #fc9272;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_61751_row31_col3 {\n",
              "  background-color: #fcbca2;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_61751_row33_col3 {\n",
              "  background-color: #fdc9b3;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_61751_row35_col3 {\n",
              "  background-color: #ed392b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_61751\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_61751_level0_col0\" class=\"col_heading level0 col0\" >data type</th>\n",
              "      <th id=\"T_61751_level0_col1\" class=\"col_heading level0 col1\" >#missing</th>\n",
              "      <th id=\"T_61751_level0_col2\" class=\"col_heading level0 col2\" >%missing</th>\n",
              "      <th id=\"T_61751_level0_col3\" class=\"col_heading level0 col3\" >#unique</th>\n",
              "      <th id=\"T_61751_level0_col4\" class=\"col_heading level0 col4\" >min</th>\n",
              "      <th id=\"T_61751_level0_col5\" class=\"col_heading level0 col5\" >max</th>\n",
              "      <th id=\"T_61751_level0_col6\" class=\"col_heading level0 col6\" >median</th>\n",
              "      <th id=\"T_61751_level0_col7\" class=\"col_heading level0 col7\" >mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row0\" class=\"row_heading level0 row0\" >Age_Category_enc</th>\n",
              "      <td id=\"T_61751_row0_col0\" class=\"data row0 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row0_col1\" class=\"data row0 col1\" >0</td>\n",
              "      <td id=\"T_61751_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row0_col3\" class=\"data row0 col3\" >110023</td>\n",
              "      <td id=\"T_61751_row0_col4\" class=\"data row0 col4\" >-5.199338</td>\n",
              "      <td id=\"T_61751_row0_col5\" class=\"data row0 col5\" >3.409998</td>\n",
              "      <td id=\"T_61751_row0_col6\" class=\"data row0 col6\" >0.001641</td>\n",
              "      <td id=\"T_61751_row0_col7\" class=\"data row0 col7\" >-0.000603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row1\" class=\"row_heading level0 row1\" >bs_nop_enc</th>\n",
              "      <td id=\"T_61751_row1_col0\" class=\"data row1 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row1_col1\" class=\"data row1 col1\" >0</td>\n",
              "      <td id=\"T_61751_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row1_col3\" class=\"data row1 col3\" >110019</td>\n",
              "      <td id=\"T_61751_row1_col4\" class=\"data row1 col4\" >-5.199338</td>\n",
              "      <td id=\"T_61751_row1_col5\" class=\"data row1 col5\" >5.199338</td>\n",
              "      <td id=\"T_61751_row1_col6\" class=\"data row1 col6\" >0.000164</td>\n",
              "      <td id=\"T_61751_row1_col7\" class=\"data row1 col7\" >-0.001644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row2\" class=\"row_heading level0 row2\" >act_nop</th>\n",
              "      <td id=\"T_61751_row2_col0\" class=\"data row2 col0\" >int64</td>\n",
              "      <td id=\"T_61751_row2_col1\" class=\"data row2 col1\" >0</td>\n",
              "      <td id=\"T_61751_row2_col2\" class=\"data row2 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row2_col3\" class=\"data row2 col3\" >5</td>\n",
              "      <td id=\"T_61751_row2_col4\" class=\"data row2 col4\" >0.000000</td>\n",
              "      <td id=\"T_61751_row2_col5\" class=\"data row2 col5\" >4.000000</td>\n",
              "      <td id=\"T_61751_row2_col6\" class=\"data row2 col6\" >2.000000</td>\n",
              "      <td id=\"T_61751_row2_col7\" class=\"data row2 col7\" >1.566836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row3\" class=\"row_heading level0 row3\" >Surname_tfidf_1</th>\n",
              "      <td id=\"T_61751_row3_col0\" class=\"data row3 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row3_col1\" class=\"data row3 col1\" >0</td>\n",
              "      <td id=\"T_61751_row3_col2\" class=\"data row3 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row3_col3\" class=\"data row3 col3\" >1006</td>\n",
              "      <td id=\"T_61751_row3_col4\" class=\"data row3 col4\" >-5.199338</td>\n",
              "      <td id=\"T_61751_row3_col5\" class=\"data row3 col5\" >5.199338</td>\n",
              "      <td id=\"T_61751_row3_col6\" class=\"data row3 col6\" >0.036391</td>\n",
              "      <td id=\"T_61751_row3_col7\" class=\"data row3 col7\" >0.003360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row4\" class=\"row_heading level0 row4\" >bs_nop_count_label</th>\n",
              "      <td id=\"T_61751_row4_col0\" class=\"data row4 col0\" >int64</td>\n",
              "      <td id=\"T_61751_row4_col1\" class=\"data row4 col1\" >0</td>\n",
              "      <td id=\"T_61751_row4_col2\" class=\"data row4 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row4_col3\" class=\"data row4 col3\" >5</td>\n",
              "      <td id=\"T_61751_row4_col4\" class=\"data row4 col4\" >0.000000</td>\n",
              "      <td id=\"T_61751_row4_col5\" class=\"data row4 col5\" >4.000000</td>\n",
              "      <td id=\"T_61751_row4_col6\" class=\"data row4 col6\" >1.000000</td>\n",
              "      <td id=\"T_61751_row4_col7\" class=\"data row4 col7\" >1.070113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row5\" class=\"row_heading level0 row5\" >HasCrCard</th>\n",
              "      <td id=\"T_61751_row5_col0\" class=\"data row5 col0\" >int64</td>\n",
              "      <td id=\"T_61751_row5_col1\" class=\"data row5 col1\" >0</td>\n",
              "      <td id=\"T_61751_row5_col2\" class=\"data row5 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row5_col3\" class=\"data row5 col3\" >2</td>\n",
              "      <td id=\"T_61751_row5_col4\" class=\"data row5 col4\" >0.000000</td>\n",
              "      <td id=\"T_61751_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
              "      <td id=\"T_61751_row5_col6\" class=\"data row5 col6\" >1.000000</td>\n",
              "      <td id=\"T_61751_row5_col7\" class=\"data row5 col7\" >0.753043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row6\" class=\"row_heading level0 row6\" >IsActiveMember</th>\n",
              "      <td id=\"T_61751_row6_col0\" class=\"data row6 col0\" >int64</td>\n",
              "      <td id=\"T_61751_row6_col1\" class=\"data row6 col1\" >0</td>\n",
              "      <td id=\"T_61751_row6_col2\" class=\"data row6 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row6_col3\" class=\"data row6 col3\" >2</td>\n",
              "      <td id=\"T_61751_row6_col4\" class=\"data row6 col4\" >0.000000</td>\n",
              "      <td id=\"T_61751_row6_col5\" class=\"data row6 col5\" >1.000000</td>\n",
              "      <td id=\"T_61751_row6_col6\" class=\"data row6 col6\" >0.000000</td>\n",
              "      <td id=\"T_61751_row6_col7\" class=\"data row6 col7\" >0.495233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row7\" class=\"row_heading level0 row7\" >Age_pca_comb</th>\n",
              "      <td id=\"T_61751_row7_col0\" class=\"data row7 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row7_col1\" class=\"data row7 col1\" >0</td>\n",
              "      <td id=\"T_61751_row7_col2\" class=\"data row7 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row7_col3\" class=\"data row7 col3\" >77</td>\n",
              "      <td id=\"T_61751_row7_col4\" class=\"data row7 col4\" >-5.199338</td>\n",
              "      <td id=\"T_61751_row7_col5\" class=\"data row7 col5\" >5.199338</td>\n",
              "      <td id=\"T_61751_row7_col6\" class=\"data row7 col6\" >0.005018</td>\n",
              "      <td id=\"T_61751_row7_col7\" class=\"data row7 col7\" >-0.004464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row8\" class=\"row_heading level0 row8\" >CreditScore_unimp_cluster_WOE</th>\n",
              "      <td id=\"T_61751_row8_col0\" class=\"data row8 col0\" >int64</td>\n",
              "      <td id=\"T_61751_row8_col1\" class=\"data row8 col1\" >0</td>\n",
              "      <td id=\"T_61751_row8_col2\" class=\"data row8 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row8_col3\" class=\"data row8 col3\" >10</td>\n",
              "      <td id=\"T_61751_row8_col4\" class=\"data row8 col4\" >0.000000</td>\n",
              "      <td id=\"T_61751_row8_col5\" class=\"data row8 col5\" >9.000000</td>\n",
              "      <td id=\"T_61751_row8_col6\" class=\"data row8 col6\" >5.000000</td>\n",
              "      <td id=\"T_61751_row8_col7\" class=\"data row8 col7\" >4.155922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row9\" class=\"row_heading level0 row9\" >Age-NumOfProducts_cat_count</th>\n",
              "      <td id=\"T_61751_row9_col0\" class=\"data row9 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row9_col1\" class=\"data row9 col1\" >0</td>\n",
              "      <td id=\"T_61751_row9_col2\" class=\"data row9 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row9_col3\" class=\"data row9 col3\" >201</td>\n",
              "      <td id=\"T_61751_row9_col4\" class=\"data row9 col4\" >-5.199338</td>\n",
              "      <td id=\"T_61751_row9_col5\" class=\"data row9 col5\" >5.199338</td>\n",
              "      <td id=\"T_61751_row9_col6\" class=\"data row9 col6\" >0.001255</td>\n",
              "      <td id=\"T_61751_row9_col7\" class=\"data row9 col7\" >-0.003742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row10\" class=\"row_heading level0 row10\" >bs_nop</th>\n",
              "      <td id=\"T_61751_row10_col0\" class=\"data row10 col0\" >int64</td>\n",
              "      <td id=\"T_61751_row10_col1\" class=\"data row10 col1\" >0</td>\n",
              "      <td id=\"T_61751_row10_col2\" class=\"data row10 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row10_col3\" class=\"data row10 col3\" >5</td>\n",
              "      <td id=\"T_61751_row10_col4\" class=\"data row10 col4\" >0.000000</td>\n",
              "      <td id=\"T_61751_row10_col5\" class=\"data row10 col5\" >4.000000</td>\n",
              "      <td id=\"T_61751_row10_col6\" class=\"data row10 col6\" >2.000000</td>\n",
              "      <td id=\"T_61751_row10_col7\" class=\"data row10 col7\" >1.720240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row11\" class=\"row_heading level0 row11\" >Geography_count_label-NumOfProducts_cat_count</th>\n",
              "      <td id=\"T_61751_row11_col0\" class=\"data row11 col0\" >int64</td>\n",
              "      <td id=\"T_61751_row11_col1\" class=\"data row11 col1\" >0</td>\n",
              "      <td id=\"T_61751_row11_col2\" class=\"data row11 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row11_col3\" class=\"data row11 col3\" >9</td>\n",
              "      <td id=\"T_61751_row11_col4\" class=\"data row11 col4\" >-84291.000000</td>\n",
              "      <td id=\"T_61751_row11_col5\" class=\"data row11 col5\" >-3367.000000</td>\n",
              "      <td id=\"T_61751_row11_col6\" class=\"data row11 col6\" >-84289.000000</td>\n",
              "      <td id=\"T_61751_row11_col7\" class=\"data row11 col7\" >-79490.626205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row12\" class=\"row_heading level0 row12\" >act_age_enc</th>\n",
              "      <td id=\"T_61751_row12_col0\" class=\"data row12 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row12_col1\" class=\"data row12 col1\" >0</td>\n",
              "      <td id=\"T_61751_row12_col2\" class=\"data row12 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row12_col3\" class=\"data row12 col3\" >110021</td>\n",
              "      <td id=\"T_61751_row12_col4\" class=\"data row12 col4\" >-5.199338</td>\n",
              "      <td id=\"T_61751_row12_col5\" class=\"data row12 col5\" >4.627085</td>\n",
              "      <td id=\"T_61751_row12_col6\" class=\"data row12 col6\" >-0.001990</td>\n",
              "      <td id=\"T_61751_row12_col7\" class=\"data row12 col7\" >0.000558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row13\" class=\"row_heading level0 row13\" >act_age</th>\n",
              "      <td id=\"T_61751_row13_col0\" class=\"data row13 col0\" >int64</td>\n",
              "      <td id=\"T_61751_row13_col1\" class=\"data row13 col1\" >0</td>\n",
              "      <td id=\"T_61751_row13_col2\" class=\"data row13 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row13_col3\" class=\"data row13 col3\" >12</td>\n",
              "      <td id=\"T_61751_row13_col4\" class=\"data row13 col4\" >0.000000</td>\n",
              "      <td id=\"T_61751_row13_col5\" class=\"data row13 col5\" >11.000000</td>\n",
              "      <td id=\"T_61751_row13_col6\" class=\"data row13 col6\" >5.000000</td>\n",
              "      <td id=\"T_61751_row13_col7\" class=\"data row13 col7\" >4.150050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row14\" class=\"row_heading level0 row14\" >Age_cat*NumOfProducts_cat_count_label</th>\n",
              "      <td id=\"T_61751_row14_col0\" class=\"data row14 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row14_col1\" class=\"data row14 col1\" >0</td>\n",
              "      <td id=\"T_61751_row14_col2\" class=\"data row14 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row14_col3\" class=\"data row14 col3\" >113</td>\n",
              "      <td id=\"T_61751_row14_col4\" class=\"data row14 col4\" >-5.199338</td>\n",
              "      <td id=\"T_61751_row14_col5\" class=\"data row14 col5\" >5.199338</td>\n",
              "      <td id=\"T_61751_row14_col6\" class=\"data row14 col6\" >-5.199338</td>\n",
              "      <td id=\"T_61751_row14_col7\" class=\"data row14 col7\" >-2.268222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row15\" class=\"row_heading level0 row15\" >CustomerId</th>\n",
              "      <td id=\"T_61751_row15_col0\" class=\"data row15 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row15_col1\" class=\"data row15 col1\" >0</td>\n",
              "      <td id=\"T_61751_row15_col2\" class=\"data row15 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row15_col3\" class=\"data row15 col3\" >19698</td>\n",
              "      <td id=\"T_61751_row15_col4\" class=\"data row15 col4\" >15565701.000000</td>\n",
              "      <td id=\"T_61751_row15_col5\" class=\"data row15 col5\" >15815690.000000</td>\n",
              "      <td id=\"T_61751_row15_col6\" class=\"data row15 col6\" >15690175.000000</td>\n",
              "      <td id=\"T_61751_row15_col7\" class=\"data row15 col7\" >15692096.605101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row16\" class=\"row_heading level0 row16\" >Geography_count/NumOfProducts_cat_count_label</th>\n",
              "      <td id=\"T_61751_row16_col0\" class=\"data row16 col0\" >int64</td>\n",
              "      <td id=\"T_61751_row16_col1\" class=\"data row16 col1\" >0</td>\n",
              "      <td id=\"T_61751_row16_col2\" class=\"data row16 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row16_col3\" class=\"data row16 col3\" >5</td>\n",
              "      <td id=\"T_61751_row16_col4\" class=\"data row16 col4\" >-5.000000</td>\n",
              "      <td id=\"T_61751_row16_col5\" class=\"data row16 col5\" >1.000000</td>\n",
              "      <td id=\"T_61751_row16_col6\" class=\"data row16 col6\" >0.000000</td>\n",
              "      <td id=\"T_61751_row16_col7\" class=\"data row16 col7\" >0.152459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row17\" class=\"row_heading level0 row17\" >IsActiveMember_enc</th>\n",
              "      <td id=\"T_61751_row17_col0\" class=\"data row17 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row17_col1\" class=\"data row17 col1\" >0</td>\n",
              "      <td id=\"T_61751_row17_col2\" class=\"data row17 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row17_col3\" class=\"data row17 col3\" >110023</td>\n",
              "      <td id=\"T_61751_row17_col4\" class=\"data row17 col4\" >-3.596265</td>\n",
              "      <td id=\"T_61751_row17_col5\" class=\"data row17 col5\" >3.399017</td>\n",
              "      <td id=\"T_61751_row17_col6\" class=\"data row17 col6\" >0.006635</td>\n",
              "      <td id=\"T_61751_row17_col7\" class=\"data row17 col7\" >0.007000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row18\" class=\"row_heading level0 row18\" >CreditScore_cat_pca_comb_final</th>\n",
              "      <td id=\"T_61751_row18_col0\" class=\"data row18 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row18_col1\" class=\"data row18 col1\" >0</td>\n",
              "      <td id=\"T_61751_row18_col2\" class=\"data row18 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row18_col3\" class=\"data row18 col3\" >454</td>\n",
              "      <td id=\"T_61751_row18_col4\" class=\"data row18 col4\" >-7.655587</td>\n",
              "      <td id=\"T_61751_row18_col5\" class=\"data row18 col5\" >14.763312</td>\n",
              "      <td id=\"T_61751_row18_col6\" class=\"data row18 col6\" >-0.164846</td>\n",
              "      <td id=\"T_61751_row18_col7\" class=\"data row18 col7\" >-0.001014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row19\" class=\"row_heading level0 row19\" >bs_active</th>\n",
              "      <td id=\"T_61751_row19_col0\" class=\"data row19 col0\" >int64</td>\n",
              "      <td id=\"T_61751_row19_col1\" class=\"data row19 col1\" >0</td>\n",
              "      <td id=\"T_61751_row19_col2\" class=\"data row19 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row19_col3\" class=\"data row19 col3\" >4</td>\n",
              "      <td id=\"T_61751_row19_col4\" class=\"data row19 col4\" >0.000000</td>\n",
              "      <td id=\"T_61751_row19_col5\" class=\"data row19 col5\" >3.000000</td>\n",
              "      <td id=\"T_61751_row19_col6\" class=\"data row19 col6\" >2.000000</td>\n",
              "      <td id=\"T_61751_row19_col7\" class=\"data row19 col7\" >1.645774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row20\" class=\"row_heading level0 row20\" >Age_pca_comb_pca_comb_final</th>\n",
              "      <td id=\"T_61751_row20_col0\" class=\"data row20 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row20_col1\" class=\"data row20 col1\" >0</td>\n",
              "      <td id=\"T_61751_row20_col2\" class=\"data row20 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row20_col3\" class=\"data row20 col3\" >77</td>\n",
              "      <td id=\"T_61751_row20_col4\" class=\"data row20 col4\" >-1.898036</td>\n",
              "      <td id=\"T_61751_row20_col5\" class=\"data row20 col5\" >8.175671</td>\n",
              "      <td id=\"T_61751_row20_col6\" class=\"data row20 col6\" >-0.768477</td>\n",
              "      <td id=\"T_61751_row20_col7\" class=\"data row20 col7\" >0.001694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row21\" class=\"row_heading level0 row21\" >Balance_Range</th>\n",
              "      <td id=\"T_61751_row21_col0\" class=\"data row21 col0\" >int64</td>\n",
              "      <td id=\"T_61751_row21_col1\" class=\"data row21 col1\" >0</td>\n",
              "      <td id=\"T_61751_row21_col2\" class=\"data row21 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row21_col3\" class=\"data row21 col3\" >5</td>\n",
              "      <td id=\"T_61751_row21_col4\" class=\"data row21 col4\" >0.000000</td>\n",
              "      <td id=\"T_61751_row21_col5\" class=\"data row21 col5\" >4.000000</td>\n",
              "      <td id=\"T_61751_row21_col6\" class=\"data row21 col6\" >0.000000</td>\n",
              "      <td id=\"T_61751_row21_col7\" class=\"data row21 col7\" >1.078811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row22\" class=\"row_heading level0 row22\" >bs_gender_enc</th>\n",
              "      <td id=\"T_61751_row22_col0\" class=\"data row22 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row22_col1\" class=\"data row22 col1\" >0</td>\n",
              "      <td id=\"T_61751_row22_col2\" class=\"data row22 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row22_col3\" class=\"data row22 col3\" >110019</td>\n",
              "      <td id=\"T_61751_row22_col4\" class=\"data row22 col4\" >-5.199338</td>\n",
              "      <td id=\"T_61751_row22_col5\" class=\"data row22 col5\" >5.199338</td>\n",
              "      <td id=\"T_61751_row22_col6\" class=\"data row22 col6\" >0.005794</td>\n",
              "      <td id=\"T_61751_row22_col7\" class=\"data row22 col7\" >0.001423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row23\" class=\"row_heading level0 row23\" >quant_EstimatedSalary</th>\n",
              "      <td id=\"T_61751_row23_col0\" class=\"data row23 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row23_col1\" class=\"data row23 col1\" >0</td>\n",
              "      <td id=\"T_61751_row23_col2\" class=\"data row23 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row23_col3\" class=\"data row23 col3\" >41670</td>\n",
              "      <td id=\"T_61751_row23_col4\" class=\"data row23 col4\" >-5.199338</td>\n",
              "      <td id=\"T_61751_row23_col5\" class=\"data row23 col5\" >5.199338</td>\n",
              "      <td id=\"T_61751_row23_col6\" class=\"data row23 col6\" >-0.003770</td>\n",
              "      <td id=\"T_61751_row23_col7\" class=\"data row23 col7\" >-0.002169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row24\" class=\"row_heading level0 row24\" >Surname_tfidf_2</th>\n",
              "      <td id=\"T_61751_row24_col0\" class=\"data row24 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row24_col1\" class=\"data row24 col1\" >0</td>\n",
              "      <td id=\"T_61751_row24_col2\" class=\"data row24 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row24_col3\" class=\"data row24 col3\" >1006</td>\n",
              "      <td id=\"T_61751_row24_col4\" class=\"data row24 col4\" >-5.199338</td>\n",
              "      <td id=\"T_61751_row24_col5\" class=\"data row24 col5\" >5.199338</td>\n",
              "      <td id=\"T_61751_row24_col6\" class=\"data row24 col6\" >0.062770</td>\n",
              "      <td id=\"T_61751_row24_col7\" class=\"data row24 col7\" >0.021045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row25\" class=\"row_heading level0 row25\" >bs_nop_count</th>\n",
              "      <td id=\"T_61751_row25_col0\" class=\"data row25 col0\" >int64</td>\n",
              "      <td id=\"T_61751_row25_col1\" class=\"data row25 col1\" >0</td>\n",
              "      <td id=\"T_61751_row25_col2\" class=\"data row25 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row25_col3\" class=\"data row25 col3\" >5</td>\n",
              "      <td id=\"T_61751_row25_col4\" class=\"data row25 col4\" >3369.000000</td>\n",
              "      <td id=\"T_61751_row25_col5\" class=\"data row25 col5\" >64815.000000</td>\n",
              "      <td id=\"T_61751_row25_col6\" class=\"data row25 col6\" >49112.000000</td>\n",
              "      <td id=\"T_61751_row25_col7\" class=\"data row25 col7\" >47364.233733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row26\" class=\"row_heading level0 row26\" >Surname_tfidf_3</th>\n",
              "      <td id=\"T_61751_row26_col0\" class=\"data row26 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row26_col1\" class=\"data row26 col1\" >0</td>\n",
              "      <td id=\"T_61751_row26_col2\" class=\"data row26 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row26_col3\" class=\"data row26 col3\" >1006</td>\n",
              "      <td id=\"T_61751_row26_col4\" class=\"data row26 col4\" >-5.199338</td>\n",
              "      <td id=\"T_61751_row26_col5\" class=\"data row26 col5\" >5.199338</td>\n",
              "      <td id=\"T_61751_row26_col6\" class=\"data row26 col6\" >-0.023839</td>\n",
              "      <td id=\"T_61751_row26_col7\" class=\"data row26 col7\" >0.001535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row27\" class=\"row_heading level0 row27\" >Gender_enc</th>\n",
              "      <td id=\"T_61751_row27_col0\" class=\"data row27 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row27_col1\" class=\"data row27 col1\" >0</td>\n",
              "      <td id=\"T_61751_row27_col2\" class=\"data row27 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row27_col3\" class=\"data row27 col3\" >110023</td>\n",
              "      <td id=\"T_61751_row27_col4\" class=\"data row27 col4\" >-5.199338</td>\n",
              "      <td id=\"T_61751_row27_col5\" class=\"data row27 col5\" >3.842937</td>\n",
              "      <td id=\"T_61751_row27_col6\" class=\"data row27 col6\" >-0.000937</td>\n",
              "      <td id=\"T_61751_row27_col7\" class=\"data row27 col7\" >0.000170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row28\" class=\"row_heading level0 row28\" >Tenure_enc</th>\n",
              "      <td id=\"T_61751_row28_col0\" class=\"data row28 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row28_col1\" class=\"data row28 col1\" >0</td>\n",
              "      <td id=\"T_61751_row28_col2\" class=\"data row28 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row28_col3\" class=\"data row28 col3\" >110023</td>\n",
              "      <td id=\"T_61751_row28_col4\" class=\"data row28 col4\" >-3.487055</td>\n",
              "      <td id=\"T_61751_row28_col5\" class=\"data row28 col5\" >3.662207</td>\n",
              "      <td id=\"T_61751_row28_col6\" class=\"data row28 col6\" >0.007725</td>\n",
              "      <td id=\"T_61751_row28_col7\" class=\"data row28 col7\" >0.008132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row29\" class=\"row_heading level0 row29\" >Balance_Range_enc</th>\n",
              "      <td id=\"T_61751_row29_col0\" class=\"data row29 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row29_col1\" class=\"data row29 col1\" >0</td>\n",
              "      <td id=\"T_61751_row29_col2\" class=\"data row29 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row29_col3\" class=\"data row29 col3\" >110022</td>\n",
              "      <td id=\"T_61751_row29_col4\" class=\"data row29 col4\" >-3.930617</td>\n",
              "      <td id=\"T_61751_row29_col5\" class=\"data row29 col5\" >5.199338</td>\n",
              "      <td id=\"T_61751_row29_col6\" class=\"data row29 col6\" >0.002520</td>\n",
              "      <td id=\"T_61751_row29_col7\" class=\"data row29 col7\" >-0.000323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row30\" class=\"row_heading level0 row30\" >Surname_tfidf_4</th>\n",
              "      <td id=\"T_61751_row30_col0\" class=\"data row30 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row30_col1\" class=\"data row30 col1\" >0</td>\n",
              "      <td id=\"T_61751_row30_col2\" class=\"data row30 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row30_col3\" class=\"data row30 col3\" >1006</td>\n",
              "      <td id=\"T_61751_row30_col4\" class=\"data row30 col4\" >-5.199338</td>\n",
              "      <td id=\"T_61751_row30_col5\" class=\"data row30 col5\" >5.199338</td>\n",
              "      <td id=\"T_61751_row30_col6\" class=\"data row30 col6\" >-0.026349</td>\n",
              "      <td id=\"T_61751_row30_col7\" class=\"data row30 col7\" >-0.000579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row31\" class=\"row_heading level0 row31\" >Balance-NumOfProducts_cat_count_label</th>\n",
              "      <td id=\"T_61751_row31_col0\" class=\"data row31 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row31_col1\" class=\"data row31 col1\" >0</td>\n",
              "      <td id=\"T_61751_row31_col2\" class=\"data row31 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row31_col3\" class=\"data row31 col3\" >27445</td>\n",
              "      <td id=\"T_61751_row31_col4\" class=\"data row31 col4\" >-5.199338</td>\n",
              "      <td id=\"T_61751_row31_col5\" class=\"data row31 col5\" >5.199338</td>\n",
              "      <td id=\"T_61751_row31_col6\" class=\"data row31 col6\" >0.469603</td>\n",
              "      <td id=\"T_61751_row31_col7\" class=\"data row31 col7\" >-0.020506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row32\" class=\"row_heading level0 row32\" >Geo_Gender_enc</th>\n",
              "      <td id=\"T_61751_row32_col0\" class=\"data row32 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row32_col1\" class=\"data row32 col1\" >0</td>\n",
              "      <td id=\"T_61751_row32_col2\" class=\"data row32 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row32_col3\" class=\"data row32 col3\" >110022</td>\n",
              "      <td id=\"T_61751_row32_col4\" class=\"data row32 col4\" >-5.199338</td>\n",
              "      <td id=\"T_61751_row32_col5\" class=\"data row32 col5\" >5.199338</td>\n",
              "      <td id=\"T_61751_row32_col6\" class=\"data row32 col6\" >-0.000077</td>\n",
              "      <td id=\"T_61751_row32_col7\" class=\"data row32 col7\" >0.003368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row33\" class=\"row_heading level0 row33\" >Balance_pca_comb</th>\n",
              "      <td id=\"T_61751_row33_col0\" class=\"data row33 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row33_col1\" class=\"data row33 col1\" >0</td>\n",
              "      <td id=\"T_61751_row33_col2\" class=\"data row33 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row33_col3\" class=\"data row33 col3\" >22513</td>\n",
              "      <td id=\"T_61751_row33_col4\" class=\"data row33 col4\" >-5.199338</td>\n",
              "      <td id=\"T_61751_row33_col5\" class=\"data row33 col5\" >5.199338</td>\n",
              "      <td id=\"T_61751_row33_col6\" class=\"data row33 col6\" >5.199338</td>\n",
              "      <td id=\"T_61751_row33_col7\" class=\"data row33 col7\" >2.431563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row34\" class=\"row_heading level0 row34\" >NumOfProducts_cat_count</th>\n",
              "      <td id=\"T_61751_row34_col0\" class=\"data row34 col0\" >int64</td>\n",
              "      <td id=\"T_61751_row34_col1\" class=\"data row34 col1\" >0</td>\n",
              "      <td id=\"T_61751_row34_col2\" class=\"data row34 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row34_col3\" class=\"data row34 col3\" >3</td>\n",
              "      <td id=\"T_61751_row34_col4\" class=\"data row34 col4\" >3369.000000</td>\n",
              "      <td id=\"T_61751_row34_col5\" class=\"data row34 col5\" >84291.000000</td>\n",
              "      <td id=\"T_61751_row34_col6\" class=\"data row34 col6\" >84291.000000</td>\n",
              "      <td id=\"T_61751_row34_col7\" class=\"data row34 col7\" >79491.260536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row35\" class=\"row_heading level0 row35\" >Balance_Salary</th>\n",
              "      <td id=\"T_61751_row35_col0\" class=\"data row35 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row35_col1\" class=\"data row35 col1\" >0</td>\n",
              "      <td id=\"T_61751_row35_col2\" class=\"data row35 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row35_col3\" class=\"data row35 col3\" >69622</td>\n",
              "      <td id=\"T_61751_row35_col4\" class=\"data row35 col4\" >-4.682787</td>\n",
              "      <td id=\"T_61751_row35_col5\" class=\"data row35 col5\" >5.199338</td>\n",
              "      <td id=\"T_61751_row35_col6\" class=\"data row35 col6\" >-0.001255</td>\n",
              "      <td id=\"T_61751_row35_col7\" class=\"data row35 col7\" >-0.005758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row36\" class=\"row_heading level0 row36\" >bs_active_enc</th>\n",
              "      <td id=\"T_61751_row36_col0\" class=\"data row36 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row36_col1\" class=\"data row36 col1\" >0</td>\n",
              "      <td id=\"T_61751_row36_col2\" class=\"data row36 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row36_col3\" class=\"data row36 col3\" >110016</td>\n",
              "      <td id=\"T_61751_row36_col4\" class=\"data row36 col4\" >-5.199338</td>\n",
              "      <td id=\"T_61751_row36_col5\" class=\"data row36 col5\" >5.199338</td>\n",
              "      <td id=\"T_61751_row36_col6\" class=\"data row36 col6\" >0.007042</td>\n",
              "      <td id=\"T_61751_row36_col7\" class=\"data row36 col7\" >0.005359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row37\" class=\"row_heading level0 row37\" >act_nop_enc</th>\n",
              "      <td id=\"T_61751_row37_col0\" class=\"data row37 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row37_col1\" class=\"data row37 col1\" >0</td>\n",
              "      <td id=\"T_61751_row37_col2\" class=\"data row37 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row37_col3\" class=\"data row37 col3\" >110023</td>\n",
              "      <td id=\"T_61751_row37_col4\" class=\"data row37 col4\" >-4.086504</td>\n",
              "      <td id=\"T_61751_row37_col5\" class=\"data row37 col5\" >3.522748</td>\n",
              "      <td id=\"T_61751_row37_col6\" class=\"data row37 col6\" >0.001006</td>\n",
              "      <td id=\"T_61751_row37_col7\" class=\"data row37 col7\" >0.003182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row38\" class=\"row_heading level0 row38\" >CreditScore_pca_comb_final</th>\n",
              "      <td id=\"T_61751_row38_col0\" class=\"data row38 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row38_col1\" class=\"data row38 col1\" >0</td>\n",
              "      <td id=\"T_61751_row38_col2\" class=\"data row38 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row38_col3\" class=\"data row38 col3\" >457</td>\n",
              "      <td id=\"T_61751_row38_col4\" class=\"data row38 col4\" >-8.965207</td>\n",
              "      <td id=\"T_61751_row38_col5\" class=\"data row38 col5\" >17.833923</td>\n",
              "      <td id=\"T_61751_row38_col6\" class=\"data row38 col6\" >-0.542647</td>\n",
              "      <td id=\"T_61751_row38_col7\" class=\"data row38 col7\" >0.020237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row39\" class=\"row_heading level0 row39\" >Balance_Range_count</th>\n",
              "      <td id=\"T_61751_row39_col0\" class=\"data row39 col0\" >int64</td>\n",
              "      <td id=\"T_61751_row39_col1\" class=\"data row39 col1\" >0</td>\n",
              "      <td id=\"T_61751_row39_col2\" class=\"data row39 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row39_col3\" class=\"data row39 col3\" >5</td>\n",
              "      <td id=\"T_61751_row39_col4\" class=\"data row39 col4\" >8974.000000</td>\n",
              "      <td id=\"T_61751_row39_col5\" class=\"data row39 col5\" >89648.000000</td>\n",
              "      <td id=\"T_61751_row39_col6\" class=\"data row39 col6\" >89648.000000</td>\n",
              "      <td id=\"T_61751_row39_col7\" class=\"data row39 col7\" >58739.097807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row40\" class=\"row_heading level0 row40\" >Surname_tfidf_0</th>\n",
              "      <td id=\"T_61751_row40_col0\" class=\"data row40 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row40_col1\" class=\"data row40 col1\" >0</td>\n",
              "      <td id=\"T_61751_row40_col2\" class=\"data row40 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row40_col3\" class=\"data row40 col3\" >1006</td>\n",
              "      <td id=\"T_61751_row40_col4\" class=\"data row40 col4\" >-5.199338</td>\n",
              "      <td id=\"T_61751_row40_col5\" class=\"data row40 col5\" >5.199338</td>\n",
              "      <td id=\"T_61751_row40_col6\" class=\"data row40 col6\" >0.001255</td>\n",
              "      <td id=\"T_61751_row40_col7\" class=\"data row40 col7\" >-0.003766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row41\" class=\"row_heading level0 row41\" >HasCrCard_enc</th>\n",
              "      <td id=\"T_61751_row41_col0\" class=\"data row41 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row41_col1\" class=\"data row41 col1\" >0</td>\n",
              "      <td id=\"T_61751_row41_col2\" class=\"data row41 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row41_col3\" class=\"data row41 col3\" >110022</td>\n",
              "      <td id=\"T_61751_row41_col4\" class=\"data row41 col4\" >-3.548503</td>\n",
              "      <td id=\"T_61751_row41_col5\" class=\"data row41 col5\" >5.199338</td>\n",
              "      <td id=\"T_61751_row41_col6\" class=\"data row41 col6\" >-0.000772</td>\n",
              "      <td id=\"T_61751_row41_col7\" class=\"data row41 col7\" >-0.005123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_61751_level0_row42\" class=\"row_heading level0 row42\" >bs_age_enc</th>\n",
              "      <td id=\"T_61751_row42_col0\" class=\"data row42 col0\" >float64</td>\n",
              "      <td id=\"T_61751_row42_col1\" class=\"data row42 col1\" >0</td>\n",
              "      <td id=\"T_61751_row42_col2\" class=\"data row42 col2\" >0.000000</td>\n",
              "      <td id=\"T_61751_row42_col3\" class=\"data row42 col3\" >110021</td>\n",
              "      <td id=\"T_61751_row42_col4\" class=\"data row42 col4\" >-3.606214</td>\n",
              "      <td id=\"T_61751_row42_col5\" class=\"data row42 col5\" >5.199338</td>\n",
              "      <td id=\"T_61751_row42_col6\" class=\"data row42 col6\" >0.002751</td>\n",
              "      <td id=\"T_61751_row42_col7\" class=\"data row42 col7\" >0.000097</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.0 Dataset Manager:**\n"
      ],
      "metadata": {
        "id": "eZhnYFq19bsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strat_feature = train[\"Exited\"]\n",
        "\n",
        "X=train.drop(columns=[\"Exited\"]).copy()\n",
        "y=train[\"Exited\"].copy()\n",
        "X_test=test.copy()\n",
        "\n",
        "X.shape[1]==X_test.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ7ku_W7_TOA",
        "outputId": "f71dceed-19a3-433e-f2cd-231cd204ad21"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_var = X.select_dtypes(\"float\").columns\n",
        "list_to_stand = [name for name in num_var if X[name].nunique()>25]\n",
        "\n",
        "scaler = QuantileTransformer(subsample=50_000, output_distribution=\"normal\",random_state=42)\n",
        "\n",
        "X[list_to_stand] = scaler.fit_transform(X[list_to_stand])\n",
        "X_test[list_to_stand] = scaler.transform(X_test[list_to_stand])"
      ],
      "metadata": {
        "id": "LpdE-Dz3AgQA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(X.select_dtypes(\"int\")).style.background_gradient(cmap='Reds')"
      ],
      "metadata": {
        "id": "1VKF5XrT9hm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "2ad7898e-8c86-47a6-c814-132aa2124223"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data shape: (165034, 14)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fae8f935f60>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_08128_row0_col1, #T_08128_row0_col2, #T_08128_row1_col1, #T_08128_row1_col2, #T_08128_row2_col1, #T_08128_row2_col2, #T_08128_row2_col3, #T_08128_row3_col1, #T_08128_row3_col2, #T_08128_row3_col3, #T_08128_row4_col1, #T_08128_row4_col2, #T_08128_row5_col1, #T_08128_row5_col2, #T_08128_row6_col1, #T_08128_row6_col2, #T_08128_row6_col4, #T_08128_row6_col5, #T_08128_row6_col6, #T_08128_row6_col7, #T_08128_row7_col1, #T_08128_row7_col2, #T_08128_row8_col1, #T_08128_row8_col2, #T_08128_row9_col1, #T_08128_row9_col2, #T_08128_row10_col1, #T_08128_row10_col2, #T_08128_row11_col1, #T_08128_row11_col2, #T_08128_row12_col1, #T_08128_row12_col2, #T_08128_row13_col1, #T_08128_row13_col2 {\n",
              "  background-color: #fff5f0;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_08128_row0_col3, #T_08128_row1_col3, #T_08128_row5_col3, #T_08128_row8_col3, #T_08128_row10_col3, #T_08128_row11_col3, #T_08128_row13_col3 {\n",
              "  background-color: #fcab8f;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_08128_row0_col4, #T_08128_row1_col4, #T_08128_row2_col4, #T_08128_row3_col4, #T_08128_row4_col4, #T_08128_row5_col4, #T_08128_row7_col4, #T_08128_row8_col4, #T_08128_row9_col4, #T_08128_row10_col4 {\n",
              "  background-color: #960b13;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_08128_row0_col5, #T_08128_row1_col5, #T_08128_row2_col5, #T_08128_row3_col5, #T_08128_row4_col5, #T_08128_row5_col5, #T_08128_row7_col5, #T_08128_row8_col5, #T_08128_row9_col5, #T_08128_row10_col5 {\n",
              "  background-color: #ffefe8;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_08128_row0_col6, #T_08128_row1_col6, #T_08128_row2_col6, #T_08128_row3_col6, #T_08128_row4_col6, #T_08128_row5_col6, #T_08128_row7_col6, #T_08128_row8_col6, #T_08128_row9_col6, #T_08128_row10_col6 {\n",
              "  background-color: #fb6e4e;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_08128_row0_col7, #T_08128_row1_col7, #T_08128_row2_col7, #T_08128_row3_col7, #T_08128_row4_col7, #T_08128_row5_col7, #T_08128_row7_col7, #T_08128_row9_col7, #T_08128_row10_col7 {\n",
              "  background-color: #fb694a;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_08128_row4_col3, #T_08128_row11_col7 {\n",
              "  background-color: #bc141a;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_08128_row6_col3 {\n",
              "  background-color: #d92523;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_08128_row7_col3, #T_08128_row12_col7, #T_08128_row13_col4, #T_08128_row13_col5, #T_08128_row13_col6 {\n",
              "  background-color: #67000d;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_08128_row8_col7 {\n",
              "  background-color: #fb6b4b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_08128_row9_col3 {\n",
              "  background-color: #fdcab5;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_08128_row11_col4, #T_08128_row12_col4 {\n",
              "  background-color: #840711;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_08128_row11_col5 {\n",
              "  background-color: #d01d1f;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_08128_row11_col6 {\n",
              "  background-color: #c5171c;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_08128_row12_col3 {\n",
              "  background-color: #fee5d8;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_08128_row12_col5 {\n",
              "  background-color: #820711;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_08128_row12_col6 {\n",
              "  background-color: #75030f;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_08128_row13_col7 {\n",
              "  background-color: #a60f15;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_08128\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_08128_level0_col0\" class=\"col_heading level0 col0\" >data type</th>\n",
              "      <th id=\"T_08128_level0_col1\" class=\"col_heading level0 col1\" >#missing</th>\n",
              "      <th id=\"T_08128_level0_col2\" class=\"col_heading level0 col2\" >%missing</th>\n",
              "      <th id=\"T_08128_level0_col3\" class=\"col_heading level0 col3\" >#unique</th>\n",
              "      <th id=\"T_08128_level0_col4\" class=\"col_heading level0 col4\" >min</th>\n",
              "      <th id=\"T_08128_level0_col5\" class=\"col_heading level0 col5\" >max</th>\n",
              "      <th id=\"T_08128_level0_col6\" class=\"col_heading level0 col6\" >median</th>\n",
              "      <th id=\"T_08128_level0_col7\" class=\"col_heading level0 col7\" >mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_08128_level0_row0\" class=\"row_heading level0 row0\" >act_nop</th>\n",
              "      <td id=\"T_08128_row0_col0\" class=\"data row0 col0\" >int64</td>\n",
              "      <td id=\"T_08128_row0_col1\" class=\"data row0 col1\" >0</td>\n",
              "      <td id=\"T_08128_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
              "      <td id=\"T_08128_row0_col3\" class=\"data row0 col3\" >5</td>\n",
              "      <td id=\"T_08128_row0_col4\" class=\"data row0 col4\" >0.000000</td>\n",
              "      <td id=\"T_08128_row0_col5\" class=\"data row0 col5\" >4.000000</td>\n",
              "      <td id=\"T_08128_row0_col6\" class=\"data row0 col6\" >2.000000</td>\n",
              "      <td id=\"T_08128_row0_col7\" class=\"data row0 col7\" >1.574748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_08128_level0_row1\" class=\"row_heading level0 row1\" >bs_nop_count_label</th>\n",
              "      <td id=\"T_08128_row1_col0\" class=\"data row1 col0\" >int64</td>\n",
              "      <td id=\"T_08128_row1_col1\" class=\"data row1 col1\" >0</td>\n",
              "      <td id=\"T_08128_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
              "      <td id=\"T_08128_row1_col3\" class=\"data row1 col3\" >5</td>\n",
              "      <td id=\"T_08128_row1_col4\" class=\"data row1 col4\" >0.000000</td>\n",
              "      <td id=\"T_08128_row1_col5\" class=\"data row1 col5\" >4.000000</td>\n",
              "      <td id=\"T_08128_row1_col6\" class=\"data row1 col6\" >1.000000</td>\n",
              "      <td id=\"T_08128_row1_col7\" class=\"data row1 col7\" >1.075778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_08128_level0_row2\" class=\"row_heading level0 row2\" >HasCrCard</th>\n",
              "      <td id=\"T_08128_row2_col0\" class=\"data row2 col0\" >int64</td>\n",
              "      <td id=\"T_08128_row2_col1\" class=\"data row2 col1\" >0</td>\n",
              "      <td id=\"T_08128_row2_col2\" class=\"data row2 col2\" >0.000000</td>\n",
              "      <td id=\"T_08128_row2_col3\" class=\"data row2 col3\" >2</td>\n",
              "      <td id=\"T_08128_row2_col4\" class=\"data row2 col4\" >0.000000</td>\n",
              "      <td id=\"T_08128_row2_col5\" class=\"data row2 col5\" >1.000000</td>\n",
              "      <td id=\"T_08128_row2_col6\" class=\"data row2 col6\" >1.000000</td>\n",
              "      <td id=\"T_08128_row2_col7\" class=\"data row2 col7\" >0.753954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_08128_level0_row3\" class=\"row_heading level0 row3\" >IsActiveMember</th>\n",
              "      <td id=\"T_08128_row3_col0\" class=\"data row3 col0\" >int64</td>\n",
              "      <td id=\"T_08128_row3_col1\" class=\"data row3 col1\" >0</td>\n",
              "      <td id=\"T_08128_row3_col2\" class=\"data row3 col2\" >0.000000</td>\n",
              "      <td id=\"T_08128_row3_col3\" class=\"data row3 col3\" >2</td>\n",
              "      <td id=\"T_08128_row3_col4\" class=\"data row3 col4\" >0.000000</td>\n",
              "      <td id=\"T_08128_row3_col5\" class=\"data row3 col5\" >1.000000</td>\n",
              "      <td id=\"T_08128_row3_col6\" class=\"data row3 col6\" >0.000000</td>\n",
              "      <td id=\"T_08128_row3_col7\" class=\"data row3 col7\" >0.497770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_08128_level0_row4\" class=\"row_heading level0 row4\" >CreditScore_unimp_cluster_WOE</th>\n",
              "      <td id=\"T_08128_row4_col0\" class=\"data row4 col0\" >int64</td>\n",
              "      <td id=\"T_08128_row4_col1\" class=\"data row4 col1\" >0</td>\n",
              "      <td id=\"T_08128_row4_col2\" class=\"data row4 col2\" >0.000000</td>\n",
              "      <td id=\"T_08128_row4_col3\" class=\"data row4 col3\" >10</td>\n",
              "      <td id=\"T_08128_row4_col4\" class=\"data row4 col4\" >0.000000</td>\n",
              "      <td id=\"T_08128_row4_col5\" class=\"data row4 col5\" >9.000000</td>\n",
              "      <td id=\"T_08128_row4_col6\" class=\"data row4 col6\" >5.000000</td>\n",
              "      <td id=\"T_08128_row4_col7\" class=\"data row4 col7\" >4.177091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_08128_level0_row5\" class=\"row_heading level0 row5\" >bs_nop</th>\n",
              "      <td id=\"T_08128_row5_col0\" class=\"data row5 col0\" >int64</td>\n",
              "      <td id=\"T_08128_row5_col1\" class=\"data row5 col1\" >0</td>\n",
              "      <td id=\"T_08128_row5_col2\" class=\"data row5 col2\" >0.000000</td>\n",
              "      <td id=\"T_08128_row5_col3\" class=\"data row5 col3\" >5</td>\n",
              "      <td id=\"T_08128_row5_col4\" class=\"data row5 col4\" >0.000000</td>\n",
              "      <td id=\"T_08128_row5_col5\" class=\"data row5 col5\" >4.000000</td>\n",
              "      <td id=\"T_08128_row5_col6\" class=\"data row5 col6\" >2.000000</td>\n",
              "      <td id=\"T_08128_row5_col7\" class=\"data row5 col7\" >1.720379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_08128_level0_row6\" class=\"row_heading level0 row6\" >Geography_count_label-NumOfProducts_cat_count</th>\n",
              "      <td id=\"T_08128_row6_col0\" class=\"data row6 col0\" >int64</td>\n",
              "      <td id=\"T_08128_row6_col1\" class=\"data row6 col1\" >0</td>\n",
              "      <td id=\"T_08128_row6_col2\" class=\"data row6 col2\" >0.000000</td>\n",
              "      <td id=\"T_08128_row6_col3\" class=\"data row6 col3\" >9</td>\n",
              "      <td id=\"T_08128_row6_col4\" class=\"data row6 col4\" >-84291.000000</td>\n",
              "      <td id=\"T_08128_row6_col5\" class=\"data row6 col5\" >-3367.000000</td>\n",
              "      <td id=\"T_08128_row6_col6\" class=\"data row6 col6\" >-84289.000000</td>\n",
              "      <td id=\"T_08128_row6_col7\" class=\"data row6 col7\" >-79395.477859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_08128_level0_row7\" class=\"row_heading level0 row7\" >act_age</th>\n",
              "      <td id=\"T_08128_row7_col0\" class=\"data row7 col0\" >int64</td>\n",
              "      <td id=\"T_08128_row7_col1\" class=\"data row7 col1\" >0</td>\n",
              "      <td id=\"T_08128_row7_col2\" class=\"data row7 col2\" >0.000000</td>\n",
              "      <td id=\"T_08128_row7_col3\" class=\"data row7 col3\" >12</td>\n",
              "      <td id=\"T_08128_row7_col4\" class=\"data row7 col4\" >0.000000</td>\n",
              "      <td id=\"T_08128_row7_col5\" class=\"data row7 col5\" >11.000000</td>\n",
              "      <td id=\"T_08128_row7_col6\" class=\"data row7 col6\" >5.000000</td>\n",
              "      <td id=\"T_08128_row7_col7\" class=\"data row7 col7\" >4.166566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_08128_level0_row8\" class=\"row_heading level0 row8\" >Geography_count/NumOfProducts_cat_count_label</th>\n",
              "      <td id=\"T_08128_row8_col0\" class=\"data row8 col0\" >int64</td>\n",
              "      <td id=\"T_08128_row8_col1\" class=\"data row8 col1\" >0</td>\n",
              "      <td id=\"T_08128_row8_col2\" class=\"data row8 col2\" >0.000000</td>\n",
              "      <td id=\"T_08128_row8_col3\" class=\"data row8 col3\" >5</td>\n",
              "      <td id=\"T_08128_row8_col4\" class=\"data row8 col4\" >-5.000000</td>\n",
              "      <td id=\"T_08128_row8_col5\" class=\"data row8 col5\" >1.000000</td>\n",
              "      <td id=\"T_08128_row8_col6\" class=\"data row8 col6\" >0.000000</td>\n",
              "      <td id=\"T_08128_row8_col7\" class=\"data row8 col7\" >0.144946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_08128_level0_row9\" class=\"row_heading level0 row9\" >bs_active</th>\n",
              "      <td id=\"T_08128_row9_col0\" class=\"data row9 col0\" >int64</td>\n",
              "      <td id=\"T_08128_row9_col1\" class=\"data row9 col1\" >0</td>\n",
              "      <td id=\"T_08128_row9_col2\" class=\"data row9 col2\" >0.000000</td>\n",
              "      <td id=\"T_08128_row9_col3\" class=\"data row9 col3\" >4</td>\n",
              "      <td id=\"T_08128_row9_col4\" class=\"data row9 col4\" >0.000000</td>\n",
              "      <td id=\"T_08128_row9_col5\" class=\"data row9 col5\" >3.000000</td>\n",
              "      <td id=\"T_08128_row9_col6\" class=\"data row9 col6\" >2.000000</td>\n",
              "      <td id=\"T_08128_row9_col7\" class=\"data row9 col7\" >1.645522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_08128_level0_row10\" class=\"row_heading level0 row10\" >Balance_Range</th>\n",
              "      <td id=\"T_08128_row10_col0\" class=\"data row10 col0\" >int64</td>\n",
              "      <td id=\"T_08128_row10_col1\" class=\"data row10 col1\" >0</td>\n",
              "      <td id=\"T_08128_row10_col2\" class=\"data row10 col2\" >0.000000</td>\n",
              "      <td id=\"T_08128_row10_col3\" class=\"data row10 col3\" >5</td>\n",
              "      <td id=\"T_08128_row10_col4\" class=\"data row10 col4\" >0.000000</td>\n",
              "      <td id=\"T_08128_row10_col5\" class=\"data row10 col5\" >4.000000</td>\n",
              "      <td id=\"T_08128_row10_col6\" class=\"data row10 col6\" >0.000000</td>\n",
              "      <td id=\"T_08128_row10_col7\" class=\"data row10 col7\" >1.082310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_08128_level0_row11\" class=\"row_heading level0 row11\" >bs_nop_count</th>\n",
              "      <td id=\"T_08128_row11_col0\" class=\"data row11 col0\" >int64</td>\n",
              "      <td id=\"T_08128_row11_col1\" class=\"data row11 col1\" >0</td>\n",
              "      <td id=\"T_08128_row11_col2\" class=\"data row11 col2\" >0.000000</td>\n",
              "      <td id=\"T_08128_row11_col3\" class=\"data row11 col3\" >5</td>\n",
              "      <td id=\"T_08128_row11_col4\" class=\"data row11 col4\" >3369.000000</td>\n",
              "      <td id=\"T_08128_row11_col5\" class=\"data row11 col5\" >64815.000000</td>\n",
              "      <td id=\"T_08128_row11_col6\" class=\"data row11 col6\" >49112.000000</td>\n",
              "      <td id=\"T_08128_row11_col7\" class=\"data row11 col7\" >47277.398294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_08128_level0_row12\" class=\"row_heading level0 row12\" >NumOfProducts_cat_count</th>\n",
              "      <td id=\"T_08128_row12_col0\" class=\"data row12 col0\" >int64</td>\n",
              "      <td id=\"T_08128_row12_col1\" class=\"data row12 col1\" >0</td>\n",
              "      <td id=\"T_08128_row12_col2\" class=\"data row12 col2\" >0.000000</td>\n",
              "      <td id=\"T_08128_row12_col3\" class=\"data row12 col3\" >3</td>\n",
              "      <td id=\"T_08128_row12_col4\" class=\"data row12 col4\" >3369.000000</td>\n",
              "      <td id=\"T_08128_row12_col5\" class=\"data row12 col5\" >84291.000000</td>\n",
              "      <td id=\"T_08128_row12_col6\" class=\"data row12 col6\" >84291.000000</td>\n",
              "      <td id=\"T_08128_row12_col7\" class=\"data row12 col7\" >79396.116667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_08128_level0_row13\" class=\"row_heading level0 row13\" >Balance_Range_count</th>\n",
              "      <td id=\"T_08128_row13_col0\" class=\"data row13 col0\" >int64</td>\n",
              "      <td id=\"T_08128_row13_col1\" class=\"data row13 col1\" >0</td>\n",
              "      <td id=\"T_08128_row13_col2\" class=\"data row13 col2\" >0.000000</td>\n",
              "      <td id=\"T_08128_row13_col3\" class=\"data row13 col3\" >5</td>\n",
              "      <td id=\"T_08128_row13_col4\" class=\"data row13 col4\" >8974.000000</td>\n",
              "      <td id=\"T_08128_row13_col5\" class=\"data row13 col5\" >89648.000000</td>\n",
              "      <td id=\"T_08128_row13_col6\" class=\"data row13 col6\" >89648.000000</td>\n",
              "      <td id=\"T_08128_row13_col7\" class=\"data row13 col7\" >58669.214622</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = OrdinalEncoder()\n",
        "to_encode = [\"Geography_count_label-NumOfProducts_cat_count\",\"Geography_count/NumOfProducts_cat_count_label\",\"bs_nop_count\",\"NumOfProducts_cat_count\",\"Balance_Range_count\"]\n",
        "X[to_encode] = encoder.fit_transform(X[to_encode])\n",
        "X[to_encode] = X[to_encode].astype(\"int\")\n",
        "X_test[to_encode] = encoder.fit_transform(X_test[to_encode])"
      ],
      "metadata": {
        "id": "RtsWanvbdqEu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(X.select_dtypes(\"int\")).style.background_gradient(cmap='Reds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "JUfieNFZdqBO",
        "outputId": "514574c4-122b-42e3-b060-bec89eaec9ac"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data shape: (165034, 14)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fae8f935d80>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_ed6e1_row0_col1, #T_ed6e1_row0_col2, #T_ed6e1_row0_col4, #T_ed6e1_row1_col1, #T_ed6e1_row1_col2, #T_ed6e1_row1_col4, #T_ed6e1_row2_col1, #T_ed6e1_row2_col2, #T_ed6e1_row2_col3, #T_ed6e1_row2_col4, #T_ed6e1_row2_col5, #T_ed6e1_row3_col1, #T_ed6e1_row3_col2, #T_ed6e1_row3_col3, #T_ed6e1_row3_col4, #T_ed6e1_row3_col5, #T_ed6e1_row3_col6, #T_ed6e1_row3_col7, #T_ed6e1_row4_col1, #T_ed6e1_row4_col2, #T_ed6e1_row4_col4, #T_ed6e1_row5_col1, #T_ed6e1_row5_col2, #T_ed6e1_row5_col4, #T_ed6e1_row6_col1, #T_ed6e1_row6_col2, #T_ed6e1_row6_col4, #T_ed6e1_row7_col1, #T_ed6e1_row7_col2, #T_ed6e1_row7_col4, #T_ed6e1_row8_col1, #T_ed6e1_row8_col2, #T_ed6e1_row8_col4, #T_ed6e1_row9_col1, #T_ed6e1_row9_col2, #T_ed6e1_row9_col4, #T_ed6e1_row10_col1, #T_ed6e1_row10_col2, #T_ed6e1_row10_col4, #T_ed6e1_row10_col6, #T_ed6e1_row11_col1, #T_ed6e1_row11_col2, #T_ed6e1_row11_col4, #T_ed6e1_row12_col1, #T_ed6e1_row12_col2, #T_ed6e1_row12_col4, #T_ed6e1_row13_col1, #T_ed6e1_row13_col2, #T_ed6e1_row13_col4 {\n",
              "  background-color: #fff5f0;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_ed6e1_row0_col3, #T_ed6e1_row0_col5, #T_ed6e1_row1_col3, #T_ed6e1_row1_col5, #T_ed6e1_row5_col3, #T_ed6e1_row5_col5, #T_ed6e1_row8_col3, #T_ed6e1_row8_col5, #T_ed6e1_row10_col3, #T_ed6e1_row10_col5, #T_ed6e1_row11_col3, #T_ed6e1_row11_col5, #T_ed6e1_row13_col3, #T_ed6e1_row13_col5 {\n",
              "  background-color: #fcab8f;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_ed6e1_row0_col6, #T_ed6e1_row5_col6, #T_ed6e1_row6_col6, #T_ed6e1_row9_col6, #T_ed6e1_row12_col6 {\n",
              "  background-color: #fc8a6a;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_ed6e1_row0_col7 {\n",
              "  background-color: #fcae92;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_ed6e1_row1_col6, #T_ed6e1_row2_col6, #T_ed6e1_row9_col3, #T_ed6e1_row9_col5 {\n",
              "  background-color: #fdcab5;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_ed6e1_row1_col7, #T_ed6e1_row10_col7 {\n",
              "  background-color: #fdd7c6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_ed6e1_row2_col7 {\n",
              "  background-color: #feeae0;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_ed6e1_row4_col3, #T_ed6e1_row4_col5, #T_ed6e1_row13_col6 {\n",
              "  background-color: #bc141a;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_ed6e1_row4_col6, #T_ed6e1_row4_col7, #T_ed6e1_row7_col3, #T_ed6e1_row7_col5, #T_ed6e1_row7_col6, #T_ed6e1_row7_col7 {\n",
              "  background-color: #67000d;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_ed6e1_row5_col7 {\n",
              "  background-color: #fca082;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_ed6e1_row6_col3, #T_ed6e1_row6_col5 {\n",
              "  background-color: #d92523;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_ed6e1_row6_col7 {\n",
              "  background-color: #fb7858;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_ed6e1_row8_col6, #T_ed6e1_row11_col6 {\n",
              "  background-color: #f14432;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_ed6e1_row8_col7 {\n",
              "  background-color: #d21f20;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_ed6e1_row9_col7 {\n",
              "  background-color: #fca78b;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_ed6e1_row11_col7 {\n",
              "  background-color: #e53228;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_ed6e1_row12_col3, #T_ed6e1_row12_col5 {\n",
              "  background-color: #fee5d8;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_ed6e1_row12_col7 {\n",
              "  background-color: #fcb499;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_ed6e1_row13_col7 {\n",
              "  background-color: #da2723;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_ed6e1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_ed6e1_level0_col0\" class=\"col_heading level0 col0\" >data type</th>\n",
              "      <th id=\"T_ed6e1_level0_col1\" class=\"col_heading level0 col1\" >#missing</th>\n",
              "      <th id=\"T_ed6e1_level0_col2\" class=\"col_heading level0 col2\" >%missing</th>\n",
              "      <th id=\"T_ed6e1_level0_col3\" class=\"col_heading level0 col3\" >#unique</th>\n",
              "      <th id=\"T_ed6e1_level0_col4\" class=\"col_heading level0 col4\" >min</th>\n",
              "      <th id=\"T_ed6e1_level0_col5\" class=\"col_heading level0 col5\" >max</th>\n",
              "      <th id=\"T_ed6e1_level0_col6\" class=\"col_heading level0 col6\" >median</th>\n",
              "      <th id=\"T_ed6e1_level0_col7\" class=\"col_heading level0 col7\" >mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_ed6e1_level0_row0\" class=\"row_heading level0 row0\" >act_nop</th>\n",
              "      <td id=\"T_ed6e1_row0_col0\" class=\"data row0 col0\" >int64</td>\n",
              "      <td id=\"T_ed6e1_row0_col1\" class=\"data row0 col1\" >0</td>\n",
              "      <td id=\"T_ed6e1_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row0_col3\" class=\"data row0 col3\" >5</td>\n",
              "      <td id=\"T_ed6e1_row0_col4\" class=\"data row0 col4\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row0_col5\" class=\"data row0 col5\" >4.000000</td>\n",
              "      <td id=\"T_ed6e1_row0_col6\" class=\"data row0 col6\" >2.000000</td>\n",
              "      <td id=\"T_ed6e1_row0_col7\" class=\"data row0 col7\" >1.574748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ed6e1_level0_row1\" class=\"row_heading level0 row1\" >bs_nop_count_label</th>\n",
              "      <td id=\"T_ed6e1_row1_col0\" class=\"data row1 col0\" >int64</td>\n",
              "      <td id=\"T_ed6e1_row1_col1\" class=\"data row1 col1\" >0</td>\n",
              "      <td id=\"T_ed6e1_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row1_col3\" class=\"data row1 col3\" >5</td>\n",
              "      <td id=\"T_ed6e1_row1_col4\" class=\"data row1 col4\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row1_col5\" class=\"data row1 col5\" >4.000000</td>\n",
              "      <td id=\"T_ed6e1_row1_col6\" class=\"data row1 col6\" >1.000000</td>\n",
              "      <td id=\"T_ed6e1_row1_col7\" class=\"data row1 col7\" >1.075778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ed6e1_level0_row2\" class=\"row_heading level0 row2\" >HasCrCard</th>\n",
              "      <td id=\"T_ed6e1_row2_col0\" class=\"data row2 col0\" >int64</td>\n",
              "      <td id=\"T_ed6e1_row2_col1\" class=\"data row2 col1\" >0</td>\n",
              "      <td id=\"T_ed6e1_row2_col2\" class=\"data row2 col2\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row2_col3\" class=\"data row2 col3\" >2</td>\n",
              "      <td id=\"T_ed6e1_row2_col4\" class=\"data row2 col4\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row2_col5\" class=\"data row2 col5\" >1.000000</td>\n",
              "      <td id=\"T_ed6e1_row2_col6\" class=\"data row2 col6\" >1.000000</td>\n",
              "      <td id=\"T_ed6e1_row2_col7\" class=\"data row2 col7\" >0.753954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ed6e1_level0_row3\" class=\"row_heading level0 row3\" >IsActiveMember</th>\n",
              "      <td id=\"T_ed6e1_row3_col0\" class=\"data row3 col0\" >int64</td>\n",
              "      <td id=\"T_ed6e1_row3_col1\" class=\"data row3 col1\" >0</td>\n",
              "      <td id=\"T_ed6e1_row3_col2\" class=\"data row3 col2\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row3_col3\" class=\"data row3 col3\" >2</td>\n",
              "      <td id=\"T_ed6e1_row3_col4\" class=\"data row3 col4\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row3_col5\" class=\"data row3 col5\" >1.000000</td>\n",
              "      <td id=\"T_ed6e1_row3_col6\" class=\"data row3 col6\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row3_col7\" class=\"data row3 col7\" >0.497770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ed6e1_level0_row4\" class=\"row_heading level0 row4\" >CreditScore_unimp_cluster_WOE</th>\n",
              "      <td id=\"T_ed6e1_row4_col0\" class=\"data row4 col0\" >int64</td>\n",
              "      <td id=\"T_ed6e1_row4_col1\" class=\"data row4 col1\" >0</td>\n",
              "      <td id=\"T_ed6e1_row4_col2\" class=\"data row4 col2\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row4_col3\" class=\"data row4 col3\" >10</td>\n",
              "      <td id=\"T_ed6e1_row4_col4\" class=\"data row4 col4\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row4_col5\" class=\"data row4 col5\" >9.000000</td>\n",
              "      <td id=\"T_ed6e1_row4_col6\" class=\"data row4 col6\" >5.000000</td>\n",
              "      <td id=\"T_ed6e1_row4_col7\" class=\"data row4 col7\" >4.177091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ed6e1_level0_row5\" class=\"row_heading level0 row5\" >bs_nop</th>\n",
              "      <td id=\"T_ed6e1_row5_col0\" class=\"data row5 col0\" >int64</td>\n",
              "      <td id=\"T_ed6e1_row5_col1\" class=\"data row5 col1\" >0</td>\n",
              "      <td id=\"T_ed6e1_row5_col2\" class=\"data row5 col2\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row5_col3\" class=\"data row5 col3\" >5</td>\n",
              "      <td id=\"T_ed6e1_row5_col4\" class=\"data row5 col4\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row5_col5\" class=\"data row5 col5\" >4.000000</td>\n",
              "      <td id=\"T_ed6e1_row5_col6\" class=\"data row5 col6\" >2.000000</td>\n",
              "      <td id=\"T_ed6e1_row5_col7\" class=\"data row5 col7\" >1.720379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ed6e1_level0_row6\" class=\"row_heading level0 row6\" >Geography_count_label-NumOfProducts_cat_count</th>\n",
              "      <td id=\"T_ed6e1_row6_col0\" class=\"data row6 col0\" >int64</td>\n",
              "      <td id=\"T_ed6e1_row6_col1\" class=\"data row6 col1\" >0</td>\n",
              "      <td id=\"T_ed6e1_row6_col2\" class=\"data row6 col2\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row6_col3\" class=\"data row6 col3\" >9</td>\n",
              "      <td id=\"T_ed6e1_row6_col4\" class=\"data row6 col4\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row6_col5\" class=\"data row6 col5\" >8.000000</td>\n",
              "      <td id=\"T_ed6e1_row6_col6\" class=\"data row6 col6\" >2.000000</td>\n",
              "      <td id=\"T_ed6e1_row6_col7\" class=\"data row6 col7\" >2.167802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ed6e1_level0_row7\" class=\"row_heading level0 row7\" >act_age</th>\n",
              "      <td id=\"T_ed6e1_row7_col0\" class=\"data row7 col0\" >int64</td>\n",
              "      <td id=\"T_ed6e1_row7_col1\" class=\"data row7 col1\" >0</td>\n",
              "      <td id=\"T_ed6e1_row7_col2\" class=\"data row7 col2\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row7_col3\" class=\"data row7 col3\" >12</td>\n",
              "      <td id=\"T_ed6e1_row7_col4\" class=\"data row7 col4\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row7_col5\" class=\"data row7 col5\" >11.000000</td>\n",
              "      <td id=\"T_ed6e1_row7_col6\" class=\"data row7 col6\" >5.000000</td>\n",
              "      <td id=\"T_ed6e1_row7_col7\" class=\"data row7 col7\" >4.166566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ed6e1_level0_row8\" class=\"row_heading level0 row8\" >Geography_count/NumOfProducts_cat_count_label</th>\n",
              "      <td id=\"T_ed6e1_row8_col0\" class=\"data row8 col0\" >int64</td>\n",
              "      <td id=\"T_ed6e1_row8_col1\" class=\"data row8 col1\" >0</td>\n",
              "      <td id=\"T_ed6e1_row8_col2\" class=\"data row8 col2\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row8_col3\" class=\"data row8 col3\" >5</td>\n",
              "      <td id=\"T_ed6e1_row8_col4\" class=\"data row8 col4\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row8_col5\" class=\"data row8 col5\" >4.000000</td>\n",
              "      <td id=\"T_ed6e1_row8_col6\" class=\"data row8 col6\" >3.000000</td>\n",
              "      <td id=\"T_ed6e1_row8_col7\" class=\"data row8 col7\" >3.159464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ed6e1_level0_row9\" class=\"row_heading level0 row9\" >bs_active</th>\n",
              "      <td id=\"T_ed6e1_row9_col0\" class=\"data row9 col0\" >int64</td>\n",
              "      <td id=\"T_ed6e1_row9_col1\" class=\"data row9 col1\" >0</td>\n",
              "      <td id=\"T_ed6e1_row9_col2\" class=\"data row9 col2\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row9_col3\" class=\"data row9 col3\" >4</td>\n",
              "      <td id=\"T_ed6e1_row9_col4\" class=\"data row9 col4\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row9_col5\" class=\"data row9 col5\" >3.000000</td>\n",
              "      <td id=\"T_ed6e1_row9_col6\" class=\"data row9 col6\" >2.000000</td>\n",
              "      <td id=\"T_ed6e1_row9_col7\" class=\"data row9 col7\" >1.645522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ed6e1_level0_row10\" class=\"row_heading level0 row10\" >Balance_Range</th>\n",
              "      <td id=\"T_ed6e1_row10_col0\" class=\"data row10 col0\" >int64</td>\n",
              "      <td id=\"T_ed6e1_row10_col1\" class=\"data row10 col1\" >0</td>\n",
              "      <td id=\"T_ed6e1_row10_col2\" class=\"data row10 col2\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row10_col3\" class=\"data row10 col3\" >5</td>\n",
              "      <td id=\"T_ed6e1_row10_col4\" class=\"data row10 col4\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row10_col5\" class=\"data row10 col5\" >4.000000</td>\n",
              "      <td id=\"T_ed6e1_row10_col6\" class=\"data row10 col6\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row10_col7\" class=\"data row10 col7\" >1.082310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ed6e1_level0_row11\" class=\"row_heading level0 row11\" >bs_nop_count</th>\n",
              "      <td id=\"T_ed6e1_row11_col0\" class=\"data row11 col0\" >int64</td>\n",
              "      <td id=\"T_ed6e1_row11_col1\" class=\"data row11 col1\" >0</td>\n",
              "      <td id=\"T_ed6e1_row11_col2\" class=\"data row11 col2\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row11_col3\" class=\"data row11 col3\" >5</td>\n",
              "      <td id=\"T_ed6e1_row11_col4\" class=\"data row11 col4\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row11_col5\" class=\"data row11 col5\" >4.000000</td>\n",
              "      <td id=\"T_ed6e1_row11_col6\" class=\"data row11 col6\" >3.000000</td>\n",
              "      <td id=\"T_ed6e1_row11_col7\" class=\"data row11 col7\" >2.924222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ed6e1_level0_row12\" class=\"row_heading level0 row12\" >NumOfProducts_cat_count</th>\n",
              "      <td id=\"T_ed6e1_row12_col0\" class=\"data row12 col0\" >int64</td>\n",
              "      <td id=\"T_ed6e1_row12_col1\" class=\"data row12 col1\" >0</td>\n",
              "      <td id=\"T_ed6e1_row12_col2\" class=\"data row12 col2\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row12_col3\" class=\"data row12 col3\" >3</td>\n",
              "      <td id=\"T_ed6e1_row12_col4\" class=\"data row12 col4\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row12_col5\" class=\"data row12 col5\" >2.000000</td>\n",
              "      <td id=\"T_ed6e1_row12_col6\" class=\"data row12 col6\" >2.000000</td>\n",
              "      <td id=\"T_ed6e1_row12_col7\" class=\"data row12 col7\" >1.490335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ed6e1_level0_row13\" class=\"row_heading level0 row13\" >Balance_Range_count</th>\n",
              "      <td id=\"T_ed6e1_row13_col0\" class=\"data row13 col0\" >int64</td>\n",
              "      <td id=\"T_ed6e1_row13_col1\" class=\"data row13 col1\" >0</td>\n",
              "      <td id=\"T_ed6e1_row13_col2\" class=\"data row13 col2\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row13_col3\" class=\"data row13 col3\" >5</td>\n",
              "      <td id=\"T_ed6e1_row13_col4\" class=\"data row13 col4\" >0.000000</td>\n",
              "      <td id=\"T_ed6e1_row13_col5\" class=\"data row13 col5\" >4.000000</td>\n",
              "      <td id=\"T_ed6e1_row13_col6\" class=\"data row13 col6\" >4.000000</td>\n",
              "      <td id=\"T_ed6e1_row13_col7\" class=\"data row13 col7\" >3.057958</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(X.select_dtypes(\"float\")).style.background_gradient(cmap='Blues')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        },
        "id": "Xu0wbSksVjkZ",
        "outputId": "efbfe52e-443c-4bcf-9ef2-8a055a14dcb2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data shape: (165034, 29)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fae8f92c2e0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_9a6e4_row0_col1, #T_9a6e4_row0_col2, #T_9a6e4_row0_col4, #T_9a6e4_row0_col5, #T_9a6e4_row1_col1, #T_9a6e4_row1_col2, #T_9a6e4_row1_col4, #T_9a6e4_row1_col5, #T_9a6e4_row2_col1, #T_9a6e4_row2_col2, #T_9a6e4_row2_col4, #T_9a6e4_row2_col5, #T_9a6e4_row3_col1, #T_9a6e4_row3_col2, #T_9a6e4_row3_col3, #T_9a6e4_row3_col4, #T_9a6e4_row3_col5, #T_9a6e4_row4_col1, #T_9a6e4_row4_col2, #T_9a6e4_row4_col3, #T_9a6e4_row4_col4, #T_9a6e4_row4_col5, #T_9a6e4_row5_col1, #T_9a6e4_row5_col2, #T_9a6e4_row5_col4, #T_9a6e4_row5_col5, #T_9a6e4_row6_col1, #T_9a6e4_row6_col2, #T_9a6e4_row6_col3, #T_9a6e4_row6_col4, #T_9a6e4_row6_col5, #T_9a6e4_row6_col6, #T_9a6e4_row6_col7, #T_9a6e4_row7_col1, #T_9a6e4_row7_col2, #T_9a6e4_row7_col4, #T_9a6e4_row7_col5, #T_9a6e4_row8_col1, #T_9a6e4_row8_col2, #T_9a6e4_row8_col4, #T_9a6e4_row8_col5, #T_9a6e4_row9_col1, #T_9a6e4_row9_col2, #T_9a6e4_row9_col3, #T_9a6e4_row9_col4, #T_9a6e4_row9_col5, #T_9a6e4_row10_col1, #T_9a6e4_row10_col2, #T_9a6e4_row10_col3, #T_9a6e4_row10_col4, #T_9a6e4_row10_col5, #T_9a6e4_row11_col1, #T_9a6e4_row11_col2, #T_9a6e4_row11_col4, #T_9a6e4_row11_col5, #T_9a6e4_row12_col1, #T_9a6e4_row12_col2, #T_9a6e4_row12_col4, #T_9a6e4_row12_col5, #T_9a6e4_row13_col1, #T_9a6e4_row13_col2, #T_9a6e4_row13_col4, #T_9a6e4_row13_col5, #T_9a6e4_row14_col1, #T_9a6e4_row14_col2, #T_9a6e4_row14_col4, #T_9a6e4_row14_col5, #T_9a6e4_row15_col1, #T_9a6e4_row15_col2, #T_9a6e4_row15_col4, #T_9a6e4_row15_col5, #T_9a6e4_row16_col1, #T_9a6e4_row16_col2, #T_9a6e4_row16_col4, #T_9a6e4_row16_col5, #T_9a6e4_row17_col1, #T_9a6e4_row17_col2, #T_9a6e4_row17_col4, #T_9a6e4_row17_col5, #T_9a6e4_row18_col1, #T_9a6e4_row18_col2, #T_9a6e4_row18_col4, #T_9a6e4_row18_col5, #T_9a6e4_row19_col1, #T_9a6e4_row19_col2, #T_9a6e4_row19_col4, #T_9a6e4_row19_col5, #T_9a6e4_row20_col1, #T_9a6e4_row20_col2, #T_9a6e4_row20_col4, #T_9a6e4_row20_col5, #T_9a6e4_row21_col1, #T_9a6e4_row21_col2, #T_9a6e4_row21_col4, #T_9a6e4_row21_col5, #T_9a6e4_row22_col1, #T_9a6e4_row22_col2, #T_9a6e4_row22_col4, #T_9a6e4_row22_col5, #T_9a6e4_row23_col1, #T_9a6e4_row23_col2, #T_9a6e4_row23_col4, #T_9a6e4_row23_col5, #T_9a6e4_row24_col1, #T_9a6e4_row24_col2, #T_9a6e4_row24_col4, #T_9a6e4_row24_col5, #T_9a6e4_row25_col1, #T_9a6e4_row25_col2, #T_9a6e4_row25_col3, #T_9a6e4_row25_col4, #T_9a6e4_row25_col5, #T_9a6e4_row26_col1, #T_9a6e4_row26_col2, #T_9a6e4_row26_col4, #T_9a6e4_row26_col5, #T_9a6e4_row27_col1, #T_9a6e4_row27_col2, #T_9a6e4_row27_col4, #T_9a6e4_row27_col5, #T_9a6e4_row28_col1, #T_9a6e4_row28_col2, #T_9a6e4_row28_col4, #T_9a6e4_row28_col5 {\n",
              "  background-color: #f7fbff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9a6e4_row0_col3, #T_9a6e4_row1_col3, #T_9a6e4_row5_col3, #T_9a6e4_row8_col3, #T_9a6e4_row11_col3, #T_9a6e4_row15_col3, #T_9a6e4_row16_col3, #T_9a6e4_row17_col3, #T_9a6e4_row20_col3, #T_9a6e4_row21_col6, #T_9a6e4_row21_col7, #T_9a6e4_row23_col3, #T_9a6e4_row24_col3, #T_9a6e4_row27_col3, #T_9a6e4_row28_col3 {\n",
              "  background-color: #08306b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9a6e4_row0_col6, #T_9a6e4_row1_col6, #T_9a6e4_row2_col6, #T_9a6e4_row3_col6, #T_9a6e4_row5_col6, #T_9a6e4_row7_col6, #T_9a6e4_row11_col6, #T_9a6e4_row12_col6, #T_9a6e4_row15_col6, #T_9a6e4_row16_col6, #T_9a6e4_row17_col6, #T_9a6e4_row22_col6, #T_9a6e4_row25_col6, #T_9a6e4_row26_col6, #T_9a6e4_row28_col6 {\n",
              "  background-color: #6aaed6;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9a6e4_row0_col7, #T_9a6e4_row1_col7, #T_9a6e4_row2_col7, #T_9a6e4_row3_col7, #T_9a6e4_row4_col7, #T_9a6e4_row5_col7, #T_9a6e4_row7_col7, #T_9a6e4_row8_col7, #T_9a6e4_row11_col7, #T_9a6e4_row12_col7, #T_9a6e4_row14_col7, #T_9a6e4_row15_col7, #T_9a6e4_row16_col7, #T_9a6e4_row17_col7, #T_9a6e4_row18_col7, #T_9a6e4_row20_col7, #T_9a6e4_row22_col7, #T_9a6e4_row23_col7, #T_9a6e4_row24_col7, #T_9a6e4_row26_col7, #T_9a6e4_row27_col7, #T_9a6e4_row28_col7 {\n",
              "  background-color: #72b2d8;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9a6e4_row2_col3, #T_9a6e4_row13_col3, #T_9a6e4_row14_col3, #T_9a6e4_row18_col3, #T_9a6e4_row26_col3 {\n",
              "  background-color: #f6faff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9a6e4_row4_col6, #T_9a6e4_row8_col6, #T_9a6e4_row9_col6, #T_9a6e4_row10_col6, #T_9a6e4_row14_col6, #T_9a6e4_row18_col6, #T_9a6e4_row20_col6, #T_9a6e4_row23_col6, #T_9a6e4_row24_col6, #T_9a6e4_row27_col6 {\n",
              "  background-color: #6caed6;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9a6e4_row7_col3 {\n",
              "  background-color: #dce9f6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9a6e4_row9_col7, #T_9a6e4_row25_col7 {\n",
              "  background-color: #75b4d8;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9a6e4_row10_col7 {\n",
              "  background-color: #82bbdb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9a6e4_row12_col3 {\n",
              "  background-color: #abd0e6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9a6e4_row13_col6 {\n",
              "  background-color: #69add5;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9a6e4_row13_col7 {\n",
              "  background-color: #6fb0d7;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9a6e4_row19_col3 {\n",
              "  background-color: #ccdff1;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9a6e4_row19_col6 {\n",
              "  background-color: #5ca4d0;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_9a6e4_row19_col7 {\n",
              "  background-color: #74b3d8;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9a6e4_row21_col3 {\n",
              "  background-color: #d3e4f3;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_9a6e4_row22_col3 {\n",
              "  background-color: #4b98ca;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_9a6e4\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_9a6e4_level0_col0\" class=\"col_heading level0 col0\" >data type</th>\n",
              "      <th id=\"T_9a6e4_level0_col1\" class=\"col_heading level0 col1\" >#missing</th>\n",
              "      <th id=\"T_9a6e4_level0_col2\" class=\"col_heading level0 col2\" >%missing</th>\n",
              "      <th id=\"T_9a6e4_level0_col3\" class=\"col_heading level0 col3\" >#unique</th>\n",
              "      <th id=\"T_9a6e4_level0_col4\" class=\"col_heading level0 col4\" >min</th>\n",
              "      <th id=\"T_9a6e4_level0_col5\" class=\"col_heading level0 col5\" >max</th>\n",
              "      <th id=\"T_9a6e4_level0_col6\" class=\"col_heading level0 col6\" >median</th>\n",
              "      <th id=\"T_9a6e4_level0_col7\" class=\"col_heading level0 col7\" >mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row0\" class=\"row_heading level0 row0\" >Age_Category_enc</th>\n",
              "      <td id=\"T_9a6e4_row0_col0\" class=\"data row0 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row0_col1\" class=\"data row0 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row0_col3\" class=\"data row0 col3\" >165031</td>\n",
              "      <td id=\"T_9a6e4_row0_col4\" class=\"data row0 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row0_col5\" class=\"data row0 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row0_col6\" class=\"data row0 col6\" >0.002424</td>\n",
              "      <td id=\"T_9a6e4_row0_col7\" class=\"data row0 col7\" >0.004039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row1\" class=\"row_heading level0 row1\" >bs_nop_enc</th>\n",
              "      <td id=\"T_9a6e4_row1_col0\" class=\"data row1 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row1_col1\" class=\"data row1 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row1_col3\" class=\"data row1 col3\" >165025</td>\n",
              "      <td id=\"T_9a6e4_row1_col4\" class=\"data row1 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row1_col5\" class=\"data row1 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row1_col6\" class=\"data row1 col6\" >0.009085</td>\n",
              "      <td id=\"T_9a6e4_row1_col7\" class=\"data row1 col7\" >0.004027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row2\" class=\"row_heading level0 row2\" >Surname_tfidf_1</th>\n",
              "      <td id=\"T_9a6e4_row2_col0\" class=\"data row2 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row2_col1\" class=\"data row2 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row2_col2\" class=\"data row2 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row2_col3\" class=\"data row2 col3\" >1007</td>\n",
              "      <td id=\"T_9a6e4_row2_col4\" class=\"data row2 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row2_col5\" class=\"data row2 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row2_col6\" class=\"data row2 col6\" >0.033880</td>\n",
              "      <td id=\"T_9a6e4_row2_col7\" class=\"data row2 col7\" >0.005195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row3\" class=\"row_heading level0 row3\" >Age_pca_comb</th>\n",
              "      <td id=\"T_9a6e4_row3_col0\" class=\"data row3 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row3_col1\" class=\"data row3 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row3_col2\" class=\"data row3 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row3_col3\" class=\"data row3 col3\" >74</td>\n",
              "      <td id=\"T_9a6e4_row3_col4\" class=\"data row3 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row3_col5\" class=\"data row3 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row3_col6\" class=\"data row3 col6\" >0.001255</td>\n",
              "      <td id=\"T_9a6e4_row3_col7\" class=\"data row3 col7\" >-0.006444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row4\" class=\"row_heading level0 row4\" >Age-NumOfProducts_cat_count</th>\n",
              "      <td id=\"T_9a6e4_row4_col0\" class=\"data row4 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row4_col1\" class=\"data row4 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row4_col2\" class=\"data row4 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row4_col3\" class=\"data row4 col3\" >196</td>\n",
              "      <td id=\"T_9a6e4_row4_col4\" class=\"data row4 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row4_col5\" class=\"data row4 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row4_col6\" class=\"data row4 col6\" >-0.003764</td>\n",
              "      <td id=\"T_9a6e4_row4_col7\" class=\"data row4 col7\" >-0.003649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row5\" class=\"row_heading level0 row5\" >act_age_enc</th>\n",
              "      <td id=\"T_9a6e4_row5_col0\" class=\"data row5 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row5_col1\" class=\"data row5 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row5_col2\" class=\"data row5 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row5_col3\" class=\"data row5 col3\" >165030</td>\n",
              "      <td id=\"T_9a6e4_row5_col4\" class=\"data row5 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row5_col5\" class=\"data row5 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row5_col6\" class=\"data row5 col6\" >0.005600</td>\n",
              "      <td id=\"T_9a6e4_row5_col7\" class=\"data row5 col7\" >0.000294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row6\" class=\"row_heading level0 row6\" >Age_cat*NumOfProducts_cat_count_label</th>\n",
              "      <td id=\"T_9a6e4_row6_col0\" class=\"data row6 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row6_col1\" class=\"data row6 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row6_col2\" class=\"data row6 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row6_col3\" class=\"data row6 col3\" >111</td>\n",
              "      <td id=\"T_9a6e4_row6_col4\" class=\"data row6 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row6_col5\" class=\"data row6 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row6_col6\" class=\"data row6 col6\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row6_col7\" class=\"data row6 col7\" >-2.259986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row7\" class=\"row_heading level0 row7\" >CustomerId</th>\n",
              "      <td id=\"T_9a6e4_row7_col0\" class=\"data row7 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row7_col1\" class=\"data row7 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row7_col2\" class=\"data row7 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row7_col3\" class=\"data row7 col3\" >23218</td>\n",
              "      <td id=\"T_9a6e4_row7_col4\" class=\"data row7 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row7_col5\" class=\"data row7 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row7_col6\" class=\"data row7 col6\" >0.006273</td>\n",
              "      <td id=\"T_9a6e4_row7_col7\" class=\"data row7 col7\" >0.005358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row8\" class=\"row_heading level0 row8\" >IsActiveMember_enc</th>\n",
              "      <td id=\"T_9a6e4_row8_col0\" class=\"data row8 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row8_col1\" class=\"data row8 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row8_col2\" class=\"data row8 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row8_col3\" class=\"data row8 col3\" >165033</td>\n",
              "      <td id=\"T_9a6e4_row8_col4\" class=\"data row8 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row8_col5\" class=\"data row8 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row8_col6\" class=\"data row8 col6\" >-0.006644</td>\n",
              "      <td id=\"T_9a6e4_row8_col7\" class=\"data row8 col7\" >-0.006912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row9\" class=\"row_heading level0 row9\" >CreditScore_cat_pca_comb_final</th>\n",
              "      <td id=\"T_9a6e4_row9_col0\" class=\"data row9 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row9_col1\" class=\"data row9 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row9_col2\" class=\"data row9 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row9_col3\" class=\"data row9 col3\" >456</td>\n",
              "      <td id=\"T_9a6e4_row9_col4\" class=\"data row9 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row9_col5\" class=\"data row9 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row9_col6\" class=\"data row9 col6\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row9_col7\" class=\"data row9 col7\" >-0.041095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row10\" class=\"row_heading level0 row10\" >Age_pca_comb_pca_comb_final</th>\n",
              "      <td id=\"T_9a6e4_row10_col0\" class=\"data row10 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row10_col1\" class=\"data row10 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row10_col2\" class=\"data row10 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row10_col3\" class=\"data row10 col3\" >74</td>\n",
              "      <td id=\"T_9a6e4_row10_col4\" class=\"data row10 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row10_col5\" class=\"data row10 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row10_col6\" class=\"data row10 col6\" >-0.028859</td>\n",
              "      <td id=\"T_9a6e4_row10_col7\" class=\"data row10 col7\" >-0.177088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row11\" class=\"row_heading level0 row11\" >bs_gender_enc</th>\n",
              "      <td id=\"T_9a6e4_row11_col0\" class=\"data row11 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row11_col1\" class=\"data row11 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row11_col2\" class=\"data row11 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row11_col3\" class=\"data row11 col3\" >165014</td>\n",
              "      <td id=\"T_9a6e4_row11_col4\" class=\"data row11 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row11_col5\" class=\"data row11 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row11_col6\" class=\"data row11 col6\" >0.006810</td>\n",
              "      <td id=\"T_9a6e4_row11_col7\" class=\"data row11 col7\" >0.004499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row12\" class=\"row_heading level0 row12\" >quant_EstimatedSalary</th>\n",
              "      <td id=\"T_9a6e4_row12_col0\" class=\"data row12 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row12_col1\" class=\"data row12 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row12_col2\" class=\"data row12 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row12_col3\" class=\"data row12 col3\" >55296</td>\n",
              "      <td id=\"T_9a6e4_row12_col4\" class=\"data row12 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row12_col5\" class=\"data row12 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row12_col6\" class=\"data row12 col6\" >0.001227</td>\n",
              "      <td id=\"T_9a6e4_row12_col7\" class=\"data row12 col7\" >0.002156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row13\" class=\"row_heading level0 row13\" >Surname_tfidf_2</th>\n",
              "      <td id=\"T_9a6e4_row13_col0\" class=\"data row13 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row13_col1\" class=\"data row13 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row13_col2\" class=\"data row13 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row13_col3\" class=\"data row13 col3\" >1007</td>\n",
              "      <td id=\"T_9a6e4_row13_col4\" class=\"data row13 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row13_col5\" class=\"data row13 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row13_col6\" class=\"data row13 col6\" >0.075345</td>\n",
              "      <td id=\"T_9a6e4_row13_col7\" class=\"data row13 col7\" >0.033864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row14\" class=\"row_heading level0 row14\" >Surname_tfidf_3</th>\n",
              "      <td id=\"T_9a6e4_row14_col0\" class=\"data row14 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row14_col1\" class=\"data row14 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row14_col2\" class=\"data row14 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row14_col3\" class=\"data row14 col3\" >1007</td>\n",
              "      <td id=\"T_9a6e4_row14_col4\" class=\"data row14 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row14_col5\" class=\"data row14 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row14_col6\" class=\"data row14 col6\" >-0.020074</td>\n",
              "      <td id=\"T_9a6e4_row14_col7\" class=\"data row14 col7\" >0.008400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row15\" class=\"row_heading level0 row15\" >Gender_enc</th>\n",
              "      <td id=\"T_9a6e4_row15_col0\" class=\"data row15 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row15_col1\" class=\"data row15 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row15_col2\" class=\"data row15 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row15_col3\" class=\"data row15 col3\" >165032</td>\n",
              "      <td id=\"T_9a6e4_row15_col4\" class=\"data row15 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row15_col5\" class=\"data row15 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row15_col6\" class=\"data row15 col6\" >0.001350</td>\n",
              "      <td id=\"T_9a6e4_row15_col7\" class=\"data row15 col7\" >-0.001185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row16\" class=\"row_heading level0 row16\" >Tenure_enc</th>\n",
              "      <td id=\"T_9a6e4_row16_col0\" class=\"data row16 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row16_col1\" class=\"data row16 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row16_col2\" class=\"data row16 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row16_col3\" class=\"data row16 col3\" >165032</td>\n",
              "      <td id=\"T_9a6e4_row16_col4\" class=\"data row16 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row16_col5\" class=\"data row16 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row16_col6\" class=\"data row16 col6\" >0.005134</td>\n",
              "      <td id=\"T_9a6e4_row16_col7\" class=\"data row16 col7\" >0.006292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row17\" class=\"row_heading level0 row17\" >Balance_Range_enc</th>\n",
              "      <td id=\"T_9a6e4_row17_col0\" class=\"data row17 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row17_col1\" class=\"data row17 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row17_col2\" class=\"data row17 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row17_col3\" class=\"data row17 col3\" >165026</td>\n",
              "      <td id=\"T_9a6e4_row17_col4\" class=\"data row17 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row17_col5\" class=\"data row17 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row17_col6\" class=\"data row17 col6\" >0.002088</td>\n",
              "      <td id=\"T_9a6e4_row17_col7\" class=\"data row17 col7\" >-0.000488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row18\" class=\"row_heading level0 row18\" >Surname_tfidf_4</th>\n",
              "      <td id=\"T_9a6e4_row18_col0\" class=\"data row18 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row18_col1\" class=\"data row18 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row18_col2\" class=\"data row18 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row18_col3\" class=\"data row18 col3\" >1007</td>\n",
              "      <td id=\"T_9a6e4_row18_col4\" class=\"data row18 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row18_col5\" class=\"data row18 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row18_col6\" class=\"data row18 col6\" >-0.020074</td>\n",
              "      <td id=\"T_9a6e4_row18_col7\" class=\"data row18 col7\" >0.009473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row19\" class=\"row_heading level0 row19\" >Balance-NumOfProducts_cat_count_label</th>\n",
              "      <td id=\"T_9a6e4_row19_col0\" class=\"data row19 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row19_col1\" class=\"data row19 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row19_col2\" class=\"data row19 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row19_col3\" class=\"data row19 col3\" >36756</td>\n",
              "      <td id=\"T_9a6e4_row19_col4\" class=\"data row19 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row19_col5\" class=\"data row19 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row19_col6\" class=\"data row19 col6\" >0.468203</td>\n",
              "      <td id=\"T_9a6e4_row19_col7\" class=\"data row19 col7\" >-0.026064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row20\" class=\"row_heading level0 row20\" >Geo_Gender_enc</th>\n",
              "      <td id=\"T_9a6e4_row20_col0\" class=\"data row20 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row20_col1\" class=\"data row20 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row20_col2\" class=\"data row20 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row20_col3\" class=\"data row20 col3\" >165030</td>\n",
              "      <td id=\"T_9a6e4_row20_col4\" class=\"data row20 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row20_col5\" class=\"data row20 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row20_col6\" class=\"data row20 col6\" >-0.001737</td>\n",
              "      <td id=\"T_9a6e4_row20_col7\" class=\"data row20 col7\" >-0.005256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row21\" class=\"row_heading level0 row21\" >Balance_pca_comb</th>\n",
              "      <td id=\"T_9a6e4_row21_col0\" class=\"data row21 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row21_col1\" class=\"data row21 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row21_col2\" class=\"data row21 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row21_col3\" class=\"data row21 col3\" >30075</td>\n",
              "      <td id=\"T_9a6e4_row21_col4\" class=\"data row21 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row21_col5\" class=\"data row21 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row21_col6\" class=\"data row21 col6\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row21_col7\" class=\"data row21 col7\" >2.426460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row22\" class=\"row_heading level0 row22\" >Balance_Salary</th>\n",
              "      <td id=\"T_9a6e4_row22_col0\" class=\"data row22 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row22_col1\" class=\"data row22 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row22_col2\" class=\"data row22 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row22_col3\" class=\"data row22 col3\" >98045</td>\n",
              "      <td id=\"T_9a6e4_row22_col4\" class=\"data row22 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row22_col5\" class=\"data row22 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row22_col6\" class=\"data row22 col6\" >0.004713</td>\n",
              "      <td id=\"T_9a6e4_row22_col7\" class=\"data row22 col7\" >0.004333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row23\" class=\"row_heading level0 row23\" >bs_active_enc</th>\n",
              "      <td id=\"T_9a6e4_row23_col0\" class=\"data row23 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row23_col1\" class=\"data row23 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row23_col2\" class=\"data row23 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row23_col3\" class=\"data row23 col3\" >165029</td>\n",
              "      <td id=\"T_9a6e4_row23_col4\" class=\"data row23 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row23_col5\" class=\"data row23 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row23_col6\" class=\"data row23 col6\" >-0.002799</td>\n",
              "      <td id=\"T_9a6e4_row23_col7\" class=\"data row23 col7\" >-0.002544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row24\" class=\"row_heading level0 row24\" >act_nop_enc</th>\n",
              "      <td id=\"T_9a6e4_row24_col0\" class=\"data row24 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row24_col1\" class=\"data row24 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row24_col2\" class=\"data row24 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row24_col3\" class=\"data row24 col3\" >165031</td>\n",
              "      <td id=\"T_9a6e4_row24_col4\" class=\"data row24 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row24_col5\" class=\"data row24 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row24_col6\" class=\"data row24 col6\" >-0.002450</td>\n",
              "      <td id=\"T_9a6e4_row24_col7\" class=\"data row24 col7\" >-0.001758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row25\" class=\"row_heading level0 row25\" >CreditScore_pca_comb_final</th>\n",
              "      <td id=\"T_9a6e4_row25_col0\" class=\"data row25 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row25_col1\" class=\"data row25 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row25_col2\" class=\"data row25 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row25_col3\" class=\"data row25 col3\" >462</td>\n",
              "      <td id=\"T_9a6e4_row25_col4\" class=\"data row25 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row25_col5\" class=\"data row25 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row25_col6\" class=\"data row25 col6\" >0.006273</td>\n",
              "      <td id=\"T_9a6e4_row25_col7\" class=\"data row25 col7\" >-0.037490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row26\" class=\"row_heading level0 row26\" >Surname_tfidf_0</th>\n",
              "      <td id=\"T_9a6e4_row26_col0\" class=\"data row26 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row26_col1\" class=\"data row26 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row26_col2\" class=\"data row26 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row26_col3\" class=\"data row26 col3\" >1007</td>\n",
              "      <td id=\"T_9a6e4_row26_col4\" class=\"data row26 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row26_col5\" class=\"data row26 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row26_col6\" class=\"data row26 col6\" >0.001995</td>\n",
              "      <td id=\"T_9a6e4_row26_col7\" class=\"data row26 col7\" >0.000703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row27\" class=\"row_heading level0 row27\" >HasCrCard_enc</th>\n",
              "      <td id=\"T_9a6e4_row27_col0\" class=\"data row27 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row27_col1\" class=\"data row27 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row27_col2\" class=\"data row27 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row27_col3\" class=\"data row27 col3\" >165030</td>\n",
              "      <td id=\"T_9a6e4_row27_col4\" class=\"data row27 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row27_col5\" class=\"data row27 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row27_col6\" class=\"data row27 col6\" >-0.001399</td>\n",
              "      <td id=\"T_9a6e4_row27_col7\" class=\"data row27 col7\" >-0.002888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9a6e4_level0_row28\" class=\"row_heading level0 row28\" >bs_age_enc</th>\n",
              "      <td id=\"T_9a6e4_row28_col0\" class=\"data row28 col0\" >float64</td>\n",
              "      <td id=\"T_9a6e4_row28_col1\" class=\"data row28 col1\" >0</td>\n",
              "      <td id=\"T_9a6e4_row28_col2\" class=\"data row28 col2\" >0.000000</td>\n",
              "      <td id=\"T_9a6e4_row28_col3\" class=\"data row28 col3\" >165028</td>\n",
              "      <td id=\"T_9a6e4_row28_col4\" class=\"data row28 col4\" >-5.199338</td>\n",
              "      <td id=\"T_9a6e4_row28_col5\" class=\"data row28 col5\" >5.199338</td>\n",
              "      <td id=\"T_9a6e4_row28_col6\" class=\"data row28 col6\" >0.003440</td>\n",
              "      <td id=\"T_9a6e4_row28_col7\" class=\"data row28 col7\" >-0.000929</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_var = X.select_dtypes(\"float\").columns\n",
        "cat_var = X.select_dtypes(\"int\").columns\n",
        "\n",
        "X[num_var] = X[num_var].astype(\"float32\")\n",
        "X_test[num_var] = X_test[num_var].astype(\"int32\")"
      ],
      "metadata": {
        "id": "MR9VkcIq9hjl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[\"Exited\"] = y\n",
        "weight=X[X[\"Exited\"]==0].shape[0]/X[X[\"Exited\"]==1].shape[0]\n",
        "X[\"weights\"] = [1 if x==0 else weight for x in X[\"Exited\"]]\n",
        "X_test[\"Exited\"] = 0\n",
        "X_test[\"weights\"] = 1"
      ],
      "metadata": {
        "id": "Tz3MRo7tGDLK"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Data Loading"
      ],
      "metadata": {
        "id": "iET1Aj_lYcmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataframe_to_dataset(dataframe, shuffle=False, batch_size=32):\n",
        "    dataframe = dataframe.copy()\n",
        "    labels = dataframe[\"Exited\"]\n",
        "    weights = dataframe.pop(\"weights\")\n",
        "    dataframe = dataframe.drop(columns=[\"Exited\"])\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices((\n",
        "                                             dict(dataframe),\n",
        "                                             labels,\n",
        "                                             #weights\n",
        "                                             ))\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(batch_size)\n",
        "    return ds"
      ],
      "metadata": {
        "id": "QTQy9bqAYfuw"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataframe_to_dataset(X, batch_size=32, shuffle=True)\n",
        "test_dataset = dataframe_to_dataset(X_test, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "ugvbzP7WYfrX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8hfbwFL37Vw",
        "outputId": "27b2a048-07c6-4153-80c0-a1684ff9651b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 165034 entries, 0 to 165033\n",
            "Data columns (total 45 columns):\n",
            " #   Column                                         Non-Null Count   Dtype  \n",
            "---  ------                                         --------------   -----  \n",
            " 0   Age_Category_enc                               165034 non-null  float32\n",
            " 1   bs_nop_enc                                     165034 non-null  float32\n",
            " 2   act_nop                                        165034 non-null  int64  \n",
            " 3   Surname_tfidf_1                                165034 non-null  float32\n",
            " 4   bs_nop_count_label                             165034 non-null  int64  \n",
            " 5   HasCrCard                                      165034 non-null  int64  \n",
            " 6   IsActiveMember                                 165034 non-null  int64  \n",
            " 7   Age_pca_comb                                   165034 non-null  float32\n",
            " 8   CreditScore_unimp_cluster_WOE                  165034 non-null  int64  \n",
            " 9   Age-NumOfProducts_cat_count                    165034 non-null  float32\n",
            " 10  bs_nop                                         165034 non-null  int64  \n",
            " 11  Geography_count_label-NumOfProducts_cat_count  165034 non-null  int64  \n",
            " 12  act_age_enc                                    165034 non-null  float32\n",
            " 13  act_age                                        165034 non-null  int64  \n",
            " 14  Age_cat*NumOfProducts_cat_count_label          165034 non-null  float32\n",
            " 15  CustomerId                                     165034 non-null  float32\n",
            " 16  Geography_count/NumOfProducts_cat_count_label  165034 non-null  int64  \n",
            " 17  IsActiveMember_enc                             165034 non-null  float32\n",
            " 18  CreditScore_cat_pca_comb_final                 165034 non-null  float32\n",
            " 19  bs_active                                      165034 non-null  int64  \n",
            " 20  Age_pca_comb_pca_comb_final                    165034 non-null  float32\n",
            " 21  Balance_Range                                  165034 non-null  int64  \n",
            " 22  bs_gender_enc                                  165034 non-null  float32\n",
            " 23  quant_EstimatedSalary                          165034 non-null  float32\n",
            " 24  Surname_tfidf_2                                165034 non-null  float32\n",
            " 25  bs_nop_count                                   165034 non-null  int64  \n",
            " 26  Surname_tfidf_3                                165034 non-null  float32\n",
            " 27  Gender_enc                                     165034 non-null  float32\n",
            " 28  Tenure_enc                                     165034 non-null  float32\n",
            " 29  Balance_Range_enc                              165034 non-null  float32\n",
            " 30  Surname_tfidf_4                                165034 non-null  float32\n",
            " 31  Balance-NumOfProducts_cat_count_label          165034 non-null  float32\n",
            " 32  Geo_Gender_enc                                 165034 non-null  float32\n",
            " 33  Balance_pca_comb                               165034 non-null  float32\n",
            " 34  NumOfProducts_cat_count                        165034 non-null  int64  \n",
            " 35  Balance_Salary                                 165034 non-null  float32\n",
            " 36  bs_active_enc                                  165034 non-null  float32\n",
            " 37  act_nop_enc                                    165034 non-null  float32\n",
            " 38  CreditScore_pca_comb_final                     165034 non-null  float32\n",
            " 39  Balance_Range_count                            165034 non-null  int64  \n",
            " 40  Surname_tfidf_0                                165034 non-null  float32\n",
            " 41  HasCrCard_enc                                  165034 non-null  float32\n",
            " 42  bs_age_enc                                     165034 non-null  float32\n",
            " 43  Exited                                         165034 non-null  int64  \n",
            " 44  weights                                        165034 non-null  float64\n",
            "dtypes: float32(29), float64(1), int64(15)\n",
            "memory usage: 39.7 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlEbtJSJ3yUy",
        "outputId": "3d8cf007-81b8-41e4-d048-fe10f76d9e8b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "159"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Test FeatureSpace"
      ],
      "metadata": {
        "id": "SxDCHrMI_a3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#X_fs = X.sample(frac=0.5,random_state=17)\n",
        "#train_dataset_fs = dataframe_to_dataset(X_fs, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "qb7ozIcL_l60"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzRVKpIkYdsa",
        "outputId": "68a2df84-c1d7-402e-becd-57e80d4f8fcd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Age_Category_enc', 'bs_nop_enc', 'act_nop', 'Surname_tfidf_1',\n",
              "       'bs_nop_count_label', 'HasCrCard', 'IsActiveMember', 'Age_pca_comb',\n",
              "       'CreditScore_unimp_cluster_WOE', 'Age-NumOfProducts_cat_count',\n",
              "       'bs_nop', 'Geography_count_label-NumOfProducts_cat_count',\n",
              "       'act_age_enc', 'act_age', 'Age_cat*NumOfProducts_cat_count_label',\n",
              "       'CustomerId', 'Geography_count/NumOfProducts_cat_count_label',\n",
              "       'IsActiveMember_enc', 'CreditScore_cat_pca_comb_final', 'bs_active',\n",
              "       'Age_pca_comb_pca_comb_final', 'Balance_Range', 'bs_gender_enc',\n",
              "       'quant_EstimatedSalary', 'Surname_tfidf_2', 'bs_nop_count',\n",
              "       'Surname_tfidf_3', 'Gender_enc', 'Tenure_enc', 'Balance_Range_enc',\n",
              "       'Surname_tfidf_4', 'Balance-NumOfProducts_cat_count_label',\n",
              "       'Geo_Gender_enc', 'Balance_pca_comb', 'NumOfProducts_cat_count',\n",
              "       'Balance_Salary', 'bs_active_enc', 'act_nop_enc',\n",
              "       'CreditScore_pca_comb_final', 'Balance_Range_count', 'Surname_tfidf_0',\n",
              "       'HasCrCard_enc', 'bs_age_enc', 'Exited', 'weights'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_var,cat_var"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgixsAY5nJLX",
        "outputId": "00ae9772-2177-4146-d59b-3361da9dcde3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Index(['Age_Category_enc', 'bs_nop_enc', 'Surname_tfidf_1', 'Age_pca_comb',\n",
              "        'Age-NumOfProducts_cat_count', 'act_age_enc',\n",
              "        'Age_cat*NumOfProducts_cat_count_label', 'CustomerId',\n",
              "        'IsActiveMember_enc', 'CreditScore_cat_pca_comb_final',\n",
              "        'Age_pca_comb_pca_comb_final', 'bs_gender_enc', 'quant_EstimatedSalary',\n",
              "        'Surname_tfidf_2', 'Surname_tfidf_3', 'Gender_enc', 'Tenure_enc',\n",
              "        'Balance_Range_enc', 'Surname_tfidf_4',\n",
              "        'Balance-NumOfProducts_cat_count_label', 'Geo_Gender_enc',\n",
              "        'Balance_pca_comb', 'Balance_Salary', 'bs_active_enc', 'act_nop_enc',\n",
              "        'CreditScore_pca_comb_final', 'Surname_tfidf_0', 'HasCrCard_enc',\n",
              "        'bs_age_enc'],\n",
              "       dtype='object'),\n",
              " Index(['act_nop', 'bs_nop_count_label', 'HasCrCard', 'IsActiveMember',\n",
              "        'CreditScore_unimp_cluster_WOE', 'bs_nop',\n",
              "        'Geography_count_label-NumOfProducts_cat_count', 'act_age',\n",
              "        'Geography_count/NumOfProducts_cat_count_label', 'bs_active',\n",
              "        'Balance_Range', 'bs_nop_count', 'NumOfProducts_cat_count',\n",
              "        'Balance_Range_count'],\n",
              "       dtype='object'))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "feature_space = FeatureSpace(\n",
        "                            features={**{a:FeatureSpace.integer_categorical(num_oov_indices=0, output_mode=\"int\") for a in cat_var},**{b:FeatureSpace.float() for b in num_var}},\n",
        "                            output_mode=\"dict\"\n",
        "                            )\n",
        "\n",
        "train_ds_with_no_labels = train_dataset.map(lambda x, *_: x)\n",
        "print(\"Adapting Features Space....\")\n",
        "feature_space.adapt(train_ds_with_no_labels)\n",
        "\n",
        "#preprocessed_train_ds = train_dataset.map(lambda x, y, w: (feature_space(x), y, w), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "#preprocessed_test_ds = test_dataset.map(lambda x, y, w: (feature_space(x), y, w), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "preprocessed_train_ds = train_dataset.map(lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "preprocessed_test_ds = test_dataset.map(lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbC1X6guYfoh",
        "outputId": "9e9bbd1e-7158-410d-db1a-48e8788a289b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fae8addfb50> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x7fae8addfb50>: no matching AST found among candidates:\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function <lambda> at 0x7fae8addfb50> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x7fae8addfb50>: no matching AST found among candidates:\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Adapting Features Space....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fae8addfe20> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x7fae8addfe20>: no matching AST found among candidates:\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function <lambda> at 0x7fae8addfe20> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x7fae8addfe20>: no matching AST found among candidates:\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fae444ef130> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x7fae444ef130>: no matching AST found among candidates:\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function <lambda> at 0x7fae444ef130> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x7fae444ef130>: no matching AST found among candidates:\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "CPU times: user 4min 34s, sys: 42.8 s, total: 5min 17s\n",
            "Wall time: 3min 27s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "FdYrxFF8YflX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a8aa308-1360-44f1-d501-10c0b37ceac4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2001"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for X_,y_ in preprocessed_train_ds.take(1):\n",
        "  print(len(X_.keys()))\n",
        "  print(y_.shape)\n",
        "#  print(w_.shape)"
      ],
      "metadata": {
        "id": "WlUtn1IoYfiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66057988-45d2-404e-dfe3-34bb4a6953ed"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43\n",
            "(32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.0 MODELS**"
      ],
      "metadata": {
        "id": "N8ACW78lXERn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Baseline:"
      ],
      "metadata": {
        "id": "5Ia_sCsMOzGb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BsMtoXTEOykD"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_categorical_nn = [name for name in X.drop(columns=\"Exited\").select_dtypes(\"int\").columns]\n",
        "Cat_Feat_Entries = {name: X[name].nunique() for name in X.drop(columns=\"Exited\").select_dtypes(\"int\").columns}"
      ],
      "metadata": {
        "id": "kAlcs4DYWXWs"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_categorical_nn"
      ],
      "metadata": {
        "id": "rnUKDTtOZkw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e526207a-88ad-4cb0-8c31-542d76918510"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['act_nop',\n",
              " 'bs_nop_count_label',\n",
              " 'HasCrCard',\n",
              " 'IsActiveMember',\n",
              " 'CreditScore_unimp_cluster_WOE',\n",
              " 'bs_nop',\n",
              " 'Geography_count_label-NumOfProducts_cat_count',\n",
              " 'act_age',\n",
              " 'Geography_count/NumOfProducts_cat_count_label',\n",
              " 'bs_active',\n",
              " 'Balance_Range',\n",
              " 'bs_nop_count',\n",
              " 'NumOfProducts_cat_count',\n",
              " 'Balance_Range_count']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1/0.33"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3XOt2JX_oxi",
        "outputId": "538c3888-4ed9-4ad8-df11-7e2f41463cb6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0303030303030303"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "v_Sxvd2QPNV7"
      },
      "outputs": [],
      "source": [
        "def create_baseline_model(fs,name=\"baseline_model\",learning_rate = 0.001,\n",
        "                          activation=\"relu\",dropout=0.5,hidden_layers=2,\n",
        "                          units_0=256,kr=0,num_dense_exp=False,output_bias=None,\n",
        "                          embedding_dims=16):\n",
        "\n",
        "  encoded_features = fs.get_encoded_features()\n",
        "  # Wide Leg\n",
        "  cat,num = encode_inputs(encoded_features, list_categorical_nn=list_categorical_nn, Cat_Feat_Entries=Cat_Feat_Entries, embedding_dims=embedding_dims, name=\"enc_wide\",num_dense_exp=num_dense_exp)\n",
        "\n",
        "#  wide_cat = tf.keras.layers.concatenate(cat, name=\"wide_cat_concat\")\n",
        "  wide_cat = tf.stack(cat, name=\"wide_cat_concat\",axis=1)\n",
        "\n",
        "#  wide_num = tf.keras.layers.concatenate(num, name=\"wide_num_concat\")\n",
        "  wide_num = tf.stack(num, name=\"wide_num_concat\",axis=1)\n",
        "\n",
        "  if num_dense_exp==False:\n",
        "    wide_cat = layers.Flatten()(wide_cat)\n",
        "    wide_num = layers.Flatten()(wide_num)\n",
        "\n",
        "  final_concat = tf.keras.layers.concatenate([wide_cat,wide_num],axis=1)\n",
        "  x_expanded = layers.Flatten()(final_concat)\n",
        "\n",
        "  for tier in range(hidden_layers):\n",
        "    x_expanded = dense_block(units_0, dropout_rate=dropout, activation=activation, kr=kr, name=f\"dense_block_n{tier}\")(x_expanded)\n",
        "\n",
        "  if output_bias is not None:\n",
        "    output = layers.Dense(1, activation=\"sigmoid\",bias_initializer=tf.keras.initializers.Constant(output_bias))(x_expanded)\n",
        "  else:\n",
        "    output = layers.Dense(1, activation=\"sigmoid\")(x_expanded)\n",
        "\n",
        "  model = tf.keras.Model(inputs=encoded_features, outputs=output, name=name)\n",
        "\n",
        "  model.compile(\n",
        "          optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "          loss=keras.losses.BinaryFocalCrossentropy(name=\"bin_foc_ce\",apply_class_balancing=True,alpha=0.67),\n",
        "          metrics=[keras.metrics.AUC(curve=\"ROC\",name=\"auc\")],\n",
        "          weighted_metrics=[])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "WG0iXPP7Phcg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f839fb-7897-47bc-81a9-acc01ad62704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"baseline_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_179 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_180 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_186 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_190 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_191 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_192 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_194 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_196 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_203 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_205 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_207 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_211 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_212 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_213 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_173 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_174 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_175 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_176 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_177 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_178 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_181 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_182 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_183 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_184 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_185 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_187 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_188 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_189 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_193 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_195 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_197 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_198 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_199 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_200 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_201 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_202 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_204 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_206 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_208 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_209 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_210 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_214 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_215 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " embedder_6 (Embedding)      (None, 1, 8)                 40        ['input_179[0][0]']           \n",
            "                                                                                                  \n",
            " embedder_7 (Embedding)      (None, 1, 8)                 40        ['input_180[0][0]']           \n",
            "                                                                                                  \n",
            " embedder_13 (Embedding)     (None, 1, 8)                 80        ['input_186[0][0]']           \n",
            "                                                                                                  \n",
            " embedder_17 (Embedding)     (None, 1, 8)                 40        ['input_190[0][0]']           \n",
            "                                                                                                  \n",
            " embedder_18 (Embedding)     (None, 1, 8)                 72        ['input_191[0][0]']           \n",
            "                                                                                                  \n",
            " embedder_19 (Embedding)     (None, 1, 8)                 16        ['input_192[0][0]']           \n",
            "                                                                                                  \n",
            " embedder_21 (Embedding)     (None, 1, 8)                 16        ['input_194[0][0]']           \n",
            "                                                                                                  \n",
            " embedder_23 (Embedding)     (None, 1, 8)                 24        ['input_196[0][0]']           \n",
            "                                                                                                  \n",
            " embedder_30 (Embedding)     (None, 1, 8)                 96        ['input_203[0][0]']           \n",
            "                                                                                                  \n",
            " embedder_32 (Embedding)     (None, 1, 8)                 40        ['input_205[0][0]']           \n",
            "                                                                                                  \n",
            " embedder_34 (Embedding)     (None, 1, 8)                 32        ['input_207[0][0]']           \n",
            "                                                                                                  \n",
            " embedder_38 (Embedding)     (None, 1, 8)                 40        ['input_211[0][0]']           \n",
            "                                                                                                  \n",
            " embedder_39 (Embedding)     (None, 1, 8)                 40        ['input_212[0][0]']           \n",
            "                                                                                                  \n",
            " embedder_40 (Embedding)     (None, 1, 8)                 40        ['input_213[0][0]']           \n",
            "                                                                                                  \n",
            " tf.expand_dims_116 (TFOpLa  (None, 1, 1)                 0         ['input_173[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_117 (TFOpLa  (None, 1, 1)                 0         ['input_174[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_118 (TFOpLa  (None, 1, 1)                 0         ['input_175[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_119 (TFOpLa  (None, 1, 1)                 0         ['input_176[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_120 (TFOpLa  (None, 1, 1)                 0         ['input_177[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_121 (TFOpLa  (None, 1, 1)                 0         ['input_178[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_122 (TFOpLa  (None, 1, 1)                 0         ['input_181[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_123 (TFOpLa  (None, 1, 1)                 0         ['input_182[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_124 (TFOpLa  (None, 1, 1)                 0         ['input_183[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_125 (TFOpLa  (None, 1, 1)                 0         ['input_184[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_126 (TFOpLa  (None, 1, 1)                 0         ['input_185[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_127 (TFOpLa  (None, 1, 1)                 0         ['input_187[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_128 (TFOpLa  (None, 1, 1)                 0         ['input_188[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_129 (TFOpLa  (None, 1, 1)                 0         ['input_189[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_130 (TFOpLa  (None, 1, 1)                 0         ['input_193[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_131 (TFOpLa  (None, 1, 1)                 0         ['input_195[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_132 (TFOpLa  (None, 1, 1)                 0         ['input_197[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_133 (TFOpLa  (None, 1, 1)                 0         ['input_198[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_134 (TFOpLa  (None, 1, 1)                 0         ['input_199[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_135 (TFOpLa  (None, 1, 1)                 0         ['input_200[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_136 (TFOpLa  (None, 1, 1)                 0         ['input_201[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_137 (TFOpLa  (None, 1, 1)                 0         ['input_202[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_138 (TFOpLa  (None, 1, 1)                 0         ['input_204[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_139 (TFOpLa  (None, 1, 1)                 0         ['input_206[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_140 (TFOpLa  (None, 1, 1)                 0         ['input_208[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_141 (TFOpLa  (None, 1, 1)                 0         ['input_209[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_142 (TFOpLa  (None, 1, 1)                 0         ['input_210[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_143 (TFOpLa  (None, 1, 1)                 0         ['input_214[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_144 (TFOpLa  (None, 1, 1)                 0         ['input_215[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.stack_8 (TFOpLambda)     (None, 14, 1, 8)             0         ['embedder_6[1][0]',          \n",
            "                                                                     'embedder_7[1][0]',          \n",
            "                                                                     'embedder_13[1][0]',         \n",
            "                                                                     'embedder_17[1][0]',         \n",
            "                                                                     'embedder_18[1][0]',         \n",
            "                                                                     'embedder_19[1][0]',         \n",
            "                                                                     'embedder_21[1][0]',         \n",
            "                                                                     'embedder_23[1][0]',         \n",
            "                                                                     'embedder_30[1][0]',         \n",
            "                                                                     'embedder_32[1][0]',         \n",
            "                                                                     'embedder_34[1][0]',         \n",
            "                                                                     'embedder_38[1][0]',         \n",
            "                                                                     'embedder_39[1][0]',         \n",
            "                                                                     'embedder_40[1][0]']         \n",
            "                                                                                                  \n",
            " tf.stack_9 (TFOpLambda)     (None, 29, 1, 1)             0         ['tf.expand_dims_116[1][0]',  \n",
            "                                                                     'tf.expand_dims_117[1][0]',  \n",
            "                                                                     'tf.expand_dims_118[1][0]',  \n",
            "                                                                     'tf.expand_dims_119[1][0]',  \n",
            "                                                                     'tf.expand_dims_120[1][0]',  \n",
            "                                                                     'tf.expand_dims_121[1][0]',  \n",
            "                                                                     'tf.expand_dims_122[1][0]',  \n",
            "                                                                     'tf.expand_dims_123[1][0]',  \n",
            "                                                                     'tf.expand_dims_124[1][0]',  \n",
            "                                                                     'tf.expand_dims_125[1][0]',  \n",
            "                                                                     'tf.expand_dims_126[1][0]',  \n",
            "                                                                     'tf.expand_dims_127[1][0]',  \n",
            "                                                                     'tf.expand_dims_128[1][0]',  \n",
            "                                                                     'tf.expand_dims_129[1][0]',  \n",
            "                                                                     'tf.expand_dims_130[1][0]',  \n",
            "                                                                     'tf.expand_dims_131[1][0]',  \n",
            "                                                                     'tf.expand_dims_132[1][0]',  \n",
            "                                                                     'tf.expand_dims_133[1][0]',  \n",
            "                                                                     'tf.expand_dims_134[1][0]',  \n",
            "                                                                     'tf.expand_dims_135[1][0]',  \n",
            "                                                                     'tf.expand_dims_136[1][0]',  \n",
            "                                                                     'tf.expand_dims_137[1][0]',  \n",
            "                                                                     'tf.expand_dims_138[1][0]',  \n",
            "                                                                     'tf.expand_dims_139[1][0]',  \n",
            "                                                                     'tf.expand_dims_140[1][0]',  \n",
            "                                                                     'tf.expand_dims_141[1][0]',  \n",
            "                                                                     'tf.expand_dims_142[1][0]',  \n",
            "                                                                     'tf.expand_dims_143[1][0]',  \n",
            "                                                                     'tf.expand_dims_144[1][0]']  \n",
            "                                                                                                  \n",
            " flatten_10 (Flatten)        (None, 112)                  0         ['tf.stack_8[1][0]']          \n",
            "                                                                                                  \n",
            " flatten_11 (Flatten)        (None, 29)                   0         ['tf.stack_9[1][0]']          \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 141)                  0         ['flatten_10[1][0]',          \n",
            " )                                                                   'flatten_11[1][0]']          \n",
            "                                                                                                  \n",
            " flatten_12 (Flatten)        (None, 141)                  0         ['concatenate_4[1][0]']       \n",
            "                                                                                                  \n",
            " dense_block_8 (dense_block  (None, 256)                  37376     ['flatten_12[1][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense_block_9 (dense_block  (None, 256)                  66816     ['dense_block_8[1][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 1)                    257       ['dense_block_9[1][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 105065 (410.41 KB)\n",
            "Trainable params: 104041 (406.41 KB)\n",
            "Non-trainable params: 1024 (4.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = create_baseline_model(feature_space,num_dense_exp=False,embedding_dims=8)\n",
        "model.summary(expand_nested=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verify_model = model.predict(preprocessed_train_ds)\n",
        "verify_model.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHTrsow0VoCl",
        "outputId": "4c8a4e99-9da2-45d9-8d88-d0cfd07086f0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5158/5158 [==============================] - 21s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(165034, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(preprocessed_train_ds, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gLFYl0Oav7x",
        "outputId": "4546cb06-6dea-47ca-b88a-de3984a95f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05946372449398041, 0.7833811640739441]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Optuna Optimization:"
      ],
      "metadata": {
        "id": "E6q_jUbKiDOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model creation\n",
        "def create_baseline_model_trial(trial):\n",
        "\n",
        "    units_0 = trial.suggest_categorical(\"units_0\", [256, 512, 768, 1024])\n",
        "    activation = trial.suggest_categorical(\"activation\", [\"swish\"])\n",
        "    dropout = trial.suggest_categorical(\"dropout\", [0.25, 0.33, 0.5])\n",
        "    hidden_layers = trial.suggest_int(\"hidden_layers\", 2, 4)\n",
        "    embedding_dims = trial.suggest_int(\"embedding_dims\", 8, 32, step=8)\n",
        "    #kr = trial.suggest_categorical(\"kr\", [0, 0.1, 1.0])\n",
        "    #num_dense_exp = trial.suggest_categorical('num_dense_exp', [True, False])\n",
        "\n",
        "\n",
        "    model = create_baseline_model(feature_space,name=\"baseline_model\",learning_rate = 0.005,\n",
        "                                  activation=activation,dropout=dropout,hidden_layers=hidden_layers,\n",
        "                                  units_0=units_0,kr=0,num_dense_exp=True, embedding_dims=embedding_dims)\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "P9YqZnTAprmT"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33pxQ6Qx4aGl",
        "outputId": "4487f848-46aa-43f2-fe17-03e8645356e3"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1398"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get hardware strategy\n",
        "def get_hardware_strategy():\n",
        "    try:\n",
        "        # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
        "        # set: this is always the case on Kaggle.\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "        print('Running on TPU ', tpu.master())\n",
        "    except ValueError:\n",
        "        tpu = None\n",
        "\n",
        "    if tpu:\n",
        "        tf.config.experimental_connect_to_cluster(tpu)\n",
        "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "        tf.config.optimizer.set_jit(True)\n",
        "    else:\n",
        "        # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "        strategy = tf.distribute.get_strategy()\n",
        "\n",
        "    return tpu, strategy\n",
        "\n",
        "tpu, strategy = get_hardware_strategy()"
      ],
      "metadata": {
        "id": "cTArFCyPiRLL"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_var,num_var"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLVotecCaZ0I",
        "outputId": "b66bcd72-99e8-44c3-991f-f1eb4be0859a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Index(['act_nop', 'bs_nop_count_label', 'HasCrCard', 'IsActiveMember',\n",
              "        'CreditScore_unimp_cluster_WOE', 'bs_nop',\n",
              "        'Geography_count_label-NumOfProducts_cat_count', 'act_age',\n",
              "        'Geography_count/NumOfProducts_cat_count_label', 'bs_active',\n",
              "        'Balance_Range', 'bs_nop_count', 'NumOfProducts_cat_count',\n",
              "        'Balance_Range_count'],\n",
              "       dtype='object'),\n",
              " Index(['Age_Category_enc', 'bs_nop_enc', 'Surname_tfidf_1', 'Age_pca_comb',\n",
              "        'Age-NumOfProducts_cat_count', 'act_age_enc',\n",
              "        'Age_cat*NumOfProducts_cat_count_label', 'CustomerId',\n",
              "        'IsActiveMember_enc', 'CreditScore_cat_pca_comb_final',\n",
              "        'Age_pca_comb_pca_comb_final', 'bs_gender_enc', 'quant_EstimatedSalary',\n",
              "        'Surname_tfidf_2', 'Surname_tfidf_3', 'Gender_enc', 'Tenure_enc',\n",
              "        'Balance_Range_enc', 'Surname_tfidf_4',\n",
              "        'Balance-NumOfProducts_cat_count_label', 'Geo_Gender_enc',\n",
              "        'Balance_pca_comb', 'Balance_Salary', 'bs_active_enc', 'act_nop_enc',\n",
              "        'CreditScore_pca_comb_final', 'Surname_tfidf_0', 'HasCrCard_enc',\n",
              "        'bs_age_enc'],\n",
              "       dtype='object'))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kf = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=1978)\n",
        "\n",
        "def objective(trial):\n",
        "    validation=0.2\n",
        "    # Clear clutter from previous session graphs.\n",
        "    keras.backend.clear_session()\n",
        "    #keras.utils.clear_session()\n",
        "    # Trial Score\n",
        "    Scores_try=[]\n",
        "\n",
        "    # define Dataset:\n",
        "    for k, (train_index, test_index) in enumerate(kf.split(X, X[\"Exited\"])):\n",
        "\n",
        "        train_examples = len(train_index)\n",
        "        train_examples = int(train_examples * (1 - validation))\n",
        "        train_index, val_index = train_index[:train_examples], train_index[train_examples:]\n",
        "\n",
        "        train_x, valid_x = X.iloc[train_index,:], X.iloc[val_index,:]\n",
        "        test_x_ = X.iloc[test_index,:]\n",
        "\n",
        "        train_dataset_ = dataframe_to_dataset(train_x, batch_size=256, shuffle=True)\n",
        "        valid_dataset_ = dataframe_to_dataset(valid_x, batch_size=256, shuffle=True)\n",
        "        test_dataset_ = dataframe_to_dataset(test_x_, batch_size=256, shuffle=False)\n",
        "\n",
        "        feature_space = FeatureSpace(\n",
        "                                    features={**{a:FeatureSpace.integer_categorical(num_oov_indices=0, output_mode=\"int\") for a in cat_var},**{b:FeatureSpace.float() for b in num_var}},\n",
        "                                    output_mode=\"dict\"\n",
        "                                    )\n",
        "\n",
        "        train_ds_with_no_labels = train_dataset_.map(lambda x, *_: x)\n",
        "        print(\"Adapting Features Space....\")\n",
        "        feature_space.adapt(train_ds_with_no_labels)\n",
        "\n",
        "#        preprocessed_train_ds = train_dataset_.map(lambda x, y, w: (feature_space(x), y, w), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "#        preprocessed_valid_ds = valid_dataset_.map(lambda x, y, w: (feature_space(x), y, w), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "#        preprocessed_test_ds = test_dataset_.map(lambda x, y, w: (feature_space(x), y, w), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "        preprocessed_train_ds = train_dataset_.map(lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "        preprocessed_valid_ds = valid_dataset_.map(lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "        preprocessed_test_ds = test_dataset_.map(lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "        model = create_baseline_model_trial(trial)\n",
        "\n",
        "        stop_early = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=12, restore_best_weights=True, start_from_epoch=5)\n",
        "        reduce_ = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=0.00001)\n",
        "\n",
        "\n",
        "        model.fit(preprocessed_train_ds,\n",
        "                  epochs=60,\n",
        "                  callbacks=[stop_early,reduce_,TFKerasPruningCallback(trial, \"auc\")],\n",
        "                  validation_data=preprocessed_valid_ds)\n",
        "\n",
        "\n",
        "        score_ = model.evaluate(preprocessed_test_ds, verbose=0)\n",
        "        Scores_try.append(score_[1])\n",
        "\n",
        "    # Evaluate the model accuracy on the validation set.\n",
        "    score = np.mean(Scores_try)\n",
        "    del feature_space\n",
        "    del model\n",
        "    del preprocessed_train_ds\n",
        "    del preprocessed_valid_ds\n",
        "    del preprocessed_test_ds\n",
        "    gc.collect()\n",
        "\n",
        "    return score"
      ],
      "metadata": {
        "id": "HMsicDvAiRIY"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create study object\n",
        "study = optuna.create_study(direction=\"maximize\", study_name=\"baseline_opt_all\", pruner=optuna.pruners.MedianPruner(n_warmup_steps=5))\n",
        "\n",
        "# Run optimization process\n",
        "study.optimize(objective, n_trials=10, show_progress_bar=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4e7b09d4602844f78fbc00d1a72e9b9d",
            "d4da8c405f374a70b1d61288d9b2ca08",
            "0dc12204ae7c41078696860c9b34bba1",
            "d1a2d6e4d1f842358193df9c39b0f179",
            "910982c8c76d4a4993158d4c3888b71f",
            "91fa00491a4f40549e62cd4f31a7518e",
            "fbca1ebdb5a74353b7dad4272dd1350e",
            "b33c49b555604c95a395c4692c10f7cb",
            "99bb684ea3574eeab76cf08d17501cf6",
            "dad4e08181794591a7acd3498892945c",
            "f39717b8199342b0b8e191e91c2ca57b"
          ]
        },
        "id": "nWJeXN-oiRFe",
        "outputId": "ef5b9e3d-e1d3-4873-c0ff-36fa5906826d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-01-29 11:59:31,636] A new study created in memory with name: baseline_opt_all\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e7b09d4602844f78fbc00d1a72e9b9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 26s 28ms/step - loss: 0.0581 - auc: 0.8521 - val_loss: 0.0449 - val_auc: 0.8802 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0441 - auc: 0.8747 - val_loss: 0.0447 - val_auc: 0.8808 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0439 - auc: 0.8760 - val_loss: 0.0474 - val_auc: 0.8800 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0433 - auc: 0.8786 - val_loss: 0.0450 - val_auc: 0.8811 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0434 - auc: 0.8785 - val_loss: 0.0431 - val_auc: 0.8831 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0426 - auc: 0.8818 - val_loss: 0.0430 - val_auc: 0.8809 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0427 - auc: 0.8816 - val_loss: 0.0425 - val_auc: 0.8835 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0426 - auc: 0.8819 - val_loss: 0.0428 - val_auc: 0.8816 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0424 - auc: 0.8831 - val_loss: 0.0431 - val_auc: 0.8837 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0424 - auc: 0.8830 - val_loss: 0.0429 - val_auc: 0.8833 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0424 - auc: 0.8831 - val_loss: 0.0426 - val_auc: 0.8834 - lr: 0.0050\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0418 - auc: 0.8862 - val_loss: 0.0424 - val_auc: 0.8842 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0418 - auc: 0.8864 - val_loss: 0.0425 - val_auc: 0.8842 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0418 - auc: 0.8860 - val_loss: 0.0426 - val_auc: 0.8842 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0417 - auc: 0.8867 - val_loss: 0.0424 - val_auc: 0.8841 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0414 - auc: 0.8881 - val_loss: 0.0422 - val_auc: 0.8845 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0415 - auc: 0.8879 - val_loss: 0.0424 - val_auc: 0.8838 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0414 - auc: 0.8884 - val_loss: 0.0425 - val_auc: 0.8850 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0413 - auc: 0.8886 - val_loss: 0.0424 - val_auc: 0.8841 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0413 - auc: 0.8887 - val_loss: 0.0422 - val_auc: 0.8845 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0412 - auc: 0.8896 - val_loss: 0.0423 - val_auc: 0.8840 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0411 - auc: 0.8899 - val_loss: 0.0424 - val_auc: 0.8843 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0411 - auc: 0.8900 - val_loss: 0.0423 - val_auc: 0.8839 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 20ms/step - loss: 0.0410 - auc: 0.8904 - val_loss: 0.0429 - val_auc: 0.8802 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 20ms/step - loss: 0.0409 - auc: 0.8907 - val_loss: 0.0424 - val_auc: 0.8841 - lr: 3.1250e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0409 - auc: 0.8910 - val_loss: 0.0423 - val_auc: 0.8844 - lr: 3.1250e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0409 - auc: 0.8911 - val_loss: 0.0423 - val_auc: 0.8837 - lr: 3.1250e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 8s 20ms/step - loss: 0.0408 - auc: 0.8914 - val_loss: 0.0424 - val_auc: 0.8836 - lr: 3.1250e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0407 - auc: 0.8923 - val_loss: 0.0424 - val_auc: 0.8838 - lr: 1.5625e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0408 - auc: 0.8917 - val_loss: 0.0423 - val_auc: 0.8841 - lr: 1.5625e-04\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0407 - auc: 0.8921 - val_loss: 0.0423 - val_auc: 0.8839 - lr: 1.5625e-04\n",
            "Epoch 32/60\n",
            "344/344 [==============================] - 8s 20ms/step - loss: 0.0407 - auc: 0.8920 - val_loss: 0.0424 - val_auc: 0.8838 - lr: 1.5625e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 23s 28ms/step - loss: 0.0554 - auc: 0.8563 - val_loss: 0.0458 - val_auc: 0.8843 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0441 - auc: 0.8753 - val_loss: 0.0466 - val_auc: 0.8856 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0437 - auc: 0.8773 - val_loss: 0.0420 - val_auc: 0.8858 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0428 - auc: 0.8816 - val_loss: 0.0422 - val_auc: 0.8854 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0427 - auc: 0.8816 - val_loss: 0.0426 - val_auc: 0.8859 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0426 - auc: 0.8823 - val_loss: 0.0428 - val_auc: 0.8829 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0426 - auc: 0.8826 - val_loss: 0.0434 - val_auc: 0.8846 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0420 - auc: 0.8854 - val_loss: 0.0418 - val_auc: 0.8873 - lr: 0.0025\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0417 - auc: 0.8868 - val_loss: 0.0421 - val_auc: 0.8864 - lr: 0.0025\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0418 - auc: 0.8866 - val_loss: 0.0421 - val_auc: 0.8856 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0418 - auc: 0.8866 - val_loss: 0.0420 - val_auc: 0.8865 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0418 - auc: 0.8866 - val_loss: 0.0419 - val_auc: 0.8868 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0415 - auc: 0.8882 - val_loss: 0.0416 - val_auc: 0.8872 - lr: 0.0012\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8890 - val_loss: 0.0416 - val_auc: 0.8875 - lr: 0.0012\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0413 - auc: 0.8890 - val_loss: 0.0419 - val_auc: 0.8863 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0412 - auc: 0.8895 - val_loss: 0.0418 - val_auc: 0.8873 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8892 - val_loss: 0.0418 - val_auc: 0.8867 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8908 - val_loss: 0.0416 - val_auc: 0.8873 - lr: 6.2500e-04\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8904 - val_loss: 0.0416 - val_auc: 0.8875 - lr: 6.2500e-04\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8907 - val_loss: 0.0417 - val_auc: 0.8876 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8913 - val_loss: 0.0418 - val_auc: 0.8871 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0407 - auc: 0.8925 - val_loss: 0.0417 - val_auc: 0.8871 - lr: 3.1250e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0407 - auc: 0.8922 - val_loss: 0.0418 - val_auc: 0.8874 - lr: 3.1250e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0407 - auc: 0.8924 - val_loss: 0.0417 - val_auc: 0.8873 - lr: 3.1250e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0407 - auc: 0.8926 - val_loss: 0.0417 - val_auc: 0.8870 - lr: 3.1250e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0406 - auc: 0.8930 - val_loss: 0.0417 - val_auc: 0.8872 - lr: 1.5625e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0406 - auc: 0.8929 - val_loss: 0.0417 - val_auc: 0.8873 - lr: 1.5625e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0405 - auc: 0.8932 - val_loss: 0.0418 - val_auc: 0.8870 - lr: 1.5625e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0406 - auc: 0.8930 - val_loss: 0.0418 - val_auc: 0.8871 - lr: 1.5625e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0405 - auc: 0.8936 - val_loss: 0.0417 - val_auc: 0.8872 - lr: 7.8125e-05\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0405 - auc: 0.8933 - val_loss: 0.0417 - val_auc: 0.8870 - lr: 7.8125e-05\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 29ms/step - loss: 0.0542 - auc: 0.8576 - val_loss: 0.0440 - val_auc: 0.8748 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0452 - auc: 0.8716 - val_loss: 0.0440 - val_auc: 0.8830 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0431 - auc: 0.8796 - val_loss: 0.0457 - val_auc: 0.8838 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0431 - auc: 0.8800 - val_loss: 0.0430 - val_auc: 0.8825 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0427 - auc: 0.8819 - val_loss: 0.0424 - val_auc: 0.8827 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0426 - auc: 0.8824 - val_loss: 0.0421 - val_auc: 0.8842 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0424 - auc: 0.8833 - val_loss: 0.0424 - val_auc: 0.8838 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0423 - auc: 0.8840 - val_loss: 0.0425 - val_auc: 0.8844 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0422 - auc: 0.8849 - val_loss: 0.0425 - val_auc: 0.8830 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0421 - auc: 0.8850 - val_loss: 0.0420 - val_auc: 0.8845 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0421 - auc: 0.8850 - val_loss: 0.0425 - val_auc: 0.8845 - lr: 0.0050\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0419 - auc: 0.8858 - val_loss: 0.0428 - val_auc: 0.8827 - lr: 0.0050\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0419 - auc: 0.8863 - val_loss: 0.0422 - val_auc: 0.8851 - lr: 0.0050\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0419 - auc: 0.8862 - val_loss: 0.0419 - val_auc: 0.8852 - lr: 0.0050\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0415 - auc: 0.8883 - val_loss: 0.0421 - val_auc: 0.8852 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0414 - auc: 0.8891 - val_loss: 0.0422 - val_auc: 0.8844 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0414 - auc: 0.8892 - val_loss: 0.0419 - val_auc: 0.8850 - lr: 0.0025\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0412 - auc: 0.8895 - val_loss: 0.0420 - val_auc: 0.8852 - lr: 0.0025\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0410 - auc: 0.8908 - val_loss: 0.0419 - val_auc: 0.8857 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0409 - auc: 0.8912 - val_loss: 0.0422 - val_auc: 0.8844 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0409 - auc: 0.8914 - val_loss: 0.0419 - val_auc: 0.8850 - lr: 0.0012\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0409 - auc: 0.8912 - val_loss: 0.0422 - val_auc: 0.8837 - lr: 0.0012\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0409 - auc: 0.8915 - val_loss: 0.0420 - val_auc: 0.8850 - lr: 0.0012\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0406 - auc: 0.8930 - val_loss: 0.0420 - val_auc: 0.8847 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0406 - auc: 0.8930 - val_loss: 0.0420 - val_auc: 0.8846 - lr: 6.2500e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0406 - auc: 0.8932 - val_loss: 0.0421 - val_auc: 0.8848 - lr: 6.2500e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0406 - auc: 0.8933 - val_loss: 0.0420 - val_auc: 0.8847 - lr: 6.2500e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0404 - auc: 0.8944 - val_loss: 0.0420 - val_auc: 0.8843 - lr: 3.1250e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0404 - auc: 0.8943 - val_loss: 0.0421 - val_auc: 0.8843 - lr: 3.1250e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0403 - auc: 0.8945 - val_loss: 0.0420 - val_auc: 0.8847 - lr: 3.1250e-04\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0403 - auc: 0.8948 - val_loss: 0.0421 - val_auc: 0.8840 - lr: 3.1250e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 30ms/step - loss: 0.0559 - auc: 0.8575 - val_loss: 0.0437 - val_auc: 0.8761 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0444 - auc: 0.8743 - val_loss: 0.0449 - val_auc: 0.8702 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0433 - auc: 0.8792 - val_loss: 0.0431 - val_auc: 0.8826 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0432 - auc: 0.8796 - val_loss: 0.0486 - val_auc: 0.8814 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0432 - auc: 0.8802 - val_loss: 0.0423 - val_auc: 0.8830 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0426 - auc: 0.8826 - val_loss: 0.0431 - val_auc: 0.8797 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0425 - auc: 0.8835 - val_loss: 0.0426 - val_auc: 0.8823 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0424 - auc: 0.8835 - val_loss: 0.0424 - val_auc: 0.8838 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0422 - auc: 0.8843 - val_loss: 0.0426 - val_auc: 0.8837 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0417 - auc: 0.8873 - val_loss: 0.0423 - val_auc: 0.8837 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0416 - auc: 0.8875 - val_loss: 0.0420 - val_auc: 0.8843 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0416 - auc: 0.8877 - val_loss: 0.0421 - val_auc: 0.8842 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0416 - auc: 0.8878 - val_loss: 0.0422 - val_auc: 0.8843 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0417 - auc: 0.8875 - val_loss: 0.0421 - val_auc: 0.8842 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0416 - auc: 0.8876 - val_loss: 0.0424 - val_auc: 0.8839 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0413 - auc: 0.8896 - val_loss: 0.0421 - val_auc: 0.8835 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0412 - auc: 0.8898 - val_loss: 0.0421 - val_auc: 0.8842 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0412 - auc: 0.8898 - val_loss: 0.0422 - val_auc: 0.8836 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0412 - auc: 0.8899 - val_loss: 0.0421 - val_auc: 0.8845 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0410 - auc: 0.8909 - val_loss: 0.0421 - val_auc: 0.8837 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0409 - auc: 0.8914 - val_loss: 0.0420 - val_auc: 0.8843 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0408 - auc: 0.8919 - val_loss: 0.0421 - val_auc: 0.8840 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0408 - auc: 0.8920 - val_loss: 0.0423 - val_auc: 0.8835 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0408 - auc: 0.8924 - val_loss: 0.0421 - val_auc: 0.8841 - lr: 3.1250e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0407 - auc: 0.8924 - val_loss: 0.0421 - val_auc: 0.8844 - lr: 3.1250e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0406 - auc: 0.8930 - val_loss: 0.0421 - val_auc: 0.8841 - lr: 3.1250e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0406 - auc: 0.8931 - val_loss: 0.0422 - val_auc: 0.8836 - lr: 3.1250e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0405 - auc: 0.8936 - val_loss: 0.0422 - val_auc: 0.8842 - lr: 1.5625e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0405 - auc: 0.8937 - val_loss: 0.0421 - val_auc: 0.8842 - lr: 1.5625e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0404 - auc: 0.8941 - val_loss: 0.0422 - val_auc: 0.8838 - lr: 1.5625e-04\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0405 - auc: 0.8933 - val_loss: 0.0421 - val_auc: 0.8841 - lr: 1.5625e-04\n",
            "Epoch 32/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0405 - auc: 0.8939 - val_loss: 0.0421 - val_auc: 0.8838 - lr: 7.8125e-05\n",
            "Epoch 33/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0404 - auc: 0.8942 - val_loss: 0.0422 - val_auc: 0.8839 - lr: 7.8125e-05\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 25s 29ms/step - loss: 0.0576 - auc: 0.8501 - val_loss: 0.0430 - val_auc: 0.8843 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0444 - auc: 0.8726 - val_loss: 0.0421 - val_auc: 0.8854 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0441 - auc: 0.8743 - val_loss: 0.0431 - val_auc: 0.8842 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0434 - auc: 0.8778 - val_loss: 0.0435 - val_auc: 0.8864 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0429 - auc: 0.8801 - val_loss: 0.0426 - val_auc: 0.8868 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0427 - auc: 0.8815 - val_loss: 0.0431 - val_auc: 0.8853 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0421 - auc: 0.8843 - val_loss: 0.0422 - val_auc: 0.8869 - lr: 0.0025\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0419 - auc: 0.8852 - val_loss: 0.0417 - val_auc: 0.8875 - lr: 0.0025\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0421 - auc: 0.8844 - val_loss: 0.0418 - val_auc: 0.8881 - lr: 0.0025\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0420 - auc: 0.8847 - val_loss: 0.0421 - val_auc: 0.8861 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0420 - auc: 0.8849 - val_loss: 0.0422 - val_auc: 0.8877 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0420 - auc: 0.8849 - val_loss: 0.0420 - val_auc: 0.8872 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0416 - auc: 0.8870 - val_loss: 0.0418 - val_auc: 0.8875 - lr: 0.0012\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0416 - auc: 0.8870 - val_loss: 0.0420 - val_auc: 0.8876 - lr: 0.0012\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0416 - auc: 0.8871 - val_loss: 0.0419 - val_auc: 0.8872 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0416 - auc: 0.8871 - val_loss: 0.0419 - val_auc: 0.8870 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8889 - val_loss: 0.0417 - val_auc: 0.8876 - lr: 6.2500e-04\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0412 - auc: 0.8889 - val_loss: 0.0418 - val_auc: 0.8880 - lr: 6.2500e-04\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8887 - val_loss: 0.0418 - val_auc: 0.8872 - lr: 6.2500e-04\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0412 - auc: 0.8892 - val_loss: 0.0418 - val_auc: 0.8879 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0411 - auc: 0.8900 - val_loss: 0.0418 - val_auc: 0.8877 - lr: 3.1250e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0410 - auc: 0.8903 - val_loss: 0.0418 - val_auc: 0.8875 - lr: 3.1250e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0410 - auc: 0.8902 - val_loss: 0.0417 - val_auc: 0.8877 - lr: 3.1250e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0410 - auc: 0.8904 - val_loss: 0.0419 - val_auc: 0.8873 - lr: 3.1250e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0409 - auc: 0.8910 - val_loss: 0.0418 - val_auc: 0.8875 - lr: 1.5625e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0409 - auc: 0.8912 - val_loss: 0.0418 - val_auc: 0.8877 - lr: 1.5625e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0408 - auc: 0.8915 - val_loss: 0.0418 - val_auc: 0.8877 - lr: 1.5625e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0408 - auc: 0.8915 - val_loss: 0.0419 - val_auc: 0.8876 - lr: 1.5625e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0407 - auc: 0.8917 - val_loss: 0.0418 - val_auc: 0.8875 - lr: 7.8125e-05\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0408 - auc: 0.8915 - val_loss: 0.0418 - val_auc: 0.8875 - lr: 7.8125e-05\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0408 - auc: 0.8916 - val_loss: 0.0418 - val_auc: 0.8874 - lr: 7.8125e-05\n",
            "Epoch 32/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0407 - auc: 0.8918 - val_loss: 0.0418 - val_auc: 0.8873 - lr: 7.8125e-05\n",
            "Epoch 33/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0407 - auc: 0.8919 - val_loss: 0.0418 - val_auc: 0.8873 - lr: 3.9062e-05\n",
            "Epoch 34/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0408 - auc: 0.8917 - val_loss: 0.0418 - val_auc: 0.8873 - lr: 3.9062e-05\n",
            "Epoch 35/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0406 - auc: 0.8925 - val_loss: 0.0419 - val_auc: 0.8872 - lr: 3.9062e-05\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 23s 29ms/step - loss: 0.0553 - auc: 0.8566 - val_loss: 0.0449 - val_auc: 0.8756 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0448 - auc: 0.8719 - val_loss: 0.0426 - val_auc: 0.8830 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0435 - auc: 0.8780 - val_loss: 0.0426 - val_auc: 0.8836 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0431 - auc: 0.8794 - val_loss: 0.0435 - val_auc: 0.8825 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0429 - auc: 0.8811 - val_loss: 0.0427 - val_auc: 0.8843 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0428 - auc: 0.8811 - val_loss: 0.0429 - val_auc: 0.8840 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0420 - auc: 0.8856 - val_loss: 0.0421 - val_auc: 0.8846 - lr: 0.0025\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0419 - auc: 0.8857 - val_loss: 0.0423 - val_auc: 0.8850 - lr: 0.0025\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0419 - auc: 0.8854 - val_loss: 0.0430 - val_auc: 0.8855 - lr: 0.0025\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0419 - auc: 0.8863 - val_loss: 0.0423 - val_auc: 0.8851 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0420 - auc: 0.8857 - val_loss: 0.0422 - val_auc: 0.8838 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0415 - auc: 0.8877 - val_loss: 0.0419 - val_auc: 0.8856 - lr: 0.0012\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0415 - auc: 0.8883 - val_loss: 0.0419 - val_auc: 0.8855 - lr: 0.0012\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0415 - auc: 0.8881 - val_loss: 0.0424 - val_auc: 0.8854 - lr: 0.0012\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0414 - auc: 0.8888 - val_loss: 0.0420 - val_auc: 0.8853 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0415 - auc: 0.8882 - val_loss: 0.0423 - val_auc: 0.8848 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0412 - auc: 0.8898 - val_loss: 0.0421 - val_auc: 0.8855 - lr: 6.2500e-04\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0411 - auc: 0.8902 - val_loss: 0.0419 - val_auc: 0.8851 - lr: 6.2500e-04\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0412 - auc: 0.8897 - val_loss: 0.0419 - val_auc: 0.8861 - lr: 6.2500e-04\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0410 - auc: 0.8904 - val_loss: 0.0421 - val_auc: 0.8852 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0409 - auc: 0.8912 - val_loss: 0.0419 - val_auc: 0.8858 - lr: 3.1250e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0408 - auc: 0.8918 - val_loss: 0.0419 - val_auc: 0.8856 - lr: 3.1250e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0408 - auc: 0.8916 - val_loss: 0.0419 - val_auc: 0.8852 - lr: 3.1250e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0408 - auc: 0.8919 - val_loss: 0.0419 - val_auc: 0.8855 - lr: 3.1250e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0407 - auc: 0.8924 - val_loss: 0.0419 - val_auc: 0.8858 - lr: 1.5625e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0406 - auc: 0.8927 - val_loss: 0.0419 - val_auc: 0.8856 - lr: 1.5625e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0406 - auc: 0.8929 - val_loss: 0.0419 - val_auc: 0.8857 - lr: 1.5625e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0406 - auc: 0.8928 - val_loss: 0.0419 - val_auc: 0.8857 - lr: 1.5625e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0406 - auc: 0.8930 - val_loss: 0.0419 - val_auc: 0.8855 - lr: 7.8125e-05\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0406 - auc: 0.8931 - val_loss: 0.0419 - val_auc: 0.8856 - lr: 7.8125e-05\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0405 - auc: 0.8931 - val_loss: 0.0419 - val_auc: 0.8854 - lr: 7.8125e-05\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 29ms/step - loss: 0.0544 - auc: 0.8552 - val_loss: 0.0446 - val_auc: 0.8843 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0444 - auc: 0.8742 - val_loss: 0.0441 - val_auc: 0.8731 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0434 - auc: 0.8788 - val_loss: 0.0429 - val_auc: 0.8843 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0432 - auc: 0.8795 - val_loss: 0.0424 - val_auc: 0.8825 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0431 - auc: 0.8806 - val_loss: 0.0425 - val_auc: 0.8883 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0427 - auc: 0.8819 - val_loss: 0.0422 - val_auc: 0.8852 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0425 - auc: 0.8834 - val_loss: 0.0421 - val_auc: 0.8881 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0423 - auc: 0.8840 - val_loss: 0.0421 - val_auc: 0.8879 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0424 - auc: 0.8838 - val_loss: 0.0417 - val_auc: 0.8876 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0421 - auc: 0.8850 - val_loss: 0.0428 - val_auc: 0.8873 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0421 - auc: 0.8853 - val_loss: 0.0421 - val_auc: 0.8880 - lr: 0.0050\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0423 - auc: 0.8847 - val_loss: 0.0417 - val_auc: 0.8881 - lr: 0.0050\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0419 - auc: 0.8859 - val_loss: 0.0427 - val_auc: 0.8870 - lr: 0.0050\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0415 - auc: 0.8881 - val_loss: 0.0414 - val_auc: 0.8883 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0415 - auc: 0.8882 - val_loss: 0.0414 - val_auc: 0.8888 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0414 - auc: 0.8886 - val_loss: 0.0417 - val_auc: 0.8878 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0415 - auc: 0.8884 - val_loss: 0.0416 - val_auc: 0.8882 - lr: 0.0025\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0415 - auc: 0.8885 - val_loss: 0.0418 - val_auc: 0.8871 - lr: 0.0025\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8896 - val_loss: 0.0417 - val_auc: 0.8883 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0411 - auc: 0.8904 - val_loss: 0.0414 - val_auc: 0.8883 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0411 - auc: 0.8905 - val_loss: 0.0414 - val_auc: 0.8888 - lr: 0.0012\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0410 - auc: 0.8911 - val_loss: 0.0414 - val_auc: 0.8886 - lr: 0.0012\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0408 - auc: 0.8919 - val_loss: 0.0415 - val_auc: 0.8887 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0408 - auc: 0.8922 - val_loss: 0.0414 - val_auc: 0.8883 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0407 - auc: 0.8928 - val_loss: 0.0415 - val_auc: 0.8885 - lr: 6.2500e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0407 - auc: 0.8927 - val_loss: 0.0416 - val_auc: 0.8873 - lr: 6.2500e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0406 - auc: 0.8933 - val_loss: 0.0414 - val_auc: 0.8881 - lr: 3.1250e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0405 - auc: 0.8936 - val_loss: 0.0415 - val_auc: 0.8879 - lr: 3.1250e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0405 - auc: 0.8938 - val_loss: 0.0414 - val_auc: 0.8879 - lr: 3.1250e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0404 - auc: 0.8944 - val_loss: 0.0415 - val_auc: 0.8880 - lr: 3.1250e-04\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0404 - auc: 0.8944 - val_loss: 0.0415 - val_auc: 0.8881 - lr: 1.5625e-04\n",
            "Epoch 32/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0403 - auc: 0.8947 - val_loss: 0.0415 - val_auc: 0.8880 - lr: 1.5625e-04\n",
            "Epoch 33/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0404 - auc: 0.8943 - val_loss: 0.0416 - val_auc: 0.8874 - lr: 1.5625e-04\n",
            "Epoch 34/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0403 - auc: 0.8947 - val_loss: 0.0415 - val_auc: 0.8879 - lr: 1.5625e-04\n",
            "Epoch 35/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0403 - auc: 0.8948 - val_loss: 0.0416 - val_auc: 0.8878 - lr: 7.8125e-05\n",
            "Epoch 36/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0402 - auc: 0.8951 - val_loss: 0.0416 - val_auc: 0.8876 - lr: 7.8125e-05\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 23s 29ms/step - loss: 0.0540 - auc: 0.8563 - val_loss: 0.0446 - val_auc: 0.8782 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0449 - auc: 0.8715 - val_loss: 0.0453 - val_auc: 0.8791 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0434 - auc: 0.8780 - val_loss: 0.0433 - val_auc: 0.8809 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0430 - auc: 0.8803 - val_loss: 0.0433 - val_auc: 0.8815 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0427 - auc: 0.8811 - val_loss: 0.0448 - val_auc: 0.8827 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0425 - auc: 0.8823 - val_loss: 0.0430 - val_auc: 0.8814 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0424 - auc: 0.8830 - val_loss: 0.0435 - val_auc: 0.8809 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0424 - auc: 0.8832 - val_loss: 0.0427 - val_auc: 0.8827 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0422 - auc: 0.8840 - val_loss: 0.0434 - val_auc: 0.8819 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0422 - auc: 0.8838 - val_loss: 0.0435 - val_auc: 0.8820 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0421 - auc: 0.8845 - val_loss: 0.0437 - val_auc: 0.8817 - lr: 0.0050\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0420 - auc: 0.8855 - val_loss: 0.0427 - val_auc: 0.8825 - lr: 0.0050\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0416 - auc: 0.8874 - val_loss: 0.0425 - val_auc: 0.8838 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0415 - auc: 0.8879 - val_loss: 0.0426 - val_auc: 0.8829 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0415 - auc: 0.8876 - val_loss: 0.0425 - val_auc: 0.8833 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0415 - auc: 0.8880 - val_loss: 0.0426 - val_auc: 0.8825 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0415 - auc: 0.8879 - val_loss: 0.0428 - val_auc: 0.8830 - lr: 0.0025\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0411 - auc: 0.8902 - val_loss: 0.0425 - val_auc: 0.8833 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0410 - auc: 0.8903 - val_loss: 0.0427 - val_auc: 0.8833 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0411 - auc: 0.8901 - val_loss: 0.0428 - val_auc: 0.8822 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8904 - val_loss: 0.0425 - val_auc: 0.8831 - lr: 0.0012\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0408 - auc: 0.8915 - val_loss: 0.0427 - val_auc: 0.8833 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0408 - auc: 0.8919 - val_loss: 0.0425 - val_auc: 0.8833 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0407 - auc: 0.8922 - val_loss: 0.0426 - val_auc: 0.8831 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0407 - auc: 0.8920 - val_loss: 0.0426 - val_auc: 0.8831 - lr: 6.2500e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0406 - auc: 0.8928 - val_loss: 0.0427 - val_auc: 0.8832 - lr: 3.1250e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0405 - auc: 0.8932 - val_loss: 0.0426 - val_auc: 0.8823 - lr: 3.1250e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0405 - auc: 0.8931 - val_loss: 0.0427 - val_auc: 0.8829 - lr: 3.1250e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0405 - auc: 0.8931 - val_loss: 0.0426 - val_auc: 0.8829 - lr: 3.1250e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0404 - auc: 0.8937 - val_loss: 0.0426 - val_auc: 0.8829 - lr: 1.5625e-04\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0404 - auc: 0.8939 - val_loss: 0.0426 - val_auc: 0.8826 - lr: 1.5625e-04\n",
            "Epoch 32/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0404 - auc: 0.8938 - val_loss: 0.0426 - val_auc: 0.8827 - lr: 1.5625e-04\n",
            "Epoch 33/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0404 - auc: 0.8939 - val_loss: 0.0426 - val_auc: 0.8828 - lr: 1.5625e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 22s 26ms/step - loss: 0.0555 - auc: 0.8522 - val_loss: 0.0443 - val_auc: 0.8765 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0447 - auc: 0.8724 - val_loss: 0.0462 - val_auc: 0.8658 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0436 - auc: 0.8773 - val_loss: 0.0427 - val_auc: 0.8827 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0432 - auc: 0.8790 - val_loss: 0.0439 - val_auc: 0.8738 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0430 - auc: 0.8801 - val_loss: 0.0428 - val_auc: 0.8839 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0428 - auc: 0.8809 - val_loss: 0.0423 - val_auc: 0.8849 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0427 - auc: 0.8818 - val_loss: 0.0426 - val_auc: 0.8842 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0424 - auc: 0.8830 - val_loss: 0.0435 - val_auc: 0.8850 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0425 - auc: 0.8824 - val_loss: 0.0423 - val_auc: 0.8849 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0423 - auc: 0.8837 - val_loss: 0.0427 - val_auc: 0.8845 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0419 - auc: 0.8858 - val_loss: 0.0420 - val_auc: 0.8850 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0418 - auc: 0.8859 - val_loss: 0.0428 - val_auc: 0.8836 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0417 - auc: 0.8866 - val_loss: 0.0422 - val_auc: 0.8856 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0417 - auc: 0.8865 - val_loss: 0.0423 - val_auc: 0.8844 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0418 - auc: 0.8861 - val_loss: 0.0421 - val_auc: 0.8847 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 8s 20ms/step - loss: 0.0415 - auc: 0.8878 - val_loss: 0.0418 - val_auc: 0.8857 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0413 - auc: 0.8889 - val_loss: 0.0420 - val_auc: 0.8855 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0413 - auc: 0.8885 - val_loss: 0.0420 - val_auc: 0.8845 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0413 - auc: 0.8889 - val_loss: 0.0423 - val_auc: 0.8853 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0413 - auc: 0.8888 - val_loss: 0.0419 - val_auc: 0.8860 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0411 - auc: 0.8902 - val_loss: 0.0418 - val_auc: 0.8857 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0411 - auc: 0.8899 - val_loss: 0.0420 - val_auc: 0.8846 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0410 - auc: 0.8907 - val_loss: 0.0419 - val_auc: 0.8855 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0410 - auc: 0.8905 - val_loss: 0.0420 - val_auc: 0.8857 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0409 - auc: 0.8911 - val_loss: 0.0419 - val_auc: 0.8852 - lr: 3.1250e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0408 - auc: 0.8916 - val_loss: 0.0419 - val_auc: 0.8854 - lr: 3.1250e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0408 - auc: 0.8915 - val_loss: 0.0420 - val_auc: 0.8849 - lr: 3.1250e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 8s 20ms/step - loss: 0.0407 - auc: 0.8920 - val_loss: 0.0419 - val_auc: 0.8854 - lr: 3.1250e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0407 - auc: 0.8924 - val_loss: 0.0419 - val_auc: 0.8852 - lr: 1.5625e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0406 - auc: 0.8926 - val_loss: 0.0420 - val_auc: 0.8850 - lr: 1.5625e-04\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0407 - auc: 0.8925 - val_loss: 0.0420 - val_auc: 0.8851 - lr: 1.5625e-04\n",
            "Epoch 32/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0406 - auc: 0.8928 - val_loss: 0.0420 - val_auc: 0.8849 - lr: 1.5625e-04\n",
            "Epoch 33/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0406 - auc: 0.8927 - val_loss: 0.0420 - val_auc: 0.8850 - lr: 7.8125e-05\n",
            "[I 2024-01-29 12:59:09,377] Trial 0 finished with value: 0.8868771261639066 and parameters: {'units_0': 1024, 'activation': 'swish', 'dropout': 0.33, 'hidden_layers': 2, 'embedding_dims': 16}. Best is trial 0 with value: 0.8868771261639066.\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 26s 31ms/step - loss: 0.0606 - auc: 0.8590 - val_loss: 0.0445 - val_auc: 0.8812 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0442 - auc: 0.8775 - val_loss: 0.0444 - val_auc: 0.8816 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 11s 27ms/step - loss: 0.0432 - auc: 0.8797 - val_loss: 0.0428 - val_auc: 0.8829 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0427 - auc: 0.8818 - val_loss: 0.0445 - val_auc: 0.8813 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0425 - auc: 0.8823 - val_loss: 0.0427 - val_auc: 0.8831 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0424 - auc: 0.8832 - val_loss: 0.0429 - val_auc: 0.8836 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0423 - auc: 0.8840 - val_loss: 0.0430 - val_auc: 0.8839 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0417 - auc: 0.8869 - val_loss: 0.0430 - val_auc: 0.8846 - lr: 0.0025\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0415 - auc: 0.8876 - val_loss: 0.0426 - val_auc: 0.8840 - lr: 0.0025\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0417 - auc: 0.8870 - val_loss: 0.0424 - val_auc: 0.8842 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0415 - auc: 0.8877 - val_loss: 0.0424 - val_auc: 0.8840 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0415 - auc: 0.8877 - val_loss: 0.0426 - val_auc: 0.8837 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0415 - auc: 0.8879 - val_loss: 0.0425 - val_auc: 0.8835 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0413 - auc: 0.8885 - val_loss: 0.0427 - val_auc: 0.8833 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0408 - auc: 0.8916 - val_loss: 0.0427 - val_auc: 0.8840 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 11s 27ms/step - loss: 0.0408 - auc: 0.8919 - val_loss: 0.0427 - val_auc: 0.8828 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0405 - auc: 0.8933 - val_loss: 0.0426 - val_auc: 0.8832 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0404 - auc: 0.8938 - val_loss: 0.0430 - val_auc: 0.8818 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0398 - auc: 0.8967 - val_loss: 0.0433 - val_auc: 0.8817 - lr: 6.2500e-04\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0398 - auc: 0.8972 - val_loss: 0.0431 - val_auc: 0.8816 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0395 - auc: 0.8988 - val_loss: 0.0432 - val_auc: 0.8811 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0394 - auc: 0.8993 - val_loss: 0.0437 - val_auc: 0.8784 - lr: 6.2500e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 27s 33ms/step - loss: 0.0627 - auc: 0.8570 - val_loss: 0.0435 - val_auc: 0.8849 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0438 - auc: 0.8788 - val_loss: 0.0428 - val_auc: 0.8849 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 11s 27ms/step - loss: 0.0432 - auc: 0.8808 - val_loss: 0.0428 - val_auc: 0.8854 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0427 - auc: 0.8826 - val_loss: 0.0444 - val_auc: 0.8849 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0426 - auc: 0.8831 - val_loss: 0.0421 - val_auc: 0.8866 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0423 - auc: 0.8847 - val_loss: 0.0427 - val_auc: 0.8815 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0423 - auc: 0.8845 - val_loss: 0.0434 - val_auc: 0.8863 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0421 - auc: 0.8846 - val_loss: 0.0421 - val_auc: 0.8865 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0419 - auc: 0.8864 - val_loss: 0.0419 - val_auc: 0.8859 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0420 - auc: 0.8858 - val_loss: 0.0423 - val_auc: 0.8863 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0417 - auc: 0.8867 - val_loss: 0.0432 - val_auc: 0.8861 - lr: 0.0050\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0416 - auc: 0.8878 - val_loss: 0.0426 - val_auc: 0.8849 - lr: 0.0050\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0416 - auc: 0.8880 - val_loss: 0.0425 - val_auc: 0.8863 - lr: 0.0050\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 11s 27ms/step - loss: 0.0410 - auc: 0.8911 - val_loss: 0.0419 - val_auc: 0.8868 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0408 - auc: 0.8916 - val_loss: 0.0426 - val_auc: 0.8865 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0407 - auc: 0.8923 - val_loss: 0.0421 - val_auc: 0.8854 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0407 - auc: 0.8925 - val_loss: 0.0425 - val_auc: 0.8850 - lr: 0.0025\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0401 - auc: 0.8961 - val_loss: 0.0422 - val_auc: 0.8864 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0399 - auc: 0.8970 - val_loss: 0.0425 - val_auc: 0.8851 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0397 - auc: 0.8980 - val_loss: 0.0434 - val_auc: 0.8833 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0396 - auc: 0.8981 - val_loss: 0.0429 - val_auc: 0.8842 - lr: 0.0012\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0389 - auc: 0.9018 - val_loss: 0.0434 - val_auc: 0.8813 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0387 - auc: 0.9031 - val_loss: 0.0443 - val_auc: 0.8811 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0385 - auc: 0.9039 - val_loss: 0.0448 - val_auc: 0.8816 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0382 - auc: 0.9053 - val_loss: 0.0448 - val_auc: 0.8809 - lr: 6.2500e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0377 - auc: 0.9080 - val_loss: 0.0466 - val_auc: 0.8796 - lr: 3.1250e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 27s 32ms/step - loss: 0.0573 - auc: 0.8606 - val_loss: 0.0454 - val_auc: 0.8810 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 27ms/step - loss: 0.0439 - auc: 0.8775 - val_loss: 0.0429 - val_auc: 0.8835 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 11s 27ms/step - loss: 0.0429 - auc: 0.8815 - val_loss: 0.0470 - val_auc: 0.8838 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0431 - auc: 0.8818 - val_loss: 0.0443 - val_auc: 0.8837 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 11s 27ms/step - loss: 0.0427 - auc: 0.8831 - val_loss: 0.0435 - val_auc: 0.8843 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0422 - auc: 0.8853 - val_loss: 0.0425 - val_auc: 0.8845 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0421 - auc: 0.8857 - val_loss: 0.0439 - val_auc: 0.8847 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0420 - auc: 0.8857 - val_loss: 0.0424 - val_auc: 0.8838 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0419 - auc: 0.8866 - val_loss: 0.0427 - val_auc: 0.8844 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0418 - auc: 0.8871 - val_loss: 0.0419 - val_auc: 0.8854 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 27ms/step - loss: 0.0417 - auc: 0.8876 - val_loss: 0.0424 - val_auc: 0.8841 - lr: 0.0050\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0416 - auc: 0.8883 - val_loss: 0.0421 - val_auc: 0.8848 - lr: 0.0050\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0414 - auc: 0.8888 - val_loss: 0.0433 - val_auc: 0.8828 - lr: 0.0050\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0416 - auc: 0.8883 - val_loss: 0.0424 - val_auc: 0.8831 - lr: 0.0050\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0407 - auc: 0.8929 - val_loss: 0.0421 - val_auc: 0.8839 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0407 - auc: 0.8931 - val_loss: 0.0423 - val_auc: 0.8823 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0405 - auc: 0.8943 - val_loss: 0.0424 - val_auc: 0.8824 - lr: 0.0025\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0403 - auc: 0.8953 - val_loss: 0.0426 - val_auc: 0.8818 - lr: 0.0025\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0396 - auc: 0.8984 - val_loss: 0.0433 - val_auc: 0.8814 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0394 - auc: 0.8997 - val_loss: 0.0429 - val_auc: 0.8807 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0392 - auc: 0.9010 - val_loss: 0.0444 - val_auc: 0.8800 - lr: 0.0012\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0391 - auc: 0.9015 - val_loss: 0.0441 - val_auc: 0.8789 - lr: 0.0012\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 27s 31ms/step - loss: 0.0648 - auc: 0.8571 - val_loss: 0.0501 - val_auc: 0.8806 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0439 - auc: 0.8789 - val_loss: 0.0428 - val_auc: 0.8815 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0427 - auc: 0.8829 - val_loss: 0.0439 - val_auc: 0.8809 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0427 - auc: 0.8827 - val_loss: 0.0426 - val_auc: 0.8836 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0423 - auc: 0.8846 - val_loss: 0.0423 - val_auc: 0.8840 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0421 - auc: 0.8851 - val_loss: 0.0428 - val_auc: 0.8811 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0420 - auc: 0.8861 - val_loss: 0.0433 - val_auc: 0.8827 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0420 - auc: 0.8857 - val_loss: 0.0440 - val_auc: 0.8835 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0418 - auc: 0.8868 - val_loss: 0.0423 - val_auc: 0.8841 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0413 - auc: 0.8898 - val_loss: 0.0422 - val_auc: 0.8834 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0413 - auc: 0.8896 - val_loss: 0.0420 - val_auc: 0.8849 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0411 - auc: 0.8905 - val_loss: 0.0424 - val_auc: 0.8833 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0412 - auc: 0.8899 - val_loss: 0.0431 - val_auc: 0.8835 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 11s 27ms/step - loss: 0.0411 - auc: 0.8907 - val_loss: 0.0427 - val_auc: 0.8838 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 11s 27ms/step - loss: 0.0411 - auc: 0.8908 - val_loss: 0.0423 - val_auc: 0.8828 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 11s 27ms/step - loss: 0.0404 - auc: 0.8943 - val_loss: 0.0424 - val_auc: 0.8832 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0403 - auc: 0.8947 - val_loss: 0.0428 - val_auc: 0.8809 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0402 - auc: 0.8954 - val_loss: 0.0431 - val_auc: 0.8824 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0401 - auc: 0.8960 - val_loss: 0.0431 - val_auc: 0.8812 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0395 - auc: 0.8991 - val_loss: 0.0431 - val_auc: 0.8808 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0393 - auc: 0.9002 - val_loss: 0.0432 - val_auc: 0.8803 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0392 - auc: 0.9006 - val_loss: 0.0435 - val_auc: 0.8801 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0390 - auc: 0.9014 - val_loss: 0.0432 - val_auc: 0.8798 - lr: 6.2500e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 27s 33ms/step - loss: 0.0605 - auc: 0.8572 - val_loss: 0.0428 - val_auc: 0.8839 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0441 - auc: 0.8760 - val_loss: 0.0438 - val_auc: 0.8851 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0432 - auc: 0.8795 - val_loss: 0.0424 - val_auc: 0.8865 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0427 - auc: 0.8812 - val_loss: 0.0426 - val_auc: 0.8860 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 11s 27ms/step - loss: 0.0427 - auc: 0.8818 - val_loss: 0.0424 - val_auc: 0.8854 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0425 - auc: 0.8828 - val_loss: 0.0420 - val_auc: 0.8872 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 11s 27ms/step - loss: 0.0423 - auc: 0.8837 - val_loss: 0.0424 - val_auc: 0.8873 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0422 - auc: 0.8843 - val_loss: 0.0425 - val_auc: 0.8861 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0420 - auc: 0.8851 - val_loss: 0.0426 - val_auc: 0.8871 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0421 - auc: 0.8851 - val_loss: 0.0442 - val_auc: 0.8872 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0414 - auc: 0.8887 - val_loss: 0.0422 - val_auc: 0.8860 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0413 - auc: 0.8889 - val_loss: 0.0420 - val_auc: 0.8872 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0413 - auc: 0.8891 - val_loss: 0.0424 - val_auc: 0.8868 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0413 - auc: 0.8893 - val_loss: 0.0424 - val_auc: 0.8869 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0406 - auc: 0.8931 - val_loss: 0.0421 - val_auc: 0.8857 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0405 - auc: 0.8933 - val_loss: 0.0423 - val_auc: 0.8856 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0404 - auc: 0.8942 - val_loss: 0.0427 - val_auc: 0.8856 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0402 - auc: 0.8948 - val_loss: 0.0431 - val_auc: 0.8850 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0396 - auc: 0.8983 - val_loss: 0.0430 - val_auc: 0.8829 - lr: 6.2500e-04\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0395 - auc: 0.8992 - val_loss: 0.0431 - val_auc: 0.8828 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0393 - auc: 0.9001 - val_loss: 0.0433 - val_auc: 0.8819 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0391 - auc: 0.9013 - val_loss: 0.0436 - val_auc: 0.8816 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0384 - auc: 0.9046 - val_loss: 0.0444 - val_auc: 0.8800 - lr: 3.1250e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0383 - auc: 0.9053 - val_loss: 0.0450 - val_auc: 0.8814 - lr: 3.1250e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 30ms/step - loss: 0.0593 - auc: 0.8601 - val_loss: 0.0449 - val_auc: 0.8808 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0440 - auc: 0.8782 - val_loss: 0.0479 - val_auc: 0.8830 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0432 - auc: 0.8812 - val_loss: 0.0425 - val_auc: 0.8835 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0429 - auc: 0.8816 - val_loss: 0.0428 - val_auc: 0.8838 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0427 - auc: 0.8829 - val_loss: 0.0426 - val_auc: 0.8837 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0423 - auc: 0.8847 - val_loss: 0.0436 - val_auc: 0.8836 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0422 - auc: 0.8848 - val_loss: 0.0424 - val_auc: 0.8847 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0416 - auc: 0.8877 - val_loss: 0.0425 - val_auc: 0.8852 - lr: 0.0025\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0416 - auc: 0.8882 - val_loss: 0.0426 - val_auc: 0.8842 - lr: 0.0025\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0415 - auc: 0.8887 - val_loss: 0.0421 - val_auc: 0.8851 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0414 - auc: 0.8887 - val_loss: 0.0425 - val_auc: 0.8847 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0413 - auc: 0.8892 - val_loss: 0.0425 - val_auc: 0.8842 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0413 - auc: 0.8892 - val_loss: 0.0425 - val_auc: 0.8830 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0412 - auc: 0.8898 - val_loss: 0.0426 - val_auc: 0.8849 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0407 - auc: 0.8926 - val_loss: 0.0428 - val_auc: 0.8843 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0405 - auc: 0.8933 - val_loss: 0.0427 - val_auc: 0.8832 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0404 - auc: 0.8939 - val_loss: 0.0429 - val_auc: 0.8822 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0403 - auc: 0.8946 - val_loss: 0.0426 - val_auc: 0.8832 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0398 - auc: 0.8974 - val_loss: 0.0431 - val_auc: 0.8827 - lr: 6.2500e-04\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0396 - auc: 0.8983 - val_loss: 0.0438 - val_auc: 0.8815 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0395 - auc: 0.8988 - val_loss: 0.0438 - val_auc: 0.8814 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0393 - auc: 0.9003 - val_loss: 0.0443 - val_auc: 0.8799 - lr: 6.2500e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 27s 35ms/step - loss: 0.0678 - auc: 0.8544 - val_loss: 0.0427 - val_auc: 0.8843 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0441 - auc: 0.8783 - val_loss: 0.0441 - val_auc: 0.8859 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0431 - auc: 0.8819 - val_loss: 0.0438 - val_auc: 0.8875 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0427 - auc: 0.8833 - val_loss: 0.0419 - val_auc: 0.8878 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0427 - auc: 0.8832 - val_loss: 0.0426 - val_auc: 0.8878 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0424 - auc: 0.8845 - val_loss: 0.0419 - val_auc: 0.8880 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0423 - auc: 0.8851 - val_loss: 0.0423 - val_auc: 0.8877 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0421 - auc: 0.8859 - val_loss: 0.0418 - val_auc: 0.8876 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0420 - auc: 0.8861 - val_loss: 0.0430 - val_auc: 0.8864 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0419 - auc: 0.8865 - val_loss: 0.0418 - val_auc: 0.8876 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0417 - auc: 0.8877 - val_loss: 0.0417 - val_auc: 0.8865 - lr: 0.0050\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0417 - auc: 0.8877 - val_loss: 0.0420 - val_auc: 0.8876 - lr: 0.0050\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0410 - auc: 0.8912 - val_loss: 0.0419 - val_auc: 0.8879 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0410 - auc: 0.8911 - val_loss: 0.0415 - val_auc: 0.8883 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0409 - auc: 0.8923 - val_loss: 0.0421 - val_auc: 0.8869 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0409 - auc: 0.8919 - val_loss: 0.0419 - val_auc: 0.8855 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0407 - auc: 0.8930 - val_loss: 0.0422 - val_auc: 0.8841 - lr: 0.0025\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0407 - auc: 0.8928 - val_loss: 0.0420 - val_auc: 0.8860 - lr: 0.0025\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0400 - auc: 0.8968 - val_loss: 0.0420 - val_auc: 0.8861 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0398 - auc: 0.8978 - val_loss: 0.0425 - val_auc: 0.8859 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0396 - auc: 0.8989 - val_loss: 0.0430 - val_auc: 0.8832 - lr: 0.0012\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0394 - auc: 0.8996 - val_loss: 0.0432 - val_auc: 0.8832 - lr: 0.0012\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0387 - auc: 0.9038 - val_loss: 0.0439 - val_auc: 0.8821 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0385 - auc: 0.9044 - val_loss: 0.0440 - val_auc: 0.8811 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0383 - auc: 0.9057 - val_loss: 0.0440 - val_auc: 0.8815 - lr: 6.2500e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0379 - auc: 0.9074 - val_loss: 0.0446 - val_auc: 0.8792 - lr: 6.2500e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 25s 30ms/step - loss: 0.0633 - auc: 0.8577 - val_loss: 0.0435 - val_auc: 0.8803 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0441 - auc: 0.8772 - val_loss: 0.0442 - val_auc: 0.8807 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0431 - auc: 0.8812 - val_loss: 0.0438 - val_auc: 0.8823 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0430 - auc: 0.8814 - val_loss: 0.0438 - val_auc: 0.8807 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0425 - auc: 0.8831 - val_loss: 0.0433 - val_auc: 0.8818 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0423 - auc: 0.8838 - val_loss: 0.0435 - val_auc: 0.8829 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0422 - auc: 0.8848 - val_loss: 0.0444 - val_auc: 0.8802 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0421 - auc: 0.8850 - val_loss: 0.0431 - val_auc: 0.8825 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0419 - auc: 0.8862 - val_loss: 0.0437 - val_auc: 0.8831 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0417 - auc: 0.8866 - val_loss: 0.0433 - val_auc: 0.8822 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0417 - auc: 0.8869 - val_loss: 0.0428 - val_auc: 0.8825 - lr: 0.0050\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0418 - auc: 0.8870 - val_loss: 0.0433 - val_auc: 0.8829 - lr: 0.0050\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0416 - auc: 0.8874 - val_loss: 0.0430 - val_auc: 0.8827 - lr: 0.0050\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0415 - auc: 0.8878 - val_loss: 0.0431 - val_auc: 0.8826 - lr: 0.0050\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0415 - auc: 0.8883 - val_loss: 0.0430 - val_auc: 0.8802 - lr: 0.0050\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0407 - auc: 0.8923 - val_loss: 0.0433 - val_auc: 0.8809 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0406 - auc: 0.8931 - val_loss: 0.0435 - val_auc: 0.8814 - lr: 0.0025\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0404 - auc: 0.8937 - val_loss: 0.0440 - val_auc: 0.8815 - lr: 0.0025\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0404 - auc: 0.8942 - val_loss: 0.0437 - val_auc: 0.8792 - lr: 0.0025\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0396 - auc: 0.8981 - val_loss: 0.0437 - val_auc: 0.8785 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0394 - auc: 0.8994 - val_loss: 0.0444 - val_auc: 0.8789 - lr: 0.0012\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0391 - auc: 0.9005 - val_loss: 0.0454 - val_auc: 0.8788 - lr: 0.0012\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0388 - auc: 0.9020 - val_loss: 0.0458 - val_auc: 0.8764 - lr: 0.0012\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 25s 30ms/step - loss: 0.0656 - auc: 0.8542 - val_loss: 0.0433 - val_auc: 0.8822 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0437 - auc: 0.8781 - val_loss: 0.0437 - val_auc: 0.8840 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0430 - auc: 0.8807 - val_loss: 0.0423 - val_auc: 0.8849 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0429 - auc: 0.8812 - val_loss: 0.0426 - val_auc: 0.8852 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0426 - auc: 0.8823 - val_loss: 0.0423 - val_auc: 0.8850 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0424 - auc: 0.8836 - val_loss: 0.0448 - val_auc: 0.8856 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0422 - auc: 0.8841 - val_loss: 0.0421 - val_auc: 0.8850 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0423 - auc: 0.8837 - val_loss: 0.0424 - val_auc: 0.8846 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0420 - auc: 0.8854 - val_loss: 0.0428 - val_auc: 0.8829 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0420 - auc: 0.8851 - val_loss: 0.0433 - val_auc: 0.8849 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0419 - auc: 0.8861 - val_loss: 0.0428 - val_auc: 0.8850 - lr: 0.0050\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0413 - auc: 0.8891 - val_loss: 0.0425 - val_auc: 0.8848 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0413 - auc: 0.8890 - val_loss: 0.0420 - val_auc: 0.8850 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0412 - auc: 0.8896 - val_loss: 0.0426 - val_auc: 0.8845 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0411 - auc: 0.8902 - val_loss: 0.0426 - val_auc: 0.8846 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0406 - auc: 0.8929 - val_loss: 0.0421 - val_auc: 0.8846 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0405 - auc: 0.8937 - val_loss: 0.0428 - val_auc: 0.8824 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0403 - auc: 0.8944 - val_loss: 0.0425 - val_auc: 0.8839 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0402 - auc: 0.8951 - val_loss: 0.0427 - val_auc: 0.8821 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0396 - auc: 0.8986 - val_loss: 0.0427 - val_auc: 0.8816 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0394 - auc: 0.8994 - val_loss: 0.0431 - val_auc: 0.8805 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0391 - auc: 0.9010 - val_loss: 0.0438 - val_auc: 0.8789 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0390 - auc: 0.9015 - val_loss: 0.0438 - val_auc: 0.8791 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0385 - auc: 0.9045 - val_loss: 0.0440 - val_auc: 0.8789 - lr: 3.1250e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0382 - auc: 0.9056 - val_loss: 0.0447 - val_auc: 0.8777 - lr: 3.1250e-04\n",
            "[I 2024-01-29 13:49:02,528] Trial 1 finished with value: 0.8864604102240669 and parameters: {'units_0': 1024, 'activation': 'gelu', 'dropout': 0.25, 'hidden_layers': 4, 'embedding_dims': 16}. Best is trial 0 with value: 0.8868771261639066.\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 27ms/step - loss: 0.0567 - auc: 0.8498 - val_loss: 0.0461 - val_auc: 0.8792 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0451 - auc: 0.8703 - val_loss: 0.0432 - val_auc: 0.8807 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0442 - auc: 0.8744 - val_loss: 0.0434 - val_auc: 0.8814 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0436 - auc: 0.8770 - val_loss: 0.0429 - val_auc: 0.8813 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0435 - auc: 0.8774 - val_loss: 0.0439 - val_auc: 0.8821 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0431 - auc: 0.8792 - val_loss: 0.0428 - val_auc: 0.8834 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0429 - auc: 0.8806 - val_loss: 0.0428 - val_auc: 0.8837 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0427 - auc: 0.8813 - val_loss: 0.0426 - val_auc: 0.8827 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0426 - auc: 0.8816 - val_loss: 0.0426 - val_auc: 0.8830 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0428 - auc: 0.8811 - val_loss: 0.0433 - val_auc: 0.8833 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0428 - auc: 0.8815 - val_loss: 0.0428 - val_auc: 0.8824 - lr: 0.0050\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0426 - auc: 0.8822 - val_loss: 0.0431 - val_auc: 0.8804 - lr: 0.0050\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0421 - auc: 0.8847 - val_loss: 0.0424 - val_auc: 0.8841 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0419 - auc: 0.8854 - val_loss: 0.0425 - val_auc: 0.8830 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0420 - auc: 0.8850 - val_loss: 0.0423 - val_auc: 0.8842 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0420 - auc: 0.8849 - val_loss: 0.0424 - val_auc: 0.8841 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0421 - auc: 0.8849 - val_loss: 0.0428 - val_auc: 0.8845 - lr: 0.0025\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0419 - auc: 0.8857 - val_loss: 0.0430 - val_auc: 0.8846 - lr: 0.0025\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0420 - auc: 0.8852 - val_loss: 0.0428 - val_auc: 0.8841 - lr: 0.0025\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0416 - auc: 0.8871 - val_loss: 0.0422 - val_auc: 0.8848 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0416 - auc: 0.8872 - val_loss: 0.0423 - val_auc: 0.8844 - lr: 0.0012\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0416 - auc: 0.8873 - val_loss: 0.0423 - val_auc: 0.8845 - lr: 0.0012\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0416 - auc: 0.8875 - val_loss: 0.0422 - val_auc: 0.8842 - lr: 0.0012\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0414 - auc: 0.8885 - val_loss: 0.0424 - val_auc: 0.8844 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0414 - auc: 0.8886 - val_loss: 0.0422 - val_auc: 0.8847 - lr: 6.2500e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0413 - auc: 0.8890 - val_loss: 0.0422 - val_auc: 0.8845 - lr: 6.2500e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0413 - auc: 0.8889 - val_loss: 0.0423 - val_auc: 0.8843 - lr: 6.2500e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0412 - auc: 0.8894 - val_loss: 0.0423 - val_auc: 0.8847 - lr: 3.1250e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0411 - auc: 0.8899 - val_loss: 0.0422 - val_auc: 0.8843 - lr: 3.1250e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0411 - auc: 0.8901 - val_loss: 0.0422 - val_auc: 0.8846 - lr: 3.1250e-04\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0411 - auc: 0.8901 - val_loss: 0.0422 - val_auc: 0.8845 - lr: 3.1250e-04\n",
            "Epoch 32/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0410 - auc: 0.8903 - val_loss: 0.0422 - val_auc: 0.8846 - lr: 1.5625e-04\n",
            "Epoch 33/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8905 - val_loss: 0.0423 - val_auc: 0.8846 - lr: 1.5625e-04\n",
            "Epoch 34/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0411 - auc: 0.8904 - val_loss: 0.0422 - val_auc: 0.8845 - lr: 1.5625e-04\n",
            "Epoch 35/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8907 - val_loss: 0.0423 - val_auc: 0.8844 - lr: 1.5625e-04\n",
            "Epoch 36/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0410 - auc: 0.8906 - val_loss: 0.0422 - val_auc: 0.8843 - lr: 7.8125e-05\n",
            "Epoch 37/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0409 - auc: 0.8909 - val_loss: 0.0422 - val_auc: 0.8844 - lr: 7.8125e-05\n",
            "Epoch 38/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8907 - val_loss: 0.0422 - val_auc: 0.8845 - lr: 7.8125e-05\n",
            "Epoch 39/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0410 - auc: 0.8906 - val_loss: 0.0422 - val_auc: 0.8845 - lr: 7.8125e-05\n",
            "Epoch 40/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8914 - val_loss: 0.0422 - val_auc: 0.8845 - lr: 3.9062e-05\n",
            "Epoch 41/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8910 - val_loss: 0.0422 - val_auc: 0.8845 - lr: 3.9062e-05\n",
            "Epoch 42/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8908 - val_loss: 0.0422 - val_auc: 0.8845 - lr: 3.9062e-05\n",
            "Epoch 43/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8914 - val_loss: 0.0422 - val_auc: 0.8843 - lr: 3.9062e-05\n",
            "Epoch 44/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8908 - val_loss: 0.0422 - val_auc: 0.8844 - lr: 1.9531e-05\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 23s 28ms/step - loss: 0.0536 - auc: 0.8529 - val_loss: 0.0468 - val_auc: 0.8831 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0454 - auc: 0.8692 - val_loss: 0.0432 - val_auc: 0.8844 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0440 - auc: 0.8756 - val_loss: 0.0431 - val_auc: 0.8843 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0435 - auc: 0.8778 - val_loss: 0.0426 - val_auc: 0.8863 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0431 - auc: 0.8796 - val_loss: 0.0424 - val_auc: 0.8866 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0428 - auc: 0.8817 - val_loss: 0.0430 - val_auc: 0.8855 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0428 - auc: 0.8814 - val_loss: 0.0423 - val_auc: 0.8843 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0427 - auc: 0.8818 - val_loss: 0.0427 - val_auc: 0.8865 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0425 - auc: 0.8830 - val_loss: 0.0418 - val_auc: 0.8866 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0424 - auc: 0.8835 - val_loss: 0.0418 - val_auc: 0.8861 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0424 - auc: 0.8835 - val_loss: 0.0426 - val_auc: 0.8865 - lr: 0.0050\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0424 - auc: 0.8836 - val_loss: 0.0419 - val_auc: 0.8873 - lr: 0.0050\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0424 - auc: 0.8837 - val_loss: 0.0426 - val_auc: 0.8865 - lr: 0.0050\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0418 - auc: 0.8865 - val_loss: 0.0417 - val_auc: 0.8874 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0418 - auc: 0.8868 - val_loss: 0.0416 - val_auc: 0.8872 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0418 - auc: 0.8866 - val_loss: 0.0418 - val_auc: 0.8872 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0418 - auc: 0.8868 - val_loss: 0.0416 - val_auc: 0.8875 - lr: 0.0025\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0417 - auc: 0.8874 - val_loss: 0.0417 - val_auc: 0.8866 - lr: 0.0025\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0417 - auc: 0.8872 - val_loss: 0.0416 - val_auc: 0.8875 - lr: 0.0025\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0415 - auc: 0.8883 - val_loss: 0.0417 - val_auc: 0.8879 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0414 - auc: 0.8886 - val_loss: 0.0416 - val_auc: 0.8876 - lr: 0.0012\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0413 - auc: 0.8895 - val_loss: 0.0415 - val_auc: 0.8877 - lr: 0.0012\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0414 - auc: 0.8891 - val_loss: 0.0416 - val_auc: 0.8873 - lr: 0.0012\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0415 - auc: 0.8885 - val_loss: 0.0416 - val_auc: 0.8875 - lr: 0.0012\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0413 - auc: 0.8894 - val_loss: 0.0417 - val_auc: 0.8874 - lr: 0.0012\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0412 - auc: 0.8898 - val_loss: 0.0416 - val_auc: 0.8873 - lr: 0.0012\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0411 - auc: 0.8901 - val_loss: 0.0415 - val_auc: 0.8875 - lr: 6.2500e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0411 - auc: 0.8903 - val_loss: 0.0417 - val_auc: 0.8871 - lr: 6.2500e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8909 - val_loss: 0.0416 - val_auc: 0.8873 - lr: 6.2500e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8906 - val_loss: 0.0417 - val_auc: 0.8874 - lr: 6.2500e-04\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8916 - val_loss: 0.0416 - val_auc: 0.8873 - lr: 3.1250e-04\n",
            "Epoch 32/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8912 - val_loss: 0.0416 - val_auc: 0.8875 - lr: 3.1250e-04\n",
            "Epoch 33/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0409 - auc: 0.8918 - val_loss: 0.0417 - val_auc: 0.8872 - lr: 3.1250e-04\n",
            "Epoch 34/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8913 - val_loss: 0.0416 - val_auc: 0.8874 - lr: 3.1250e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 22s 27ms/step - loss: 0.0565 - auc: 0.8527 - val_loss: 0.0444 - val_auc: 0.8789 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0452 - auc: 0.8710 - val_loss: 0.0429 - val_auc: 0.8823 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0439 - auc: 0.8764 - val_loss: 0.0444 - val_auc: 0.8837 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0439 - auc: 0.8764 - val_loss: 0.0428 - val_auc: 0.8823 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0430 - auc: 0.8801 - val_loss: 0.0424 - val_auc: 0.8824 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0431 - auc: 0.8802 - val_loss: 0.0421 - val_auc: 0.8838 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0428 - auc: 0.8816 - val_loss: 0.0424 - val_auc: 0.8835 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0426 - auc: 0.8827 - val_loss: 0.0421 - val_auc: 0.8843 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0425 - auc: 0.8836 - val_loss: 0.0422 - val_auc: 0.8838 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0426 - auc: 0.8824 - val_loss: 0.0430 - val_auc: 0.8834 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0421 - auc: 0.8855 - val_loss: 0.0420 - val_auc: 0.8850 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0419 - auc: 0.8861 - val_loss: 0.0422 - val_auc: 0.8847 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0418 - auc: 0.8866 - val_loss: 0.0420 - val_auc: 0.8851 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0420 - auc: 0.8858 - val_loss: 0.0423 - val_auc: 0.8845 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0419 - auc: 0.8858 - val_loss: 0.0421 - val_auc: 0.8846 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0415 - auc: 0.8880 - val_loss: 0.0420 - val_auc: 0.8850 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0416 - auc: 0.8876 - val_loss: 0.0420 - val_auc: 0.8851 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0416 - auc: 0.8879 - val_loss: 0.0420 - val_auc: 0.8846 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0415 - auc: 0.8883 - val_loss: 0.0421 - val_auc: 0.8850 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0413 - auc: 0.8893 - val_loss: 0.0418 - val_auc: 0.8852 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0413 - auc: 0.8893 - val_loss: 0.0420 - val_auc: 0.8854 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0413 - auc: 0.8897 - val_loss: 0.0418 - val_auc: 0.8853 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0412 - auc: 0.8901 - val_loss: 0.0419 - val_auc: 0.8849 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0412 - auc: 0.8899 - val_loss: 0.0420 - val_auc: 0.8850 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0411 - auc: 0.8904 - val_loss: 0.0420 - val_auc: 0.8848 - lr: 3.1250e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8911 - val_loss: 0.0419 - val_auc: 0.8853 - lr: 3.1250e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8909 - val_loss: 0.0419 - val_auc: 0.8852 - lr: 3.1250e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8912 - val_loss: 0.0419 - val_auc: 0.8851 - lr: 3.1250e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8914 - val_loss: 0.0419 - val_auc: 0.8852 - lr: 1.5625e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8914 - val_loss: 0.0419 - val_auc: 0.8850 - lr: 1.5625e-04\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8916 - val_loss: 0.0419 - val_auc: 0.8851 - lr: 1.5625e-04\n",
            "Epoch 32/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0409 - auc: 0.8918 - val_loss: 0.0419 - val_auc: 0.8850 - lr: 1.5625e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 30ms/step - loss: 0.0563 - auc: 0.8531 - val_loss: 0.0463 - val_auc: 0.8810 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0449 - auc: 0.8722 - val_loss: 0.0430 - val_auc: 0.8816 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0441 - auc: 0.8758 - val_loss: 0.0457 - val_auc: 0.8795 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0435 - auc: 0.8788 - val_loss: 0.0430 - val_auc: 0.8793 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0431 - auc: 0.8805 - val_loss: 0.0437 - val_auc: 0.8825 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0428 - auc: 0.8817 - val_loss: 0.0424 - val_auc: 0.8833 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0428 - auc: 0.8817 - val_loss: 0.0434 - val_auc: 0.8812 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0426 - auc: 0.8831 - val_loss: 0.0427 - val_auc: 0.8831 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0425 - auc: 0.8834 - val_loss: 0.0430 - val_auc: 0.8836 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0425 - auc: 0.8830 - val_loss: 0.0426 - val_auc: 0.8833 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0419 - auc: 0.8864 - val_loss: 0.0422 - val_auc: 0.8833 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0419 - auc: 0.8864 - val_loss: 0.0422 - val_auc: 0.8838 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0419 - auc: 0.8862 - val_loss: 0.0423 - val_auc: 0.8839 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0419 - auc: 0.8860 - val_loss: 0.0424 - val_auc: 0.8837 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0418 - auc: 0.8867 - val_loss: 0.0421 - val_auc: 0.8840 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0416 - auc: 0.8879 - val_loss: 0.0421 - val_auc: 0.8844 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0415 - auc: 0.8883 - val_loss: 0.0422 - val_auc: 0.8844 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0415 - auc: 0.8884 - val_loss: 0.0422 - val_auc: 0.8834 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0415 - auc: 0.8885 - val_loss: 0.0423 - val_auc: 0.8843 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0413 - auc: 0.8894 - val_loss: 0.0420 - val_auc: 0.8846 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0413 - auc: 0.8899 - val_loss: 0.0420 - val_auc: 0.8845 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0412 - auc: 0.8901 - val_loss: 0.0420 - val_auc: 0.8844 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0413 - auc: 0.8896 - val_loss: 0.0421 - val_auc: 0.8847 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0411 - auc: 0.8904 - val_loss: 0.0421 - val_auc: 0.8840 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0411 - auc: 0.8908 - val_loss: 0.0420 - val_auc: 0.8844 - lr: 3.1250e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0410 - auc: 0.8910 - val_loss: 0.0421 - val_auc: 0.8844 - lr: 3.1250e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0411 - auc: 0.8907 - val_loss: 0.0420 - val_auc: 0.8845 - lr: 3.1250e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8910 - val_loss: 0.0420 - val_auc: 0.8842 - lr: 3.1250e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0409 - auc: 0.8915 - val_loss: 0.0420 - val_auc: 0.8843 - lr: 1.5625e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0409 - auc: 0.8915 - val_loss: 0.0420 - val_auc: 0.8844 - lr: 1.5625e-04\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8918 - val_loss: 0.0420 - val_auc: 0.8843 - lr: 1.5625e-04\n",
            "Epoch 32/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0408 - auc: 0.8922 - val_loss: 0.0420 - val_auc: 0.8843 - lr: 1.5625e-04\n",
            "Epoch 33/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0408 - auc: 0.8920 - val_loss: 0.0420 - val_auc: 0.8844 - lr: 7.8125e-05\n",
            "Epoch 34/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0409 - auc: 0.8916 - val_loss: 0.0420 - val_auc: 0.8842 - lr: 7.8125e-05\n",
            "Epoch 35/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0408 - auc: 0.8922 - val_loss: 0.0420 - val_auc: 0.8842 - lr: 7.8125e-05\n",
            "Epoch 36/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8918 - val_loss: 0.0421 - val_auc: 0.8843 - lr: 7.8125e-05\n",
            "Epoch 37/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0408 - auc: 0.8920 - val_loss: 0.0420 - val_auc: 0.8844 - lr: 3.9062e-05\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 23s 28ms/step - loss: 0.0553 - auc: 0.8511 - val_loss: 0.0453 - val_auc: 0.8662 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0454 - auc: 0.8685 - val_loss: 0.0439 - val_auc: 0.8846 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0442 - auc: 0.8741 - val_loss: 0.0457 - val_auc: 0.8853 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0436 - auc: 0.8765 - val_loss: 0.0428 - val_auc: 0.8860 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0434 - auc: 0.8780 - val_loss: 0.0421 - val_auc: 0.8864 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0431 - auc: 0.8796 - val_loss: 0.0423 - val_auc: 0.8865 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0429 - auc: 0.8803 - val_loss: 0.0426 - val_auc: 0.8875 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0428 - auc: 0.8806 - val_loss: 0.0422 - val_auc: 0.8867 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0429 - auc: 0.8809 - val_loss: 0.0433 - val_auc: 0.8874 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0423 - auc: 0.8833 - val_loss: 0.0419 - val_auc: 0.8874 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0422 - auc: 0.8839 - val_loss: 0.0420 - val_auc: 0.8872 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0421 - auc: 0.8848 - val_loss: 0.0423 - val_auc: 0.8875 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0421 - auc: 0.8842 - val_loss: 0.0419 - val_auc: 0.8873 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0422 - auc: 0.8840 - val_loss: 0.0425 - val_auc: 0.8845 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0418 - auc: 0.8859 - val_loss: 0.0417 - val_auc: 0.8881 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0418 - auc: 0.8860 - val_loss: 0.0419 - val_auc: 0.8870 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0419 - auc: 0.8858 - val_loss: 0.0419 - val_auc: 0.8880 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0417 - auc: 0.8867 - val_loss: 0.0419 - val_auc: 0.8871 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0418 - auc: 0.8863 - val_loss: 0.0418 - val_auc: 0.8880 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0415 - auc: 0.8878 - val_loss: 0.0417 - val_auc: 0.8876 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0415 - auc: 0.8876 - val_loss: 0.0418 - val_auc: 0.8875 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0413 - auc: 0.8884 - val_loss: 0.0416 - val_auc: 0.8883 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0414 - auc: 0.8881 - val_loss: 0.0417 - val_auc: 0.8880 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0414 - auc: 0.8880 - val_loss: 0.0417 - val_auc: 0.8880 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0414 - auc: 0.8884 - val_loss: 0.0419 - val_auc: 0.8876 - lr: 6.2500e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0414 - auc: 0.8883 - val_loss: 0.0417 - val_auc: 0.8879 - lr: 6.2500e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0412 - auc: 0.8890 - val_loss: 0.0416 - val_auc: 0.8882 - lr: 3.1250e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0413 - auc: 0.8889 - val_loss: 0.0417 - val_auc: 0.8882 - lr: 3.1250e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0412 - auc: 0.8892 - val_loss: 0.0417 - val_auc: 0.8879 - lr: 3.1250e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0412 - auc: 0.8895 - val_loss: 0.0416 - val_auc: 0.8883 - lr: 3.1250e-04\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0411 - auc: 0.8901 - val_loss: 0.0416 - val_auc: 0.8882 - lr: 1.5625e-04\n",
            "Epoch 32/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0411 - auc: 0.8899 - val_loss: 0.0417 - val_auc: 0.8877 - lr: 1.5625e-04\n",
            "Epoch 33/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0410 - auc: 0.8903 - val_loss: 0.0417 - val_auc: 0.8880 - lr: 1.5625e-04\n",
            "Epoch 34/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0410 - auc: 0.8904 - val_loss: 0.0417 - val_auc: 0.8881 - lr: 1.5625e-04\n",
            "Epoch 35/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0410 - auc: 0.8906 - val_loss: 0.0417 - val_auc: 0.8879 - lr: 7.8125e-05\n",
            "Epoch 36/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0411 - auc: 0.8900 - val_loss: 0.0417 - val_auc: 0.8879 - lr: 7.8125e-05\n",
            "Epoch 37/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8905 - val_loss: 0.0417 - val_auc: 0.8878 - lr: 7.8125e-05\n",
            "Epoch 38/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8904 - val_loss: 0.0417 - val_auc: 0.8879 - lr: 7.8125e-05\n",
            "Epoch 39/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8909 - val_loss: 0.0417 - val_auc: 0.8878 - lr: 3.9062e-05\n",
            "Epoch 40/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0410 - auc: 0.8904 - val_loss: 0.0417 - val_auc: 0.8879 - lr: 3.9062e-05\n",
            "Epoch 41/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8905 - val_loss: 0.0417 - val_auc: 0.8879 - lr: 3.9062e-05\n",
            "Epoch 42/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8903 - val_loss: 0.0417 - val_auc: 0.8879 - lr: 3.9062e-05\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 23s 28ms/step - loss: 0.0553 - auc: 0.8534 - val_loss: 0.0434 - val_auc: 0.8821 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0450 - auc: 0.8713 - val_loss: 0.0444 - val_auc: 0.8692 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0443 - auc: 0.8750 - val_loss: 0.0429 - val_auc: 0.8831 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0434 - auc: 0.8789 - val_loss: 0.0431 - val_auc: 0.8829 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0431 - auc: 0.8795 - val_loss: 0.0431 - val_auc: 0.8843 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0430 - auc: 0.8807 - val_loss: 0.0422 - val_auc: 0.8843 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0429 - auc: 0.8809 - val_loss: 0.0428 - val_auc: 0.8843 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0426 - auc: 0.8823 - val_loss: 0.0424 - val_auc: 0.8850 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0425 - auc: 0.8830 - val_loss: 0.0424 - val_auc: 0.8843 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0427 - auc: 0.8820 - val_loss: 0.0420 - val_auc: 0.8849 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0424 - auc: 0.8836 - val_loss: 0.0422 - val_auc: 0.8853 - lr: 0.0050\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0423 - auc: 0.8837 - val_loss: 0.0426 - val_auc: 0.8841 - lr: 0.0050\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0426 - auc: 0.8823 - val_loss: 0.0426 - val_auc: 0.8830 - lr: 0.0050\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0424 - auc: 0.8834 - val_loss: 0.0429 - val_auc: 0.8857 - lr: 0.0050\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0419 - auc: 0.8863 - val_loss: 0.0421 - val_auc: 0.8855 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0418 - auc: 0.8864 - val_loss: 0.0419 - val_auc: 0.8855 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0418 - auc: 0.8863 - val_loss: 0.0420 - val_auc: 0.8858 - lr: 0.0025\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0418 - auc: 0.8868 - val_loss: 0.0419 - val_auc: 0.8860 - lr: 0.0025\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0418 - auc: 0.8866 - val_loss: 0.0419 - val_auc: 0.8864 - lr: 0.0025\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0417 - auc: 0.8871 - val_loss: 0.0421 - val_auc: 0.8856 - lr: 0.0025\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0415 - auc: 0.8884 - val_loss: 0.0419 - val_auc: 0.8856 - lr: 0.0012\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0414 - auc: 0.8889 - val_loss: 0.0420 - val_auc: 0.8856 - lr: 0.0012\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0414 - auc: 0.8891 - val_loss: 0.0418 - val_auc: 0.8858 - lr: 0.0012\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0414 - auc: 0.8889 - val_loss: 0.0418 - val_auc: 0.8861 - lr: 0.0012\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0411 - auc: 0.8904 - val_loss: 0.0418 - val_auc: 0.8859 - lr: 6.2500e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0412 - auc: 0.8899 - val_loss: 0.0419 - val_auc: 0.8861 - lr: 6.2500e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0411 - auc: 0.8904 - val_loss: 0.0420 - val_auc: 0.8857 - lr: 6.2500e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0411 - auc: 0.8904 - val_loss: 0.0419 - val_auc: 0.8855 - lr: 6.2500e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0410 - auc: 0.8907 - val_loss: 0.0419 - val_auc: 0.8858 - lr: 3.1250e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8912 - val_loss: 0.0418 - val_auc: 0.8858 - lr: 3.1250e-04\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8912 - val_loss: 0.0419 - val_auc: 0.8859 - lr: 3.1250e-04\n",
            "Epoch 32/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8911 - val_loss: 0.0419 - val_auc: 0.8856 - lr: 3.1250e-04\n",
            "Epoch 33/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8911 - val_loss: 0.0419 - val_auc: 0.8856 - lr: 1.5625e-04\n",
            "Epoch 34/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8913 - val_loss: 0.0418 - val_auc: 0.8857 - lr: 1.5625e-04\n",
            "Epoch 35/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8913 - val_loss: 0.0418 - val_auc: 0.8858 - lr: 1.5625e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 23s 30ms/step - loss: 0.0560 - auc: 0.8525 - val_loss: 0.0453 - val_auc: 0.8768 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0451 - auc: 0.8707 - val_loss: 0.0419 - val_auc: 0.8858 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0444 - auc: 0.8750 - val_loss: 0.0436 - val_auc: 0.8751 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0436 - auc: 0.8780 - val_loss: 0.0417 - val_auc: 0.8865 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0430 - auc: 0.8808 - val_loss: 0.0434 - val_auc: 0.8855 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0428 - auc: 0.8817 - val_loss: 0.0414 - val_auc: 0.8885 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0429 - auc: 0.8816 - val_loss: 0.0418 - val_auc: 0.8868 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0426 - auc: 0.8825 - val_loss: 0.0416 - val_auc: 0.8868 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0424 - auc: 0.8833 - val_loss: 0.0418 - val_auc: 0.8872 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0426 - auc: 0.8827 - val_loss: 0.0425 - val_auc: 0.8874 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0420 - auc: 0.8860 - val_loss: 0.0413 - val_auc: 0.8890 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0420 - auc: 0.8860 - val_loss: 0.0414 - val_auc: 0.8886 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0418 - auc: 0.8866 - val_loss: 0.0416 - val_auc: 0.8875 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0419 - auc: 0.8862 - val_loss: 0.0414 - val_auc: 0.8886 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0420 - auc: 0.8859 - val_loss: 0.0414 - val_auc: 0.8886 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0416 - auc: 0.8877 - val_loss: 0.0414 - val_auc: 0.8888 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0416 - auc: 0.8879 - val_loss: 0.0415 - val_auc: 0.8888 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0415 - auc: 0.8883 - val_loss: 0.0414 - val_auc: 0.8885 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0415 - auc: 0.8883 - val_loss: 0.0414 - val_auc: 0.8890 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8895 - val_loss: 0.0414 - val_auc: 0.8888 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0413 - auc: 0.8895 - val_loss: 0.0412 - val_auc: 0.8891 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0412 - auc: 0.8900 - val_loss: 0.0413 - val_auc: 0.8891 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8897 - val_loss: 0.0413 - val_auc: 0.8889 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0411 - auc: 0.8906 - val_loss: 0.0412 - val_auc: 0.8892 - lr: 3.1250e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0411 - auc: 0.8908 - val_loss: 0.0412 - val_auc: 0.8891 - lr: 3.1250e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0410 - auc: 0.8911 - val_loss: 0.0413 - val_auc: 0.8894 - lr: 3.1250e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0410 - auc: 0.8908 - val_loss: 0.0412 - val_auc: 0.8893 - lr: 3.1250e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0410 - auc: 0.8911 - val_loss: 0.0412 - val_auc: 0.8894 - lr: 1.5625e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0410 - auc: 0.8912 - val_loss: 0.0412 - val_auc: 0.8894 - lr: 1.5625e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8915 - val_loss: 0.0413 - val_auc: 0.8892 - lr: 1.5625e-04\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0409 - auc: 0.8918 - val_loss: 0.0413 - val_auc: 0.8891 - lr: 1.5625e-04\n",
            "Epoch 32/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8920 - val_loss: 0.0412 - val_auc: 0.8891 - lr: 7.8125e-05\n",
            "Epoch 33/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0409 - auc: 0.8915 - val_loss: 0.0412 - val_auc: 0.8892 - lr: 7.8125e-05\n",
            "Epoch 34/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8914 - val_loss: 0.0412 - val_auc: 0.8892 - lr: 7.8125e-05\n",
            "Epoch 35/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0409 - auc: 0.8919 - val_loss: 0.0412 - val_auc: 0.8892 - lr: 7.8125e-05\n",
            "Epoch 36/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8918 - val_loss: 0.0412 - val_auc: 0.8893 - lr: 3.9062e-05\n",
            "Epoch 37/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0409 - auc: 0.8917 - val_loss: 0.0412 - val_auc: 0.8892 - lr: 3.9062e-05\n",
            "Epoch 38/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0408 - auc: 0.8918 - val_loss: 0.0412 - val_auc: 0.8891 - lr: 3.9062e-05\n",
            "Epoch 39/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0408 - auc: 0.8921 - val_loss: 0.0412 - val_auc: 0.8892 - lr: 3.9062e-05\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 23s 28ms/step - loss: 0.0566 - auc: 0.8511 - val_loss: 0.0452 - val_auc: 0.8802 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0450 - auc: 0.8711 - val_loss: 0.0473 - val_auc: 0.8812 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0438 - auc: 0.8762 - val_loss: 0.0435 - val_auc: 0.8782 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0432 - auc: 0.8794 - val_loss: 0.0435 - val_auc: 0.8820 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0431 - auc: 0.8800 - val_loss: 0.0431 - val_auc: 0.8807 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0428 - auc: 0.8809 - val_loss: 0.0428 - val_auc: 0.8824 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0426 - auc: 0.8817 - val_loss: 0.0429 - val_auc: 0.8813 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0427 - auc: 0.8818 - val_loss: 0.0434 - val_auc: 0.8811 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0427 - auc: 0.8817 - val_loss: 0.0430 - val_auc: 0.8827 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0425 - auc: 0.8827 - val_loss: 0.0431 - val_auc: 0.8831 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0420 - auc: 0.8853 - val_loss: 0.0428 - val_auc: 0.8823 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0419 - auc: 0.8859 - val_loss: 0.0424 - val_auc: 0.8836 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0420 - auc: 0.8855 - val_loss: 0.0429 - val_auc: 0.8827 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0421 - auc: 0.8851 - val_loss: 0.0430 - val_auc: 0.8830 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0419 - auc: 0.8859 - val_loss: 0.0426 - val_auc: 0.8829 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0419 - auc: 0.8856 - val_loss: 0.0426 - val_auc: 0.8837 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0415 - auc: 0.8876 - val_loss: 0.0425 - val_auc: 0.8833 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0415 - auc: 0.8879 - val_loss: 0.0426 - val_auc: 0.8832 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0414 - auc: 0.8884 - val_loss: 0.0427 - val_auc: 0.8833 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0414 - auc: 0.8883 - val_loss: 0.0427 - val_auc: 0.8831 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8889 - val_loss: 0.0424 - val_auc: 0.8838 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0412 - auc: 0.8895 - val_loss: 0.0425 - val_auc: 0.8838 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0412 - auc: 0.8893 - val_loss: 0.0424 - val_auc: 0.8838 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0412 - auc: 0.8896 - val_loss: 0.0427 - val_auc: 0.8836 - lr: 6.2500e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 25s 28ms/step - loss: 0.0574 - auc: 0.8508 - val_loss: 0.0443 - val_auc: 0.8770 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0453 - auc: 0.8698 - val_loss: 0.0440 - val_auc: 0.8825 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0442 - auc: 0.8745 - val_loss: 0.0440 - val_auc: 0.8828 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0438 - auc: 0.8763 - val_loss: 0.0438 - val_auc: 0.8832 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0432 - auc: 0.8793 - val_loss: 0.0424 - val_auc: 0.8835 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0430 - auc: 0.8798 - val_loss: 0.0429 - val_auc: 0.8834 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0429 - auc: 0.8805 - val_loss: 0.0425 - val_auc: 0.8822 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0429 - auc: 0.8805 - val_loss: 0.0421 - val_auc: 0.8850 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0428 - auc: 0.8810 - val_loss: 0.0421 - val_auc: 0.8849 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0427 - auc: 0.8816 - val_loss: 0.0432 - val_auc: 0.8828 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0426 - auc: 0.8823 - val_loss: 0.0422 - val_auc: 0.8838 - lr: 0.0050\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0425 - auc: 0.8824 - val_loss: 0.0422 - val_auc: 0.8849 - lr: 0.0050\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0421 - auc: 0.8846 - val_loss: 0.0420 - val_auc: 0.8855 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0420 - auc: 0.8852 - val_loss: 0.0419 - val_auc: 0.8859 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0420 - auc: 0.8854 - val_loss: 0.0422 - val_auc: 0.8850 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0421 - auc: 0.8850 - val_loss: 0.0421 - val_auc: 0.8853 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0420 - auc: 0.8855 - val_loss: 0.0419 - val_auc: 0.8854 - lr: 0.0025\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0419 - auc: 0.8856 - val_loss: 0.0422 - val_auc: 0.8848 - lr: 0.0025\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0418 - auc: 0.8867 - val_loss: 0.0418 - val_auc: 0.8857 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0417 - auc: 0.8870 - val_loss: 0.0419 - val_auc: 0.8857 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0416 - auc: 0.8873 - val_loss: 0.0417 - val_auc: 0.8863 - lr: 0.0012\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0415 - auc: 0.8879 - val_loss: 0.0419 - val_auc: 0.8855 - lr: 0.0012\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0416 - auc: 0.8877 - val_loss: 0.0418 - val_auc: 0.8860 - lr: 0.0012\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0416 - auc: 0.8874 - val_loss: 0.0418 - val_auc: 0.8856 - lr: 0.0012\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0415 - auc: 0.8877 - val_loss: 0.0419 - val_auc: 0.8859 - lr: 0.0012\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0414 - auc: 0.8885 - val_loss: 0.0419 - val_auc: 0.8862 - lr: 6.2500e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0414 - auc: 0.8886 - val_loss: 0.0418 - val_auc: 0.8861 - lr: 6.2500e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0412 - auc: 0.8895 - val_loss: 0.0420 - val_auc: 0.8864 - lr: 6.2500e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 8s 21ms/step - loss: 0.0413 - auc: 0.8890 - val_loss: 0.0419 - val_auc: 0.8856 - lr: 6.2500e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 9s 21ms/step - loss: 0.0412 - auc: 0.8895 - val_loss: 0.0418 - val_auc: 0.8860 - lr: 3.1250e-04\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0411 - auc: 0.8899 - val_loss: 0.0418 - val_auc: 0.8860 - lr: 3.1250e-04\n",
            "Epoch 32/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0411 - auc: 0.8900 - val_loss: 0.0418 - val_auc: 0.8862 - lr: 3.1250e-04\n",
            "Epoch 33/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0411 - auc: 0.8901 - val_loss: 0.0418 - val_auc: 0.8859 - lr: 3.1250e-04\n",
            "[I 2024-01-29 14:51:11,658] Trial 2 finished with value: 0.8870233562257555 and parameters: {'units_0': 1024, 'activation': 'swish', 'dropout': 0.5, 'hidden_layers': 2, 'embedding_dims': 32}. Best is trial 2 with value: 0.8870233562257555.\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 28ms/step - loss: 0.0650 - auc: 0.8533 - val_loss: 0.0454 - val_auc: 0.8790 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0441 - auc: 0.8755 - val_loss: 0.0428 - val_auc: 0.8818 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0437 - auc: 0.8775 - val_loss: 0.0437 - val_auc: 0.8800 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0431 - auc: 0.8798 - val_loss: 0.0439 - val_auc: 0.8746 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0427 - auc: 0.8814 - val_loss: 0.0449 - val_auc: 0.8813 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0427 - auc: 0.8816 - val_loss: 0.0431 - val_auc: 0.8823 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0421 - auc: 0.8846 - val_loss: 0.0423 - val_auc: 0.8846 - lr: 0.0025\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0419 - auc: 0.8856 - val_loss: 0.0426 - val_auc: 0.8839 - lr: 0.0025\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0420 - auc: 0.8852 - val_loss: 0.0426 - val_auc: 0.8835 - lr: 0.0025\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0419 - auc: 0.8854 - val_loss: 0.0427 - val_auc: 0.8839 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0421 - auc: 0.8848 - val_loss: 0.0428 - val_auc: 0.8832 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0416 - auc: 0.8874 - val_loss: 0.0423 - val_auc: 0.8848 - lr: 0.0012\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0415 - auc: 0.8877 - val_loss: 0.0423 - val_auc: 0.8845 - lr: 0.0012\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0414 - auc: 0.8880 - val_loss: 0.0427 - val_auc: 0.8846 - lr: 0.0012\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0414 - auc: 0.8882 - val_loss: 0.0425 - val_auc: 0.8835 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0412 - auc: 0.8893 - val_loss: 0.0422 - val_auc: 0.8851 - lr: 6.2500e-04\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0410 - auc: 0.8904 - val_loss: 0.0427 - val_auc: 0.8844 - lr: 6.2500e-04\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0411 - auc: 0.8900 - val_loss: 0.0423 - val_auc: 0.8847 - lr: 6.2500e-04\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0410 - auc: 0.8905 - val_loss: 0.0424 - val_auc: 0.8842 - lr: 6.2500e-04\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0408 - auc: 0.8917 - val_loss: 0.0423 - val_auc: 0.8846 - lr: 3.1250e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0408 - auc: 0.8917 - val_loss: 0.0424 - val_auc: 0.8840 - lr: 3.1250e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0408 - auc: 0.8918 - val_loss: 0.0427 - val_auc: 0.8838 - lr: 3.1250e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0407 - auc: 0.8921 - val_loss: 0.0424 - val_auc: 0.8835 - lr: 3.1250e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0405 - auc: 0.8932 - val_loss: 0.0424 - val_auc: 0.8842 - lr: 1.5625e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0404 - auc: 0.8934 - val_loss: 0.0425 - val_auc: 0.8840 - lr: 1.5625e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0403 - auc: 0.8941 - val_loss: 0.0425 - val_auc: 0.8837 - lr: 1.5625e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0404 - auc: 0.8940 - val_loss: 0.0425 - val_auc: 0.8835 - lr: 1.5625e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0402 - auc: 0.8947 - val_loss: 0.0426 - val_auc: 0.8836 - lr: 7.8125e-05\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 29ms/step - loss: 0.0597 - auc: 0.8592 - val_loss: 0.0435 - val_auc: 0.8847 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0441 - auc: 0.8769 - val_loss: 0.0422 - val_auc: 0.8852 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0431 - auc: 0.8802 - val_loss: 0.0437 - val_auc: 0.8851 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0428 - auc: 0.8812 - val_loss: 0.0456 - val_auc: 0.8863 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0426 - auc: 0.8822 - val_loss: 0.0421 - val_auc: 0.8863 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0423 - auc: 0.8836 - val_loss: 0.0424 - val_auc: 0.8876 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0418 - auc: 0.8865 - val_loss: 0.0417 - val_auc: 0.8872 - lr: 0.0025\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0417 - auc: 0.8870 - val_loss: 0.0418 - val_auc: 0.8864 - lr: 0.0025\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0418 - auc: 0.8867 - val_loss: 0.0435 - val_auc: 0.8848 - lr: 0.0025\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0418 - auc: 0.8865 - val_loss: 0.0420 - val_auc: 0.8870 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0417 - auc: 0.8872 - val_loss: 0.0419 - val_auc: 0.8871 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0412 - auc: 0.8898 - val_loss: 0.0417 - val_auc: 0.8878 - lr: 0.0012\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0413 - auc: 0.8892 - val_loss: 0.0422 - val_auc: 0.8865 - lr: 0.0012\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0413 - auc: 0.8894 - val_loss: 0.0420 - val_auc: 0.8873 - lr: 0.0012\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0412 - auc: 0.8897 - val_loss: 0.0424 - val_auc: 0.8869 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0409 - auc: 0.8916 - val_loss: 0.0418 - val_auc: 0.8870 - lr: 6.2500e-04\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0409 - auc: 0.8915 - val_loss: 0.0419 - val_auc: 0.8868 - lr: 6.2500e-04\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0408 - auc: 0.8918 - val_loss: 0.0419 - val_auc: 0.8861 - lr: 6.2500e-04\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0408 - auc: 0.8920 - val_loss: 0.0420 - val_auc: 0.8856 - lr: 6.2500e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 29ms/step - loss: 0.0672 - auc: 0.8555 - val_loss: 0.0429 - val_auc: 0.8821 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0435 - auc: 0.8784 - val_loss: 0.0431 - val_auc: 0.8813 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0438 - auc: 0.8777 - val_loss: 0.0429 - val_auc: 0.8837 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0428 - auc: 0.8822 - val_loss: 0.0423 - val_auc: 0.8826 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0425 - auc: 0.8831 - val_loss: 0.0435 - val_auc: 0.8837 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0425 - auc: 0.8833 - val_loss: 0.0423 - val_auc: 0.8850 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0423 - auc: 0.8841 - val_loss: 0.0421 - val_auc: 0.8837 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0423 - auc: 0.8841 - val_loss: 0.0420 - val_auc: 0.8849 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0422 - auc: 0.8848 - val_loss: 0.0438 - val_auc: 0.8839 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0422 - auc: 0.8849 - val_loss: 0.0423 - val_auc: 0.8850 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0419 - auc: 0.8861 - val_loss: 0.0422 - val_auc: 0.8846 - lr: 0.0050\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0419 - auc: 0.8863 - val_loss: 0.0420 - val_auc: 0.8847 - lr: 0.0050\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0414 - auc: 0.8887 - val_loss: 0.0419 - val_auc: 0.8847 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8893 - val_loss: 0.0420 - val_auc: 0.8845 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8895 - val_loss: 0.0423 - val_auc: 0.8829 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8895 - val_loss: 0.0426 - val_auc: 0.8844 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0408 - auc: 0.8916 - val_loss: 0.0422 - val_auc: 0.8832 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0407 - auc: 0.8923 - val_loss: 0.0423 - val_auc: 0.8841 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0408 - auc: 0.8919 - val_loss: 0.0420 - val_auc: 0.8846 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0408 - auc: 0.8921 - val_loss: 0.0423 - val_auc: 0.8833 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0404 - auc: 0.8943 - val_loss: 0.0424 - val_auc: 0.8834 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0403 - auc: 0.8947 - val_loss: 0.0423 - val_auc: 0.8830 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0402 - auc: 0.8952 - val_loss: 0.0424 - val_auc: 0.8841 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0402 - auc: 0.8949 - val_loss: 0.0423 - val_auc: 0.8833 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0399 - auc: 0.8968 - val_loss: 0.0423 - val_auc: 0.8838 - lr: 3.1250e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 23s 28ms/step - loss: 0.0644 - auc: 0.8568 - val_loss: 0.0432 - val_auc: 0.8795 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0449 - auc: 0.8742 - val_loss: 0.0426 - val_auc: 0.8816 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0430 - auc: 0.8811 - val_loss: 0.0430 - val_auc: 0.8827 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0431 - auc: 0.8807 - val_loss: 0.0426 - val_auc: 0.8824 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0423 - auc: 0.8842 - val_loss: 0.0430 - val_auc: 0.8826 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0424 - auc: 0.8837 - val_loss: 0.0425 - val_auc: 0.8829 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0421 - auc: 0.8851 - val_loss: 0.0433 - val_auc: 0.8834 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0421 - auc: 0.8850 - val_loss: 0.0424 - val_auc: 0.8834 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0421 - auc: 0.8852 - val_loss: 0.0429 - val_auc: 0.8831 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0421 - auc: 0.8854 - val_loss: 0.0427 - val_auc: 0.8830 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0415 - auc: 0.8886 - val_loss: 0.0421 - val_auc: 0.8840 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0415 - auc: 0.8884 - val_loss: 0.0424 - val_auc: 0.8832 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0415 - auc: 0.8884 - val_loss: 0.0422 - val_auc: 0.8838 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0414 - auc: 0.8890 - val_loss: 0.0422 - val_auc: 0.8835 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0415 - auc: 0.8884 - val_loss: 0.0421 - val_auc: 0.8840 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0410 - auc: 0.8909 - val_loss: 0.0422 - val_auc: 0.8838 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0409 - auc: 0.8913 - val_loss: 0.0424 - val_auc: 0.8835 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0409 - auc: 0.8914 - val_loss: 0.0423 - val_auc: 0.8831 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0409 - auc: 0.8917 - val_loss: 0.0423 - val_auc: 0.8835 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0405 - auc: 0.8935 - val_loss: 0.0424 - val_auc: 0.8827 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0404 - auc: 0.8943 - val_loss: 0.0423 - val_auc: 0.8826 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0404 - auc: 0.8945 - val_loss: 0.0424 - val_auc: 0.8828 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0403 - auc: 0.8947 - val_loss: 0.0425 - val_auc: 0.8827 - lr: 6.2500e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 29ms/step - loss: 0.0677 - auc: 0.8520 - val_loss: 0.0427 - val_auc: 0.8822 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0443 - auc: 0.8740 - val_loss: 0.0447 - val_auc: 0.8751 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0435 - auc: 0.8777 - val_loss: 0.0421 - val_auc: 0.8856 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0432 - auc: 0.8790 - val_loss: 0.0422 - val_auc: 0.8852 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0428 - auc: 0.8809 - val_loss: 0.0425 - val_auc: 0.8856 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0427 - auc: 0.8812 - val_loss: 0.0422 - val_auc: 0.8860 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0426 - auc: 0.8822 - val_loss: 0.0441 - val_auc: 0.8856 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0420 - auc: 0.8850 - val_loss: 0.0420 - val_auc: 0.8868 - lr: 0.0025\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0420 - auc: 0.8851 - val_loss: 0.0422 - val_auc: 0.8860 - lr: 0.0025\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0420 - auc: 0.8850 - val_loss: 0.0423 - val_auc: 0.8871 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0418 - auc: 0.8860 - val_loss: 0.0418 - val_auc: 0.8873 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0420 - auc: 0.8855 - val_loss: 0.0421 - val_auc: 0.8874 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0418 - auc: 0.8859 - val_loss: 0.0421 - val_auc: 0.8874 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0417 - auc: 0.8867 - val_loss: 0.0419 - val_auc: 0.8874 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0418 - auc: 0.8866 - val_loss: 0.0420 - val_auc: 0.8871 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0414 - auc: 0.8885 - val_loss: 0.0420 - val_auc: 0.8875 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0412 - auc: 0.8891 - val_loss: 0.0422 - val_auc: 0.8869 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8887 - val_loss: 0.0419 - val_auc: 0.8877 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0412 - auc: 0.8894 - val_loss: 0.0420 - val_auc: 0.8871 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0409 - auc: 0.8912 - val_loss: 0.0420 - val_auc: 0.8873 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0408 - auc: 0.8914 - val_loss: 0.0422 - val_auc: 0.8869 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0408 - auc: 0.8912 - val_loss: 0.0419 - val_auc: 0.8873 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0408 - auc: 0.8916 - val_loss: 0.0422 - val_auc: 0.8869 - lr: 6.2500e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 29ms/step - loss: 0.0636 - auc: 0.8552 - val_loss: 0.0434 - val_auc: 0.8780 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0441 - auc: 0.8758 - val_loss: 0.0430 - val_auc: 0.8819 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0432 - auc: 0.8794 - val_loss: 0.0427 - val_auc: 0.8832 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0429 - auc: 0.8811 - val_loss: 0.0437 - val_auc: 0.8808 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0427 - auc: 0.8820 - val_loss: 0.0425 - val_auc: 0.8837 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0425 - auc: 0.8830 - val_loss: 0.0431 - val_auc: 0.8842 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0422 - auc: 0.8841 - val_loss: 0.0427 - val_auc: 0.8831 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0421 - auc: 0.8848 - val_loss: 0.0423 - val_auc: 0.8850 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0422 - auc: 0.8847 - val_loss: 0.0427 - val_auc: 0.8842 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0422 - auc: 0.8848 - val_loss: 0.0423 - val_auc: 0.8835 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0420 - auc: 0.8859 - val_loss: 0.0423 - val_auc: 0.8845 - lr: 0.0050\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0420 - auc: 0.8856 - val_loss: 0.0434 - val_auc: 0.8842 - lr: 0.0050\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8891 - val_loss: 0.0421 - val_auc: 0.8852 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8891 - val_loss: 0.0427 - val_auc: 0.8854 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8894 - val_loss: 0.0421 - val_auc: 0.8855 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0412 - auc: 0.8897 - val_loss: 0.0421 - val_auc: 0.8851 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0412 - auc: 0.8899 - val_loss: 0.0423 - val_auc: 0.8842 - lr: 0.0025\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0408 - auc: 0.8917 - val_loss: 0.0424 - val_auc: 0.8847 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0408 - auc: 0.8921 - val_loss: 0.0425 - val_auc: 0.8837 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0407 - auc: 0.8925 - val_loss: 0.0423 - val_auc: 0.8852 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0407 - auc: 0.8923 - val_loss: 0.0424 - val_auc: 0.8833 - lr: 0.0012\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0403 - auc: 0.8944 - val_loss: 0.0423 - val_auc: 0.8841 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0403 - auc: 0.8948 - val_loss: 0.0423 - val_auc: 0.8840 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0402 - auc: 0.8948 - val_loss: 0.0427 - val_auc: 0.8836 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0402 - auc: 0.8953 - val_loss: 0.0424 - val_auc: 0.8837 - lr: 6.2500e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 30ms/step - loss: 0.0669 - auc: 0.8542 - val_loss: 0.0430 - val_auc: 0.8820 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0436 - auc: 0.8775 - val_loss: 0.0425 - val_auc: 0.8841 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0432 - auc: 0.8798 - val_loss: 0.0418 - val_auc: 0.8863 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0427 - auc: 0.8821 - val_loss: 0.0422 - val_auc: 0.8878 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0427 - auc: 0.8822 - val_loss: 0.0415 - val_auc: 0.8877 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0422 - auc: 0.8846 - val_loss: 0.0426 - val_auc: 0.8879 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0421 - auc: 0.8849 - val_loss: 0.0419 - val_auc: 0.8875 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0423 - auc: 0.8845 - val_loss: 0.0413 - val_auc: 0.8885 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0422 - auc: 0.8849 - val_loss: 0.0417 - val_auc: 0.8881 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0422 - auc: 0.8851 - val_loss: 0.0422 - val_auc: 0.8859 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0421 - auc: 0.8855 - val_loss: 0.0431 - val_auc: 0.8863 - lr: 0.0050\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0419 - auc: 0.8867 - val_loss: 0.0414 - val_auc: 0.8883 - lr: 0.0050\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0415 - auc: 0.8886 - val_loss: 0.0413 - val_auc: 0.8891 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0414 - auc: 0.8890 - val_loss: 0.0420 - val_auc: 0.8872 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0414 - auc: 0.8888 - val_loss: 0.0414 - val_auc: 0.8887 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0414 - auc: 0.8891 - val_loss: 0.0420 - val_auc: 0.8876 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0410 - auc: 0.8912 - val_loss: 0.0414 - val_auc: 0.8883 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0409 - auc: 0.8917 - val_loss: 0.0416 - val_auc: 0.8874 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8917 - val_loss: 0.0414 - val_auc: 0.8880 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0409 - auc: 0.8920 - val_loss: 0.0419 - val_auc: 0.8877 - lr: 0.0012\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 29ms/step - loss: 0.0645 - auc: 0.8529 - val_loss: 0.0445 - val_auc: 0.8785 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0435 - auc: 0.8782 - val_loss: 0.0452 - val_auc: 0.8778 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0434 - auc: 0.8786 - val_loss: 0.0430 - val_auc: 0.8816 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0431 - auc: 0.8801 - val_loss: 0.0461 - val_auc: 0.8805 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0425 - auc: 0.8827 - val_loss: 0.0431 - val_auc: 0.8819 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0424 - auc: 0.8832 - val_loss: 0.0435 - val_auc: 0.8796 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0423 - auc: 0.8837 - val_loss: 0.0432 - val_auc: 0.8828 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0418 - auc: 0.8864 - val_loss: 0.0431 - val_auc: 0.8827 - lr: 0.0025\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0417 - auc: 0.8869 - val_loss: 0.0427 - val_auc: 0.8825 - lr: 0.0025\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0417 - auc: 0.8869 - val_loss: 0.0431 - val_auc: 0.8828 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0416 - auc: 0.8871 - val_loss: 0.0437 - val_auc: 0.8824 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0417 - auc: 0.8871 - val_loss: 0.0427 - val_auc: 0.8823 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0416 - auc: 0.8872 - val_loss: 0.0426 - val_auc: 0.8827 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0417 - auc: 0.8872 - val_loss: 0.0431 - val_auc: 0.8821 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0416 - auc: 0.8873 - val_loss: 0.0435 - val_auc: 0.8829 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0415 - auc: 0.8882 - val_loss: 0.0429 - val_auc: 0.8827 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0415 - auc: 0.8882 - val_loss: 0.0430 - val_auc: 0.8818 - lr: 0.0025\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0409 - auc: 0.8909 - val_loss: 0.0426 - val_auc: 0.8838 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0409 - auc: 0.8911 - val_loss: 0.0426 - val_auc: 0.8830 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0408 - auc: 0.8915 - val_loss: 0.0431 - val_auc: 0.8824 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0408 - auc: 0.8917 - val_loss: 0.0430 - val_auc: 0.8829 - lr: 0.0012\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0403 - auc: 0.8938 - val_loss: 0.0429 - val_auc: 0.8831 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0403 - auc: 0.8941 - val_loss: 0.0428 - val_auc: 0.8826 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0402 - auc: 0.8948 - val_loss: 0.0429 - val_auc: 0.8821 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0402 - auc: 0.8946 - val_loss: 0.0432 - val_auc: 0.8815 - lr: 6.2500e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0399 - auc: 0.8963 - val_loss: 0.0431 - val_auc: 0.8815 - lr: 3.1250e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0398 - auc: 0.8971 - val_loss: 0.0435 - val_auc: 0.8812 - lr: 3.1250e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0397 - auc: 0.8971 - val_loss: 0.0432 - val_auc: 0.8812 - lr: 3.1250e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0397 - auc: 0.8975 - val_loss: 0.0434 - val_auc: 0.8807 - lr: 3.1250e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0395 - auc: 0.8983 - val_loss: 0.0434 - val_auc: 0.8810 - lr: 1.5625e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 29ms/step - loss: 0.0642 - auc: 0.8530 - val_loss: 0.0442 - val_auc: 0.8806 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0437 - auc: 0.8768 - val_loss: 0.0437 - val_auc: 0.8795 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0433 - auc: 0.8791 - val_loss: 0.0429 - val_auc: 0.8829 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0429 - auc: 0.8809 - val_loss: 0.0430 - val_auc: 0.8846 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0429 - auc: 0.8812 - val_loss: 0.0423 - val_auc: 0.8849 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0425 - auc: 0.8824 - val_loss: 0.0430 - val_auc: 0.8849 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0424 - auc: 0.8830 - val_loss: 0.0428 - val_auc: 0.8847 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0424 - auc: 0.8835 - val_loss: 0.0422 - val_auc: 0.8841 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0424 - auc: 0.8835 - val_loss: 0.0426 - val_auc: 0.8843 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0418 - auc: 0.8866 - val_loss: 0.0418 - val_auc: 0.8860 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0416 - auc: 0.8872 - val_loss: 0.0424 - val_auc: 0.8855 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0416 - auc: 0.8875 - val_loss: 0.0426 - val_auc: 0.8836 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0418 - auc: 0.8863 - val_loss: 0.0423 - val_auc: 0.8861 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0417 - auc: 0.8871 - val_loss: 0.0422 - val_auc: 0.8852 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8891 - val_loss: 0.0418 - val_auc: 0.8857 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0412 - auc: 0.8896 - val_loss: 0.0418 - val_auc: 0.8863 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0412 - auc: 0.8895 - val_loss: 0.0419 - val_auc: 0.8860 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0411 - auc: 0.8898 - val_loss: 0.0422 - val_auc: 0.8860 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0408 - auc: 0.8917 - val_loss: 0.0419 - val_auc: 0.8859 - lr: 6.2500e-04\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0408 - auc: 0.8918 - val_loss: 0.0420 - val_auc: 0.8861 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0407 - auc: 0.8923 - val_loss: 0.0421 - val_auc: 0.8843 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0406 - auc: 0.8926 - val_loss: 0.0421 - val_auc: 0.8848 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0404 - auc: 0.8937 - val_loss: 0.0421 - val_auc: 0.8850 - lr: 3.1250e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0404 - auc: 0.8940 - val_loss: 0.0422 - val_auc: 0.8849 - lr: 3.1250e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0403 - auc: 0.8944 - val_loss: 0.0422 - val_auc: 0.8847 - lr: 3.1250e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0403 - auc: 0.8946 - val_loss: 0.0422 - val_auc: 0.8839 - lr: 3.1250e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0401 - auc: 0.8958 - val_loss: 0.0422 - val_auc: 0.8844 - lr: 1.5625e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0400 - auc: 0.8959 - val_loss: 0.0422 - val_auc: 0.8842 - lr: 1.5625e-04\n",
            "[I 2024-01-29 15:40:04,829] Trial 3 finished with value: 0.8867335253291659 and parameters: {'units_0': 1024, 'activation': 'swish', 'dropout': 0.25, 'hidden_layers': 3, 'embedding_dims': 32}. Best is trial 2 with value: 0.8870233562257555.\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 27s 32ms/step - loss: 0.0542 - auc: 0.8522 - val_loss: 0.0454 - val_auc: 0.8803 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0442 - auc: 0.8748 - val_loss: 0.0430 - val_auc: 0.8809 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0435 - auc: 0.8784 - val_loss: 0.0430 - val_auc: 0.8827 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0433 - auc: 0.8793 - val_loss: 0.0425 - val_auc: 0.8831 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0430 - auc: 0.8807 - val_loss: 0.0434 - val_auc: 0.8829 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0429 - auc: 0.8806 - val_loss: 0.0432 - val_auc: 0.8834 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0427 - auc: 0.8816 - val_loss: 0.0424 - val_auc: 0.8840 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0425 - auc: 0.8825 - val_loss: 0.0428 - val_auc: 0.8827 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0424 - auc: 0.8830 - val_loss: 0.0429 - val_auc: 0.8833 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0425 - auc: 0.8824 - val_loss: 0.0428 - val_auc: 0.8831 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0426 - auc: 0.8824 - val_loss: 0.0424 - val_auc: 0.8833 - lr: 0.0050\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 11s 28ms/step - loss: 0.0421 - auc: 0.8847 - val_loss: 0.0423 - val_auc: 0.8841 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0418 - auc: 0.8860 - val_loss: 0.0425 - val_auc: 0.8847 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0418 - auc: 0.8864 - val_loss: 0.0425 - val_auc: 0.8837 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0419 - auc: 0.8859 - val_loss: 0.0423 - val_auc: 0.8845 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0415 - auc: 0.8880 - val_loss: 0.0423 - val_auc: 0.8847 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0415 - auc: 0.8883 - val_loss: 0.0423 - val_auc: 0.8845 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0414 - auc: 0.8884 - val_loss: 0.0423 - val_auc: 0.8840 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0413 - auc: 0.8892 - val_loss: 0.0422 - val_auc: 0.8850 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0413 - auc: 0.8892 - val_loss: 0.0425 - val_auc: 0.8842 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0411 - auc: 0.8901 - val_loss: 0.0422 - val_auc: 0.8848 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0409 - auc: 0.8913 - val_loss: 0.0425 - val_auc: 0.8846 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0410 - auc: 0.8908 - val_loss: 0.0422 - val_auc: 0.8850 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0408 - auc: 0.8917 - val_loss: 0.0423 - val_auc: 0.8847 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0407 - auc: 0.8927 - val_loss: 0.0423 - val_auc: 0.8845 - lr: 3.1250e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0406 - auc: 0.8931 - val_loss: 0.0423 - val_auc: 0.8843 - lr: 3.1250e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0406 - auc: 0.8931 - val_loss: 0.0425 - val_auc: 0.8844 - lr: 3.1250e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0406 - auc: 0.8929 - val_loss: 0.0424 - val_auc: 0.8844 - lr: 3.1250e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0404 - auc: 0.8939 - val_loss: 0.0424 - val_auc: 0.8843 - lr: 1.5625e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0405 - auc: 0.8937 - val_loss: 0.0424 - val_auc: 0.8843 - lr: 1.5625e-04\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0405 - auc: 0.8936 - val_loss: 0.0424 - val_auc: 0.8844 - lr: 1.5625e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 29ms/step - loss: 0.0538 - auc: 0.8528 - val_loss: 0.0478 - val_auc: 0.8837 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0448 - auc: 0.8737 - val_loss: 0.0438 - val_auc: 0.8862 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0435 - auc: 0.8792 - val_loss: 0.0420 - val_auc: 0.8860 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0431 - auc: 0.8805 - val_loss: 0.0435 - val_auc: 0.8862 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0428 - auc: 0.8819 - val_loss: 0.0430 - val_auc: 0.8866 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0427 - auc: 0.8824 - val_loss: 0.0430 - val_auc: 0.8866 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0427 - auc: 0.8820 - val_loss: 0.0429 - val_auc: 0.8868 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0420 - auc: 0.8855 - val_loss: 0.0416 - val_auc: 0.8878 - lr: 0.0025\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0419 - auc: 0.8862 - val_loss: 0.0428 - val_auc: 0.8873 - lr: 0.0025\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0419 - auc: 0.8859 - val_loss: 0.0418 - val_auc: 0.8872 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0419 - auc: 0.8864 - val_loss: 0.0419 - val_auc: 0.8875 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0419 - auc: 0.8862 - val_loss: 0.0417 - val_auc: 0.8876 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0415 - auc: 0.8885 - val_loss: 0.0416 - val_auc: 0.8872 - lr: 0.0012\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0414 - auc: 0.8887 - val_loss: 0.0417 - val_auc: 0.8875 - lr: 0.0012\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0413 - auc: 0.8893 - val_loss: 0.0420 - val_auc: 0.8871 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0414 - auc: 0.8892 - val_loss: 0.0417 - val_auc: 0.8874 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0410 - auc: 0.8908 - val_loss: 0.0416 - val_auc: 0.8870 - lr: 6.2500e-04\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0411 - auc: 0.8903 - val_loss: 0.0420 - val_auc: 0.8872 - lr: 6.2500e-04\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0411 - auc: 0.8907 - val_loss: 0.0417 - val_auc: 0.8866 - lr: 6.2500e-04\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0410 - auc: 0.8907 - val_loss: 0.0418 - val_auc: 0.8864 - lr: 6.2500e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 30ms/step - loss: 0.0540 - auc: 0.8539 - val_loss: 0.0476 - val_auc: 0.8812 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0446 - auc: 0.8748 - val_loss: 0.0437 - val_auc: 0.8840 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0437 - auc: 0.8785 - val_loss: 0.0425 - val_auc: 0.8840 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0433 - auc: 0.8798 - val_loss: 0.0427 - val_auc: 0.8850 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0429 - auc: 0.8816 - val_loss: 0.0440 - val_auc: 0.8851 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0425 - auc: 0.8831 - val_loss: 0.0422 - val_auc: 0.8842 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0426 - auc: 0.8829 - val_loss: 0.0425 - val_auc: 0.8840 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0425 - auc: 0.8830 - val_loss: 0.0434 - val_auc: 0.8849 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0424 - auc: 0.8835 - val_loss: 0.0423 - val_auc: 0.8827 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0422 - auc: 0.8846 - val_loss: 0.0423 - val_auc: 0.8846 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0418 - auc: 0.8868 - val_loss: 0.0422 - val_auc: 0.8849 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0418 - auc: 0.8872 - val_loss: 0.0422 - val_auc: 0.8851 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0417 - auc: 0.8873 - val_loss: 0.0430 - val_auc: 0.8839 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0417 - auc: 0.8877 - val_loss: 0.0420 - val_auc: 0.8849 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0416 - auc: 0.8882 - val_loss: 0.0424 - val_auc: 0.8854 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0417 - auc: 0.8878 - val_loss: 0.0421 - val_auc: 0.8848 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0415 - auc: 0.8882 - val_loss: 0.0424 - val_auc: 0.8842 - lr: 0.0025\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0415 - auc: 0.8883 - val_loss: 0.0424 - val_auc: 0.8841 - lr: 0.0025\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0410 - auc: 0.8910 - val_loss: 0.0420 - val_auc: 0.8848 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0410 - auc: 0.8913 - val_loss: 0.0421 - val_auc: 0.8849 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0410 - auc: 0.8912 - val_loss: 0.0419 - val_auc: 0.8848 - lr: 0.0012\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0409 - auc: 0.8920 - val_loss: 0.0422 - val_auc: 0.8838 - lr: 0.0012\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0409 - auc: 0.8918 - val_loss: 0.0423 - val_auc: 0.8840 - lr: 0.0012\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0408 - auc: 0.8925 - val_loss: 0.0427 - val_auc: 0.8831 - lr: 0.0012\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0408 - auc: 0.8926 - val_loss: 0.0423 - val_auc: 0.8841 - lr: 0.0012\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0404 - auc: 0.8947 - val_loss: 0.0424 - val_auc: 0.8837 - lr: 6.2500e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0403 - auc: 0.8950 - val_loss: 0.0424 - val_auc: 0.8832 - lr: 6.2500e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0402 - auc: 0.8954 - val_loss: 0.0425 - val_auc: 0.8835 - lr: 6.2500e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0402 - auc: 0.8958 - val_loss: 0.0424 - val_auc: 0.8827 - lr: 6.2500e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0400 - auc: 0.8965 - val_loss: 0.0424 - val_auc: 0.8829 - lr: 3.1250e-04\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0399 - auc: 0.8973 - val_loss: 0.0426 - val_auc: 0.8829 - lr: 3.1250e-04\n",
            "Epoch 32/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0398 - auc: 0.8975 - val_loss: 0.0425 - val_auc: 0.8827 - lr: 3.1250e-04\n",
            "Epoch 33/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0398 - auc: 0.8976 - val_loss: 0.0427 - val_auc: 0.8827 - lr: 3.1250e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 23s 28ms/step - loss: 0.0544 - auc: 0.8533 - val_loss: 0.0467 - val_auc: 0.8805 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0454 - auc: 0.8727 - val_loss: 0.0458 - val_auc: 0.8824 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0436 - auc: 0.8789 - val_loss: 0.0424 - val_auc: 0.8831 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0433 - auc: 0.8805 - val_loss: 0.0425 - val_auc: 0.8828 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0429 - auc: 0.8819 - val_loss: 0.0428 - val_auc: 0.8830 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0426 - auc: 0.8831 - val_loss: 0.0426 - val_auc: 0.8834 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0427 - auc: 0.8829 - val_loss: 0.0431 - val_auc: 0.8825 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0420 - auc: 0.8859 - val_loss: 0.0425 - val_auc: 0.8836 - lr: 0.0025\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0420 - auc: 0.8863 - val_loss: 0.0422 - val_auc: 0.8841 - lr: 0.0025\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0418 - auc: 0.8871 - val_loss: 0.0420 - val_auc: 0.8844 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0418 - auc: 0.8869 - val_loss: 0.0423 - val_auc: 0.8840 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0419 - auc: 0.8868 - val_loss: 0.0424 - val_auc: 0.8840 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0418 - auc: 0.8867 - val_loss: 0.0424 - val_auc: 0.8835 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0418 - auc: 0.8871 - val_loss: 0.0422 - val_auc: 0.8834 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0414 - auc: 0.8891 - val_loss: 0.0422 - val_auc: 0.8845 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8892 - val_loss: 0.0421 - val_auc: 0.8843 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8895 - val_loss: 0.0426 - val_auc: 0.8842 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8899 - val_loss: 0.0423 - val_auc: 0.8836 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0409 - auc: 0.8916 - val_loss: 0.0421 - val_auc: 0.8842 - lr: 6.2500e-04\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0409 - auc: 0.8919 - val_loss: 0.0423 - val_auc: 0.8841 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0409 - auc: 0.8919 - val_loss: 0.0421 - val_auc: 0.8836 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0407 - auc: 0.8925 - val_loss: 0.0422 - val_auc: 0.8837 - lr: 6.2500e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 28ms/step - loss: 0.0547 - auc: 0.8505 - val_loss: 0.0438 - val_auc: 0.8812 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0447 - auc: 0.8733 - val_loss: 0.0439 - val_auc: 0.8851 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0436 - auc: 0.8772 - val_loss: 0.0424 - val_auc: 0.8862 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0434 - auc: 0.8778 - val_loss: 0.0421 - val_auc: 0.8869 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0429 - auc: 0.8804 - val_loss: 0.0425 - val_auc: 0.8859 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0429 - auc: 0.8807 - val_loss: 0.0420 - val_auc: 0.8876 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0427 - auc: 0.8817 - val_loss: 0.0427 - val_auc: 0.8870 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0426 - auc: 0.8821 - val_loss: 0.0424 - val_auc: 0.8864 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0421 - auc: 0.8844 - val_loss: 0.0418 - val_auc: 0.8875 - lr: 0.0025\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0421 - auc: 0.8848 - val_loss: 0.0427 - val_auc: 0.8867 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0421 - auc: 0.8849 - val_loss: 0.0419 - val_auc: 0.8872 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0421 - auc: 0.8847 - val_loss: 0.0422 - val_auc: 0.8871 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0420 - auc: 0.8851 - val_loss: 0.0420 - val_auc: 0.8875 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0416 - auc: 0.8877 - val_loss: 0.0417 - val_auc: 0.8879 - lr: 0.0012\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0415 - auc: 0.8876 - val_loss: 0.0418 - val_auc: 0.8875 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0415 - auc: 0.8877 - val_loss: 0.0418 - val_auc: 0.8878 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0415 - auc: 0.8876 - val_loss: 0.0418 - val_auc: 0.8875 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0415 - auc: 0.8879 - val_loss: 0.0419 - val_auc: 0.8867 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0412 - auc: 0.8894 - val_loss: 0.0418 - val_auc: 0.8872 - lr: 6.2500e-04\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0411 - auc: 0.8900 - val_loss: 0.0421 - val_auc: 0.8870 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0410 - auc: 0.8905 - val_loss: 0.0424 - val_auc: 0.8870 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0410 - auc: 0.8907 - val_loss: 0.0418 - val_auc: 0.8871 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0408 - auc: 0.8916 - val_loss: 0.0419 - val_auc: 0.8870 - lr: 3.1250e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0407 - auc: 0.8925 - val_loss: 0.0421 - val_auc: 0.8869 - lr: 3.1250e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0407 - auc: 0.8925 - val_loss: 0.0419 - val_auc: 0.8868 - lr: 3.1250e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0407 - auc: 0.8925 - val_loss: 0.0420 - val_auc: 0.8863 - lr: 3.1250e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 29ms/step - loss: 0.0533 - auc: 0.8523 - val_loss: 0.0451 - val_auc: 0.8632 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0449 - auc: 0.8734 - val_loss: 0.0452 - val_auc: 0.8840 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0439 - auc: 0.8778 - val_loss: 0.0425 - val_auc: 0.8842 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0434 - auc: 0.8797 - val_loss: 0.0437 - val_auc: 0.8831 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0429 - auc: 0.8819 - val_loss: 0.0427 - val_auc: 0.8836 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0427 - auc: 0.8826 - val_loss: 0.0425 - val_auc: 0.8844 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0428 - auc: 0.8819 - val_loss: 0.0430 - val_auc: 0.8851 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0420 - auc: 0.8855 - val_loss: 0.0421 - val_auc: 0.8852 - lr: 0.0025\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0419 - auc: 0.8861 - val_loss: 0.0421 - val_auc: 0.8855 - lr: 0.0025\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0421 - auc: 0.8854 - val_loss: 0.0422 - val_auc: 0.8852 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0419 - auc: 0.8861 - val_loss: 0.0421 - val_auc: 0.8849 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0418 - auc: 0.8866 - val_loss: 0.0435 - val_auc: 0.8856 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0416 - auc: 0.8879 - val_loss: 0.0419 - val_auc: 0.8859 - lr: 0.0012\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0415 - auc: 0.8882 - val_loss: 0.0420 - val_auc: 0.8854 - lr: 0.0012\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0414 - auc: 0.8889 - val_loss: 0.0420 - val_auc: 0.8857 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 11s 26ms/step - loss: 0.0413 - auc: 0.8897 - val_loss: 0.0421 - val_auc: 0.8858 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0413 - auc: 0.8892 - val_loss: 0.0423 - val_auc: 0.8849 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0411 - auc: 0.8904 - val_loss: 0.0421 - val_auc: 0.8852 - lr: 6.2500e-04\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0410 - auc: 0.8910 - val_loss: 0.0421 - val_auc: 0.8850 - lr: 6.2500e-04\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0410 - auc: 0.8913 - val_loss: 0.0422 - val_auc: 0.8850 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0409 - auc: 0.8916 - val_loss: 0.0421 - val_auc: 0.8848 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0407 - auc: 0.8926 - val_loss: 0.0422 - val_auc: 0.8852 - lr: 3.1250e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0407 - auc: 0.8926 - val_loss: 0.0423 - val_auc: 0.8850 - lr: 3.1250e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0407 - auc: 0.8930 - val_loss: 0.0423 - val_auc: 0.8851 - lr: 3.1250e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0406 - auc: 0.8930 - val_loss: 0.0422 - val_auc: 0.8849 - lr: 3.1250e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 28s 30ms/step - loss: 0.0548 - auc: 0.8541 - val_loss: 0.0432 - val_auc: 0.8857 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0440 - auc: 0.8769 - val_loss: 0.0433 - val_auc: 0.8845 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0436 - auc: 0.8783 - val_loss: 0.0420 - val_auc: 0.8872 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0430 - auc: 0.8810 - val_loss: 0.0440 - val_auc: 0.8878 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0428 - auc: 0.8817 - val_loss: 0.0420 - val_auc: 0.8883 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0427 - auc: 0.8826 - val_loss: 0.0418 - val_auc: 0.8875 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0425 - auc: 0.8834 - val_loss: 0.0418 - val_auc: 0.8883 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0424 - auc: 0.8838 - val_loss: 0.0418 - val_auc: 0.8881 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0424 - auc: 0.8838 - val_loss: 0.0416 - val_auc: 0.8877 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0423 - auc: 0.8845 - val_loss: 0.0414 - val_auc: 0.8886 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0423 - auc: 0.8843 - val_loss: 0.0424 - val_auc: 0.8886 - lr: 0.0050\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0424 - auc: 0.8837 - val_loss: 0.0416 - val_auc: 0.8874 - lr: 0.0050\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0424 - auc: 0.8838 - val_loss: 0.0432 - val_auc: 0.8887 - lr: 0.0050\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0420 - auc: 0.8858 - val_loss: 0.0415 - val_auc: 0.8880 - lr: 0.0050\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0417 - auc: 0.8875 - val_loss: 0.0416 - val_auc: 0.8883 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0415 - auc: 0.8885 - val_loss: 0.0413 - val_auc: 0.8887 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0415 - auc: 0.8884 - val_loss: 0.0414 - val_auc: 0.8883 - lr: 0.0025\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0414 - auc: 0.8890 - val_loss: 0.0415 - val_auc: 0.8885 - lr: 0.0025\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0411 - auc: 0.8906 - val_loss: 0.0416 - val_auc: 0.8887 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0411 - auc: 0.8908 - val_loss: 0.0417 - val_auc: 0.8879 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0410 - auc: 0.8916 - val_loss: 0.0416 - val_auc: 0.8881 - lr: 0.0012\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0409 - auc: 0.8922 - val_loss: 0.0418 - val_auc: 0.8878 - lr: 0.0012\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0406 - auc: 0.8935 - val_loss: 0.0415 - val_auc: 0.8881 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0406 - auc: 0.8932 - val_loss: 0.0415 - val_auc: 0.8881 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0406 - auc: 0.8937 - val_loss: 0.0415 - val_auc: 0.8879 - lr: 6.2500e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0405 - auc: 0.8942 - val_loss: 0.0416 - val_auc: 0.8875 - lr: 6.2500e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0403 - auc: 0.8951 - val_loss: 0.0417 - val_auc: 0.8875 - lr: 3.1250e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0402 - auc: 0.8955 - val_loss: 0.0416 - val_auc: 0.8873 - lr: 3.1250e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 29ms/step - loss: 0.0523 - auc: 0.8543 - val_loss: 0.0464 - val_auc: 0.8806 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0444 - auc: 0.8756 - val_loss: 0.0434 - val_auc: 0.8813 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0435 - auc: 0.8786 - val_loss: 0.0429 - val_auc: 0.8815 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0431 - auc: 0.8805 - val_loss: 0.0440 - val_auc: 0.8820 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0428 - auc: 0.8816 - val_loss: 0.0447 - val_auc: 0.8814 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0426 - auc: 0.8821 - val_loss: 0.0433 - val_auc: 0.8819 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0425 - auc: 0.8827 - val_loss: 0.0438 - val_auc: 0.8825 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0420 - auc: 0.8853 - val_loss: 0.0427 - val_auc: 0.8823 - lr: 0.0025\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0419 - auc: 0.8859 - val_loss: 0.0431 - val_auc: 0.8823 - lr: 0.0025\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0420 - auc: 0.8855 - val_loss: 0.0426 - val_auc: 0.8830 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0419 - auc: 0.8860 - val_loss: 0.0426 - val_auc: 0.8830 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0418 - auc: 0.8868 - val_loss: 0.0427 - val_auc: 0.8824 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0417 - auc: 0.8868 - val_loss: 0.0429 - val_auc: 0.8834 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0418 - auc: 0.8866 - val_loss: 0.0426 - val_auc: 0.8830 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0414 - auc: 0.8883 - val_loss: 0.0424 - val_auc: 0.8840 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0413 - auc: 0.8890 - val_loss: 0.0425 - val_auc: 0.8837 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0413 - auc: 0.8892 - val_loss: 0.0426 - val_auc: 0.8834 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0412 - auc: 0.8897 - val_loss: 0.0427 - val_auc: 0.8823 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0411 - auc: 0.8901 - val_loss: 0.0426 - val_auc: 0.8832 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0409 - auc: 0.8913 - val_loss: 0.0429 - val_auc: 0.8832 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0409 - auc: 0.8915 - val_loss: 0.0425 - val_auc: 0.8836 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0407 - auc: 0.8922 - val_loss: 0.0427 - val_auc: 0.8834 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0408 - auc: 0.8921 - val_loss: 0.0428 - val_auc: 0.8832 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0405 - auc: 0.8937 - val_loss: 0.0427 - val_auc: 0.8833 - lr: 3.1250e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0405 - auc: 0.8934 - val_loss: 0.0428 - val_auc: 0.8829 - lr: 3.1250e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0405 - auc: 0.8934 - val_loss: 0.0427 - val_auc: 0.8828 - lr: 3.1250e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0404 - auc: 0.8941 - val_loss: 0.0427 - val_auc: 0.8829 - lr: 3.1250e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 29ms/step - loss: 0.0531 - auc: 0.8526 - val_loss: 0.0431 - val_auc: 0.8787 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0446 - auc: 0.8738 - val_loss: 0.0432 - val_auc: 0.8824 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0438 - auc: 0.8768 - val_loss: 0.0433 - val_auc: 0.8839 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0432 - auc: 0.8799 - val_loss: 0.0428 - val_auc: 0.8846 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0430 - auc: 0.8807 - val_loss: 0.0437 - val_auc: 0.8856 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0428 - auc: 0.8814 - val_loss: 0.0422 - val_auc: 0.8850 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0426 - auc: 0.8824 - val_loss: 0.0430 - val_auc: 0.8850 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0426 - auc: 0.8824 - val_loss: 0.0427 - val_auc: 0.8858 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0425 - auc: 0.8830 - val_loss: 0.0428 - val_auc: 0.8860 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0425 - auc: 0.8823 - val_loss: 0.0432 - val_auc: 0.8853 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0421 - auc: 0.8845 - val_loss: 0.0420 - val_auc: 0.8857 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0419 - auc: 0.8858 - val_loss: 0.0421 - val_auc: 0.8861 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0419 - auc: 0.8861 - val_loss: 0.0420 - val_auc: 0.8861 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0418 - auc: 0.8860 - val_loss: 0.0421 - val_auc: 0.8853 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0419 - auc: 0.8859 - val_loss: 0.0422 - val_auc: 0.8856 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0414 - auc: 0.8885 - val_loss: 0.0420 - val_auc: 0.8859 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0414 - auc: 0.8888 - val_loss: 0.0420 - val_auc: 0.8849 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0414 - auc: 0.8885 - val_loss: 0.0422 - val_auc: 0.8857 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0412 - auc: 0.8896 - val_loss: 0.0420 - val_auc: 0.8856 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0410 - auc: 0.8906 - val_loss: 0.0419 - val_auc: 0.8856 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0409 - auc: 0.8911 - val_loss: 0.0421 - val_auc: 0.8854 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0410 - auc: 0.8911 - val_loss: 0.0421 - val_auc: 0.8852 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0409 - auc: 0.8911 - val_loss: 0.0419 - val_auc: 0.8852 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0408 - auc: 0.8918 - val_loss: 0.0420 - val_auc: 0.8853 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0406 - auc: 0.8927 - val_loss: 0.0420 - val_auc: 0.8852 - lr: 3.1250e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0406 - auc: 0.8931 - val_loss: 0.0422 - val_auc: 0.8851 - lr: 3.1250e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0406 - auc: 0.8930 - val_loss: 0.0421 - val_auc: 0.8849 - lr: 3.1250e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0406 - auc: 0.8930 - val_loss: 0.0421 - val_auc: 0.8846 - lr: 3.1250e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0403 - auc: 0.8947 - val_loss: 0.0423 - val_auc: 0.8847 - lr: 1.5625e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 9s 22ms/step - loss: 0.0405 - auc: 0.8938 - val_loss: 0.0422 - val_auc: 0.8847 - lr: 1.5625e-04\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0403 - auc: 0.8947 - val_loss: 0.0422 - val_auc: 0.8845 - lr: 1.5625e-04\n",
            "Epoch 32/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0403 - auc: 0.8946 - val_loss: 0.0422 - val_auc: 0.8847 - lr: 1.5625e-04\n",
            "[I 2024-01-29 16:33:01,922] Trial 4 finished with value: 0.8870219389597574 and parameters: {'units_0': 768, 'activation': 'gelu', 'dropout': 0.5, 'hidden_layers': 3, 'embedding_dims': 24}. Best is trial 2 with value: 0.8870233562257555.\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 25s 30ms/step - loss: 0.0556 - auc: 0.8543 - val_loss: 0.0472 - val_auc: 0.8584 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0447 - auc: 0.8730 - val_loss: 0.0427 - val_auc: 0.8824 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0435 - auc: 0.8781 - val_loss: 0.0438 - val_auc: 0.8799 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0431 - auc: 0.8794 - val_loss: 0.0428 - val_auc: 0.8828 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0428 - auc: 0.8807 - val_loss: 0.0435 - val_auc: 0.8825 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0425 - auc: 0.8822 - val_loss: 0.0429 - val_auc: 0.8825 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 23ms/step - loss: 0.0419 - auc: 0.8858 - val_loss: 0.0425 - val_auc: 0.8831 - lr: 0.0025\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0419 - auc: 0.8856 - val_loss: 0.0423 - val_auc: 0.8840 - lr: 0.0025\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0418 - auc: 0.8860 - val_loss: 0.0430 - val_auc: 0.8837 - lr: 0.0025\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0418 - auc: 0.8861 - val_loss: 0.0424 - val_auc: 0.8838 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0419 - auc: 0.8856 - val_loss: 0.0423 - val_auc: 0.8845 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "343/344 [============================>.] - ETA: 0s - loss: 0.0417 - auc: 0.8863[I 2024-01-29 16:36:30,254] Trial 5 pruned. Trial was pruned at epoch 11.\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 26s 31ms/step - loss: 0.0589 - auc: 0.8593 - val_loss: 0.0443 - val_auc: 0.8802 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0433 - auc: 0.8789 - val_loss: 0.0439 - val_auc: 0.8808 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0433 - auc: 0.8784 - val_loss: 0.0431 - val_auc: 0.8824 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0427 - auc: 0.8817 - val_loss: 0.0428 - val_auc: 0.8828 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0427 - auc: 0.8815 - val_loss: 0.0425 - val_auc: 0.8836 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0425 - auc: 0.8827 - val_loss: 0.0434 - val_auc: 0.8817 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0424 - auc: 0.8831 - val_loss: 0.0441 - val_auc: 0.8834 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0423 - auc: 0.8833 - val_loss: 0.0427 - val_auc: 0.8831 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0421 - auc: 0.8844 - val_loss: 0.0435 - val_auc: 0.8834 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0418 - auc: 0.8863 - val_loss: 0.0426 - val_auc: 0.8846 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0418 - auc: 0.8863 - val_loss: 0.0423 - val_auc: 0.8844 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0417 - auc: 0.8868 - val_loss: 0.0425 - val_auc: 0.8840 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0417 - auc: 0.8869 - val_loss: 0.0428 - val_auc: 0.8840 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0416 - auc: 0.8872 - val_loss: 0.0423 - val_auc: 0.8847 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0417 - auc: 0.8871 - val_loss: 0.0432 - val_auc: 0.8837 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0412 - auc: 0.8896 - val_loss: 0.0427 - val_auc: 0.8823 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0412 - auc: 0.8899 - val_loss: 0.0424 - val_auc: 0.8840 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0411 - auc: 0.8900 - val_loss: 0.0427 - val_auc: 0.8846 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0409 - auc: 0.8908 - val_loss: 0.0433 - val_auc: 0.8838 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0407 - auc: 0.8919 - val_loss: 0.0426 - val_auc: 0.8836 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0406 - auc: 0.8926 - val_loss: 0.0426 - val_auc: 0.8843 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0406 - auc: 0.8927 - val_loss: 0.0431 - val_auc: 0.8824 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0405 - auc: 0.8931 - val_loss: 0.0428 - val_auc: 0.8830 - lr: 6.2500e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 25s 30ms/step - loss: 0.0613 - auc: 0.8565 - val_loss: 0.0429 - val_auc: 0.8846 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0430 - auc: 0.8800 - val_loss: 0.0425 - val_auc: 0.8856 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0431 - auc: 0.8800 - val_loss: 0.0434 - val_auc: 0.8829 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0425 - auc: 0.8830 - val_loss: 0.0429 - val_auc: 0.8857 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0422 - auc: 0.8841 - val_loss: 0.0444 - val_auc: 0.8862 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0424 - auc: 0.8837 - val_loss: 0.0426 - val_auc: 0.8863 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0419 - auc: 0.8866 - val_loss: 0.0425 - val_auc: 0.8858 - lr: 0.0025\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0417 - auc: 0.8868 - val_loss: 0.0422 - val_auc: 0.8861 - lr: 0.0025\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0418 - auc: 0.8868 - val_loss: 0.0418 - val_auc: 0.8866 - lr: 0.0025\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0417 - auc: 0.8872 - val_loss: 0.0420 - val_auc: 0.8856 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0418 - auc: 0.8865 - val_loss: 0.0423 - val_auc: 0.8863 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0416 - auc: 0.8875 - val_loss: 0.0421 - val_auc: 0.8863 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0417 - auc: 0.8874 - val_loss: 0.0421 - val_auc: 0.8866 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0413 - auc: 0.8891 - val_loss: 0.0418 - val_auc: 0.8874 - lr: 0.0012\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0412 - auc: 0.8898 - val_loss: 0.0419 - val_auc: 0.8865 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0412 - auc: 0.8897 - val_loss: 0.0420 - val_auc: 0.8865 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0412 - auc: 0.8897 - val_loss: 0.0418 - val_auc: 0.8869 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0408 - auc: 0.8915 - val_loss: 0.0419 - val_auc: 0.8868 - lr: 6.2500e-04\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0408 - auc: 0.8916 - val_loss: 0.0420 - val_auc: 0.8868 - lr: 6.2500e-04\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0408 - auc: 0.8920 - val_loss: 0.0417 - val_auc: 0.8866 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0407 - auc: 0.8924 - val_loss: 0.0417 - val_auc: 0.8867 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0407 - auc: 0.8926 - val_loss: 0.0419 - val_auc: 0.8866 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0405 - auc: 0.8933 - val_loss: 0.0422 - val_auc: 0.8870 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0406 - auc: 0.8928 - val_loss: 0.0419 - val_auc: 0.8861 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0404 - auc: 0.8941 - val_loss: 0.0419 - val_auc: 0.8863 - lr: 3.1250e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0403 - auc: 0.8946 - val_loss: 0.0419 - val_auc: 0.8864 - lr: 3.1250e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0402 - auc: 0.8949 - val_loss: 0.0422 - val_auc: 0.8858 - lr: 3.1250e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0401 - auc: 0.8952 - val_loss: 0.0421 - val_auc: 0.8859 - lr: 3.1250e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0400 - auc: 0.8960 - val_loss: 0.0423 - val_auc: 0.8861 - lr: 1.5625e-04\n",
            "Epoch 30/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0399 - auc: 0.8966 - val_loss: 0.0422 - val_auc: 0.8857 - lr: 1.5625e-04\n",
            "Epoch 31/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0398 - auc: 0.8968 - val_loss: 0.0425 - val_auc: 0.8852 - lr: 1.5625e-04\n",
            "Epoch 32/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0398 - auc: 0.8971 - val_loss: 0.0424 - val_auc: 0.8853 - lr: 1.5625e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 25s 30ms/step - loss: 0.0562 - auc: 0.8606 - val_loss: 0.0437 - val_auc: 0.8788 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0437 - auc: 0.8786 - val_loss: 0.0439 - val_auc: 0.8818 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0427 - auc: 0.8828 - val_loss: 0.0433 - val_auc: 0.8828 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0427 - auc: 0.8823 - val_loss: 0.0427 - val_auc: 0.8837 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0425 - auc: 0.8832 - val_loss: 0.0424 - val_auc: 0.8824 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0422 - auc: 0.8845 - val_loss: 0.0424 - val_auc: 0.8844 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0422 - auc: 0.8844 - val_loss: 0.0418 - val_auc: 0.8857 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0420 - auc: 0.8859 - val_loss: 0.0424 - val_auc: 0.8843 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0420 - auc: 0.8858 - val_loss: 0.0425 - val_auc: 0.8831 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0420 - auc: 0.8856 - val_loss: 0.0430 - val_auc: 0.8853 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0418 - auc: 0.8867 - val_loss: 0.0424 - val_auc: 0.8840 - lr: 0.0050\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0415 - auc: 0.8885 - val_loss: 0.0419 - val_auc: 0.8852 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0414 - auc: 0.8888 - val_loss: 0.0423 - val_auc: 0.8853 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0412 - auc: 0.8897 - val_loss: 0.0420 - val_auc: 0.8858 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0413 - auc: 0.8898 - val_loss: 0.0420 - val_auc: 0.8846 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0408 - auc: 0.8917 - val_loss: 0.0420 - val_auc: 0.8854 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0408 - auc: 0.8921 - val_loss: 0.0420 - val_auc: 0.8849 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0407 - auc: 0.8925 - val_loss: 0.0422 - val_auc: 0.8833 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0406 - auc: 0.8931 - val_loss: 0.0424 - val_auc: 0.8827 - lr: 0.0012\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 30ms/step - loss: 0.0560 - auc: 0.8583 - val_loss: 0.0449 - val_auc: 0.8820 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0431 - auc: 0.8803 - val_loss: 0.0427 - val_auc: 0.8808 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0430 - auc: 0.8813 - val_loss: 0.0423 - val_auc: 0.8831 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0427 - auc: 0.8826 - val_loss: 0.0425 - val_auc: 0.8831 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0423 - auc: 0.8840 - val_loss: 0.0435 - val_auc: 0.8833 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0424 - auc: 0.8843 - val_loss: 0.0440 - val_auc: 0.8830 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0421 - auc: 0.8849 - val_loss: 0.0430 - val_auc: 0.8787 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0417 - auc: 0.8873 - val_loss: 0.0426 - val_auc: 0.8840 - lr: 0.0025\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0415 - auc: 0.8880 - val_loss: 0.0424 - val_auc: 0.8831 - lr: 0.0025\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0416 - auc: 0.8877 - val_loss: 0.0423 - val_auc: 0.8839 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0416 - auc: 0.8877 - val_loss: 0.0423 - val_auc: 0.8841 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0414 - auc: 0.8892 - val_loss: 0.0420 - val_auc: 0.8848 - lr: 0.0012\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8895 - val_loss: 0.0425 - val_auc: 0.8841 - lr: 0.0012\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0413 - auc: 0.8896 - val_loss: 0.0424 - val_auc: 0.8840 - lr: 0.0012\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0413 - auc: 0.8896 - val_loss: 0.0423 - val_auc: 0.8838 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0412 - auc: 0.8902 - val_loss: 0.0425 - val_auc: 0.8841 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0409 - auc: 0.8915 - val_loss: 0.0421 - val_auc: 0.8841 - lr: 6.2500e-04\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0409 - auc: 0.8918 - val_loss: 0.0422 - val_auc: 0.8840 - lr: 6.2500e-04\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0406 - auc: 0.8930 - val_loss: 0.0423 - val_auc: 0.8829 - lr: 6.2500e-04\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0407 - auc: 0.8924 - val_loss: 0.0424 - val_auc: 0.8835 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0404 - auc: 0.8940 - val_loss: 0.0423 - val_auc: 0.8833 - lr: 3.1250e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0404 - auc: 0.8942 - val_loss: 0.0423 - val_auc: 0.8831 - lr: 3.1250e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0403 - auc: 0.8946 - val_loss: 0.0426 - val_auc: 0.8829 - lr: 3.1250e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0404 - auc: 0.8945 - val_loss: 0.0427 - val_auc: 0.8830 - lr: 3.1250e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 25s 30ms/step - loss: 0.0612 - auc: 0.8564 - val_loss: 0.0435 - val_auc: 0.8807 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0437 - auc: 0.8768 - val_loss: 0.0429 - val_auc: 0.8859 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0430 - auc: 0.8795 - val_loss: 0.0434 - val_auc: 0.8859 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0430 - auc: 0.8806 - val_loss: 0.0426 - val_auc: 0.8852 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0426 - auc: 0.8817 - val_loss: 0.0424 - val_auc: 0.8868 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0426 - auc: 0.8818 - val_loss: 0.0421 - val_auc: 0.8875 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0425 - auc: 0.8830 - val_loss: 0.0437 - val_auc: 0.8844 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0423 - auc: 0.8836 - val_loss: 0.0423 - val_auc: 0.8867 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0423 - auc: 0.8835 - val_loss: 0.0423 - val_auc: 0.8871 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0422 - auc: 0.8837 - val_loss: 0.0423 - val_auc: 0.8871 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0418 - auc: 0.8864 - val_loss: 0.0419 - val_auc: 0.8869 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0417 - auc: 0.8869 - val_loss: 0.0418 - val_auc: 0.8873 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0417 - auc: 0.8868 - val_loss: 0.0418 - val_auc: 0.8881 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0416 - auc: 0.8873 - val_loss: 0.0419 - val_auc: 0.8870 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0416 - auc: 0.8875 - val_loss: 0.0421 - val_auc: 0.8861 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0415 - auc: 0.8875 - val_loss: 0.0421 - val_auc: 0.8872 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0412 - auc: 0.8897 - val_loss: 0.0422 - val_auc: 0.8869 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0411 - auc: 0.8902 - val_loss: 0.0422 - val_auc: 0.8869 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0410 - auc: 0.8903 - val_loss: 0.0420 - val_auc: 0.8871 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0410 - auc: 0.8906 - val_loss: 0.0421 - val_auc: 0.8861 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0407 - auc: 0.8926 - val_loss: 0.0419 - val_auc: 0.8870 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0406 - auc: 0.8927 - val_loss: 0.0422 - val_auc: 0.8864 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0405 - auc: 0.8932 - val_loss: 0.0420 - val_auc: 0.8861 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0405 - auc: 0.8932 - val_loss: 0.0424 - val_auc: 0.8859 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0402 - auc: 0.8948 - val_loss: 0.0422 - val_auc: 0.8865 - lr: 3.1250e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 25s 29ms/step - loss: 0.0571 - auc: 0.8596 - val_loss: 0.0452 - val_auc: 0.8817 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0436 - auc: 0.8776 - val_loss: 0.0427 - val_auc: 0.8836 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0427 - auc: 0.8819 - val_loss: 0.0428 - val_auc: 0.8841 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0427 - auc: 0.8824 - val_loss: 0.0438 - val_auc: 0.8834 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0425 - auc: 0.8832 - val_loss: 0.0432 - val_auc: 0.8831 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0422 - auc: 0.8843 - val_loss: 0.0429 - val_auc: 0.8848 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0419 - auc: 0.8863 - val_loss: 0.0431 - val_auc: 0.8841 - lr: 0.0025\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0418 - auc: 0.8865 - val_loss: 0.0424 - val_auc: 0.8844 - lr: 0.0025\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0417 - auc: 0.8866 - val_loss: 0.0422 - val_auc: 0.8854 - lr: 0.0025\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0417 - auc: 0.8872 - val_loss: 0.0421 - val_auc: 0.8856 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0417 - auc: 0.8876 - val_loss: 0.0422 - val_auc: 0.8844 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0417 - auc: 0.8874 - val_loss: 0.0424 - val_auc: 0.8853 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0417 - auc: 0.8873 - val_loss: 0.0424 - val_auc: 0.8856 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0416 - auc: 0.8878 - val_loss: 0.0424 - val_auc: 0.8850 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0411 - auc: 0.8906 - val_loss: 0.0425 - val_auc: 0.8847 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0410 - auc: 0.8907 - val_loss: 0.0425 - val_auc: 0.8850 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0410 - auc: 0.8907 - val_loss: 0.0429 - val_auc: 0.8835 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0410 - auc: 0.8908 - val_loss: 0.0425 - val_auc: 0.8847 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0407 - auc: 0.8925 - val_loss: 0.0424 - val_auc: 0.8849 - lr: 6.2500e-04\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0406 - auc: 0.8929 - val_loss: 0.0425 - val_auc: 0.8843 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0405 - auc: 0.8932 - val_loss: 0.0426 - val_auc: 0.8847 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0405 - auc: 0.8937 - val_loss: 0.0428 - val_auc: 0.8835 - lr: 6.2500e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 26s 32ms/step - loss: 0.0553 - auc: 0.8640 - val_loss: 0.0449 - val_auc: 0.8853 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0433 - auc: 0.8796 - val_loss: 0.0419 - val_auc: 0.8874 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0429 - auc: 0.8811 - val_loss: 0.0422 - val_auc: 0.8866 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0427 - auc: 0.8826 - val_loss: 0.0421 - val_auc: 0.8864 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0425 - auc: 0.8832 - val_loss: 0.0423 - val_auc: 0.8876 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0423 - auc: 0.8843 - val_loss: 0.0414 - val_auc: 0.8883 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0424 - auc: 0.8839 - val_loss: 0.0417 - val_auc: 0.8884 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0421 - auc: 0.8848 - val_loss: 0.0417 - val_auc: 0.8869 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0421 - auc: 0.8855 - val_loss: 0.0426 - val_auc: 0.8885 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0421 - auc: 0.8856 - val_loss: 0.0417 - val_auc: 0.8880 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0416 - auc: 0.8880 - val_loss: 0.0418 - val_auc: 0.8881 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0416 - auc: 0.8879 - val_loss: 0.0419 - val_auc: 0.8884 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0415 - auc: 0.8883 - val_loss: 0.0414 - val_auc: 0.8883 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0415 - auc: 0.8884 - val_loss: 0.0415 - val_auc: 0.8885 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0411 - auc: 0.8909 - val_loss: 0.0415 - val_auc: 0.8882 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0409 - auc: 0.8912 - val_loss: 0.0414 - val_auc: 0.8882 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0409 - auc: 0.8915 - val_loss: 0.0419 - val_auc: 0.8883 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0408 - auc: 0.8921 - val_loss: 0.0415 - val_auc: 0.8880 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0406 - auc: 0.8936 - val_loss: 0.0417 - val_auc: 0.8876 - lr: 6.2500e-04\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0405 - auc: 0.8935 - val_loss: 0.0420 - val_auc: 0.8874 - lr: 6.2500e-04\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0404 - auc: 0.8941 - val_loss: 0.0418 - val_auc: 0.8870 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0404 - auc: 0.8942 - val_loss: 0.0420 - val_auc: 0.8874 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0402 - auc: 0.8955 - val_loss: 0.0419 - val_auc: 0.8869 - lr: 3.1250e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0400 - auc: 0.8963 - val_loss: 0.0418 - val_auc: 0.8868 - lr: 3.1250e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0399 - auc: 0.8966 - val_loss: 0.0418 - val_auc: 0.8864 - lr: 3.1250e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 26s 31ms/step - loss: 0.0594 - auc: 0.8584 - val_loss: 0.0478 - val_auc: 0.8808 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0434 - auc: 0.8792 - val_loss: 0.0432 - val_auc: 0.8811 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0428 - auc: 0.8812 - val_loss: 0.0439 - val_auc: 0.8819 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0427 - auc: 0.8816 - val_loss: 0.0463 - val_auc: 0.8812 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0424 - auc: 0.8829 - val_loss: 0.0430 - val_auc: 0.8823 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0425 - auc: 0.8831 - val_loss: 0.0437 - val_auc: 0.8796 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0421 - auc: 0.8848 - val_loss: 0.0432 - val_auc: 0.8805 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0422 - auc: 0.8846 - val_loss: 0.0430 - val_auc: 0.8816 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0422 - auc: 0.8850 - val_loss: 0.0432 - val_auc: 0.8821 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0416 - auc: 0.8870 - val_loss: 0.0429 - val_auc: 0.8824 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0416 - auc: 0.8871 - val_loss: 0.0433 - val_auc: 0.8818 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0416 - auc: 0.8877 - val_loss: 0.0428 - val_auc: 0.8824 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0415 - auc: 0.8877 - val_loss: 0.0429 - val_auc: 0.8833 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0414 - auc: 0.8881 - val_loss: 0.0430 - val_auc: 0.8832 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0415 - auc: 0.8881 - val_loss: 0.0431 - val_auc: 0.8827 - lr: 0.0025\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0414 - auc: 0.8887 - val_loss: 0.0430 - val_auc: 0.8834 - lr: 0.0025\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0410 - auc: 0.8905 - val_loss: 0.0428 - val_auc: 0.8827 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0409 - auc: 0.8910 - val_loss: 0.0430 - val_auc: 0.8815 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0408 - auc: 0.8914 - val_loss: 0.0431 - val_auc: 0.8825 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0407 - auc: 0.8920 - val_loss: 0.0432 - val_auc: 0.8821 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0405 - auc: 0.8930 - val_loss: 0.0432 - val_auc: 0.8813 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0405 - auc: 0.8931 - val_loss: 0.0433 - val_auc: 0.8815 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0403 - auc: 0.8941 - val_loss: 0.0433 - val_auc: 0.8812 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0403 - auc: 0.8944 - val_loss: 0.0433 - val_auc: 0.8818 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0400 - auc: 0.8955 - val_loss: 0.0432 - val_auc: 0.8816 - lr: 3.1250e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0401 - auc: 0.8956 - val_loss: 0.0433 - val_auc: 0.8814 - lr: 3.1250e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0400 - auc: 0.8957 - val_loss: 0.0434 - val_auc: 0.8812 - lr: 3.1250e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0399 - auc: 0.8963 - val_loss: 0.0437 - val_auc: 0.8802 - lr: 3.1250e-04\n",
            "Epoch 29/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0397 - auc: 0.8974 - val_loss: 0.0436 - val_auc: 0.8809 - lr: 1.5625e-04\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 25s 30ms/step - loss: 0.0586 - auc: 0.8568 - val_loss: 0.0431 - val_auc: 0.8788 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0435 - auc: 0.8779 - val_loss: 0.0462 - val_auc: 0.8745 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0431 - auc: 0.8803 - val_loss: 0.0425 - val_auc: 0.8838 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0426 - auc: 0.8823 - val_loss: 0.0431 - val_auc: 0.8833 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0426 - auc: 0.8821 - val_loss: 0.0428 - val_auc: 0.8849 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0425 - auc: 0.8829 - val_loss: 0.0428 - val_auc: 0.8844 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0424 - auc: 0.8838 - val_loss: 0.0435 - val_auc: 0.8844 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0419 - auc: 0.8859 - val_loss: 0.0422 - val_auc: 0.8859 - lr: 0.0025\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0418 - auc: 0.8859 - val_loss: 0.0423 - val_auc: 0.8852 - lr: 0.0025\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0419 - auc: 0.8856 - val_loss: 0.0421 - val_auc: 0.8858 - lr: 0.0025\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0418 - auc: 0.8865 - val_loss: 0.0422 - val_auc: 0.8843 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0417 - auc: 0.8868 - val_loss: 0.0425 - val_auc: 0.8844 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0418 - auc: 0.8866 - val_loss: 0.0422 - val_auc: 0.8857 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0417 - auc: 0.8871 - val_loss: 0.0422 - val_auc: 0.8853 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0414 - auc: 0.8885 - val_loss: 0.0420 - val_auc: 0.8850 - lr: 0.0012\n",
            "Epoch 16/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0413 - auc: 0.8890 - val_loss: 0.0420 - val_auc: 0.8853 - lr: 0.0012\n",
            "Epoch 17/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0411 - auc: 0.8901 - val_loss: 0.0422 - val_auc: 0.8845 - lr: 0.0012\n",
            "Epoch 18/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0412 - auc: 0.8896 - val_loss: 0.0420 - val_auc: 0.8850 - lr: 0.0012\n",
            "Epoch 19/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0411 - auc: 0.8901 - val_loss: 0.0423 - val_auc: 0.8851 - lr: 0.0012\n",
            "Epoch 20/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0411 - auc: 0.8901 - val_loss: 0.0426 - val_auc: 0.8842 - lr: 0.0012\n",
            "Epoch 21/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0407 - auc: 0.8925 - val_loss: 0.0424 - val_auc: 0.8848 - lr: 6.2500e-04\n",
            "Epoch 22/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0406 - auc: 0.8927 - val_loss: 0.0424 - val_auc: 0.8846 - lr: 6.2500e-04\n",
            "Epoch 23/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0405 - auc: 0.8936 - val_loss: 0.0423 - val_auc: 0.8834 - lr: 6.2500e-04\n",
            "Epoch 24/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0405 - auc: 0.8937 - val_loss: 0.0423 - val_auc: 0.8833 - lr: 6.2500e-04\n",
            "Epoch 25/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0401 - auc: 0.8953 - val_loss: 0.0428 - val_auc: 0.8836 - lr: 3.1250e-04\n",
            "Epoch 26/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0400 - auc: 0.8961 - val_loss: 0.0428 - val_auc: 0.8828 - lr: 3.1250e-04\n",
            "Epoch 27/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0400 - auc: 0.8960 - val_loss: 0.0428 - val_auc: 0.8826 - lr: 3.1250e-04\n",
            "Epoch 28/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0400 - auc: 0.8959 - val_loss: 0.0428 - val_auc: 0.8821 - lr: 3.1250e-04\n",
            "[I 2024-01-29 17:27:42,888] Trial 6 finished with value: 0.886884245607588 and parameters: {'units_0': 768, 'activation': 'swish', 'dropout': 0.25, 'hidden_layers': 4, 'embedding_dims': 24}. Best is trial 2 with value: 0.8870233562257555.\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 26s 31ms/step - loss: 0.0538 - auc: 0.8526 - val_loss: 0.0440 - val_auc: 0.8788 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0446 - auc: 0.8731 - val_loss: 0.0454 - val_auc: 0.8821 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0438 - auc: 0.8764 - val_loss: 0.0429 - val_auc: 0.8808 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0431 - auc: 0.8800 - val_loss: 0.0429 - val_auc: 0.8829 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0428 - auc: 0.8809 - val_loss: 0.0431 - val_auc: 0.8834 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "343/344 [============================>.] - ETA: 0s - loss: 0.0427 - auc: 0.8814[I 2024-01-29 17:30:15,616] Trial 7 pruned. Trial was pruned at epoch 5.\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 26s 31ms/step - loss: 0.0462 - auc: 0.8646 - val_loss: 0.0441 - val_auc: 0.8811 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0431 - auc: 0.8791 - val_loss: 0.0426 - val_auc: 0.8829 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0429 - auc: 0.8805 - val_loss: 0.0430 - val_auc: 0.8828 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 11s 27ms/step - loss: 0.0425 - auc: 0.8822 - val_loss: 0.0428 - val_auc: 0.8822 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 10s 26ms/step - loss: 0.0424 - auc: 0.8828 - val_loss: 0.0427 - val_auc: 0.8837 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 11s 27ms/step - loss: 0.0424 - auc: 0.8828 - val_loss: 0.0425 - val_auc: 0.8832 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0422 - auc: 0.8837 - val_loss: 0.0426 - val_auc: 0.8840 - lr: 0.0050\n",
            "Epoch 8/60\n",
            "344/344 [==============================] - 9s 24ms/step - loss: 0.0421 - auc: 0.8845 - val_loss: 0.0426 - val_auc: 0.8833 - lr: 0.0050\n",
            "Epoch 9/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0421 - auc: 0.8845 - val_loss: 0.0426 - val_auc: 0.8842 - lr: 0.0050\n",
            "Epoch 10/60\n",
            "344/344 [==============================] - 10s 25ms/step - loss: 0.0420 - auc: 0.8848 - val_loss: 0.0430 - val_auc: 0.8849 - lr: 0.0050\n",
            "Epoch 11/60\n",
            "344/344 [==============================] - 11s 27ms/step - loss: 0.0417 - auc: 0.8866 - val_loss: 0.0423 - val_auc: 0.8850 - lr: 0.0025\n",
            "Epoch 12/60\n",
            "344/344 [==============================] - 11s 27ms/step - loss: 0.0417 - auc: 0.8867 - val_loss: 0.0422 - val_auc: 0.8853 - lr: 0.0025\n",
            "Epoch 13/60\n",
            "344/344 [==============================] - 11s 27ms/step - loss: 0.0417 - auc: 0.8867 - val_loss: 0.0423 - val_auc: 0.8848 - lr: 0.0025\n",
            "Epoch 14/60\n",
            "344/344 [==============================] - 11s 27ms/step - loss: 0.0417 - auc: 0.8869 - val_loss: 0.0425 - val_auc: 0.8841 - lr: 0.0025\n",
            "Epoch 15/60\n",
            "342/344 [============================>.] - ETA: 0s - loss: 0.0417 - auc: 0.8867[I 2024-01-29 17:34:26,246] Trial 8 pruned. Trial was pruned at epoch 14.\n",
            "Adapting Features Space....\n",
            "Epoch 1/60\n",
            "344/344 [==============================] - 24s 29ms/step - loss: 0.0544 - auc: 0.8575 - val_loss: 0.0466 - val_auc: 0.8796 - lr: 0.0050\n",
            "Epoch 2/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0441 - auc: 0.8749 - val_loss: 0.0434 - val_auc: 0.8793 - lr: 0.0050\n",
            "Epoch 3/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0436 - auc: 0.8774 - val_loss: 0.0449 - val_auc: 0.8827 - lr: 0.0050\n",
            "Epoch 4/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0431 - auc: 0.8795 - val_loss: 0.0433 - val_auc: 0.8821 - lr: 0.0050\n",
            "Epoch 5/60\n",
            "344/344 [==============================] - 9s 23ms/step - loss: 0.0429 - auc: 0.8804 - val_loss: 0.0433 - val_auc: 0.8816 - lr: 0.0050\n",
            "Epoch 6/60\n",
            "344/344 [==============================] - 10s 24ms/step - loss: 0.0426 - auc: 0.8817 - val_loss: 0.0433 - val_auc: 0.8805 - lr: 0.0050\n",
            "Epoch 7/60\n",
            "342/344 [============================>.] - ETA: 0s - loss: 0.0425 - auc: 0.8824[I 2024-01-29 17:37:02,643] Trial 9 pruned. Trial was pruned at epoch 6.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'units_0': 704, 'activation': 'swish', 'dropout': 0.36962894665903023, 'hidden_layers': 3, 'num_dense_exp': True}. Best is trial 15 with value: 0.8874946766429477.\n",
        "\n",
        "{'units_0': 320, 'activation': 'gelu', 'dropout': 0.323414848307589, 'hidden_layers': 2} trial 2 with value: 0.8871975276205275.\n",
        "\n",
        "AUC: 0.8870259126027426\n",
        "Best hyperparameters: {'units_0': 768, 'activation': 'swish', 'dropout': 0.2551166017702234, 'hidden_layers': 3}\n",
        "\n",
        "{'units_0': 1024, 'activation': 'swish', 'dropout': 0.5, 'hidden_layers': 2, 'embedding_dims': 32}. Best is trial 2 with value: 0.8870233562257555."
      ],
      "metadata": {
        "id": "uh2Uwmvz6BMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trial = study.best_trial\n",
        "print('AUC: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ],
      "metadata": {
        "id": "v4MNIdONy-kG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "274e4f3d-184b-421a-8c13-c25ed53e6e43"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.8870233562257555\n",
            "Best hyperparameters: {'units_0': 1024, 'activation': 'swish', 'dropout': 0.5, 'hidden_layers': 2, 'embedding_dims': 32}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = optuna.visualization.plot_optimization_history(study)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ZrIgmwBszEJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DI-KYWSB5nHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZwMcxQYSoFC"
      },
      "source": [
        "### 4.3 Fit the Model - No OverSampling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neg, pos = np.bincount(X['Exited'])\n",
        "Best_Model={'units_0': 704, 'activation': 'swish', 'dropout': 0.37, 'hidden_layers': 3}\n",
        "\n",
        "initial_bias = np.log([pos/neg])\n",
        "initial_bias"
      ],
      "metadata": {
        "id": "uFnnfDuqgEM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "068f5e2b-832a-47e2-ff55-ab6dd1ffe37d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.31531494])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-IKVWWNSoFC"
      },
      "outputs": [],
      "source": [
        "def run_experiment(train, test_data, input_format=\"dict\", experiment_name=\"model_baseline\", splits=5, num_epochs=300, batch_size=32, n_repeats=8, rs=42, param=Best_Model, biases=initial_bias):\n",
        "\n",
        "  skf = RepeatedStratifiedKFold(n_splits=splits, n_repeats=n_repeats, random_state=rs)\n",
        "\n",
        "  test_results_df_all = pd.DataFrame(index=test_data.index, columns=list(range(splits*n_repeats)))\n",
        "\n",
        "  test_results_df = pd.DataFrame(index=test_data.index, columns=[\"Exited\"])\n",
        "\n",
        "  all_logloss = []\n",
        "  all_AUC_roc = []\n",
        "\n",
        "\n",
        "  for i, (train_index, valid_index) in enumerate(skf.split(X,X[\"Exited\"])):\n",
        "\n",
        "    print(f\"\\nRunning CV {i}\\n\")\n",
        "    ########################################################################## Prepare the Dataset:\n",
        "    X_trn = train.iloc[train_index,:]\n",
        "    X_val = train.iloc[valid_index,:]\n",
        "\n",
        "    train_dataset_ = dataframe_to_dataset(X_trn, batch_size=256, shuffle=True)\n",
        "    valid_dataset_ = dataframe_to_dataset(X_val, batch_size=256, shuffle=False)\n",
        "    test_dataset_ = dataframe_to_dataset(test_data, batch_size=256, shuffle=False)\n",
        "\n",
        "    feature_space = FeatureSpace(\n",
        "                                features={**{a:FeatureSpace.integer_categorical(num_oov_indices=0, output_mode=\"int\") for a in cat_var},**{b:FeatureSpace.float() for b in num_var}},\n",
        "                                output_mode=input_format\n",
        "                                )\n",
        "\n",
        "    train_ds_with_no_labels = train_dataset_.map(lambda x, *_: x)\n",
        "    print(\"Adapting Features Space....\")\n",
        "    feature_space.adapt(train_ds_with_no_labels)\n",
        "\n",
        "    preprocessed_train_ds = train_dataset_.map(lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "    preprocessed_valid_ds = valid_dataset_.map(lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "    preprocessed_test_ds = test_dataset_.map(lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    # Callbacks:\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\",\n",
        "                                                      patience=30,\n",
        "                                                      restore_best_weights=True,\n",
        "                                                      start_from_epoch=5,\n",
        "                                                      verbose=1,\n",
        "                                                      mode='max')\n",
        "\n",
        "    reduce_on_plat = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_auc',\n",
        "                                                          factor=0.5,\n",
        "                                                          patience=5,\n",
        "                                                          mode=\"max\",\n",
        "                                                          min_lr=0.000005)\n",
        "\n",
        "    checkpoint_filepath = folders_nn + 'checkpoint/'\n",
        "    Checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                                    save_weights_only=True,\n",
        "                                                    monitor=\"val_auc\",\n",
        "                                                    mode='max',\n",
        "                                                    restore_best_weights=True,\n",
        "                                                    start_from_epoch=5,\n",
        "                                                    save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "    # Generate Model\n",
        "    model = create_baseline_model(feature_space,\n",
        "                                  name=experiment_name,\n",
        "                                  learning_rate = 0.001,\n",
        "                                  kr=0,\n",
        "                                  num_dense_exp=True,\n",
        "                                  output_bias=initial_bias,\n",
        "                                  **Best_Model)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"Start training the model...\")\n",
        "    history = model.fit(preprocessed_train_ds,\n",
        "                        epochs=num_epochs,\n",
        "                        callbacks=[early_stopping,Checkpoint,reduce_on_plat],\n",
        "                        validation_data=preprocessed_valid_ds)\n",
        "\n",
        "    print(\"Model training finished\")\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    log_loss, AUC_roc = model.evaluate(preprocessed_valid_ds, verbose=0)\n",
        "\n",
        "\n",
        "    plot_training_session(history)\n",
        "\n",
        "    y_hat = model.predict(preprocessed_test_ds)\n",
        "    y_hat_valid = model.predict(preprocessed_valid_ds)\n",
        "\n",
        "    target = X_val[\"Exited\"]\n",
        "    print(y_hat_valid.shape,target.shape)\n",
        "    eval = [0 if yp<0.5 else 1 for yp in y_hat_valid]\n",
        "    plot_confusion_matrix(target, eval, labels=[0,1])\n",
        "\n",
        "    print(\"\\n\",classification_report(y_true=target, y_pred=eval))\n",
        "    print(f\"y_hat shape:{y_hat.shape}\")\n",
        "\n",
        "    test_results_df_all.iloc[:,i] = y_hat\n",
        "\n",
        "    model.save(f'{folders_nn+experiment_name}/CV_{i}')\n",
        "    feature_space.save(f\"{folders_nn+experiment_name}/CV_{i}/myfeaturespace_{experiment_name}.keras\")\n",
        "\n",
        "\n",
        "    print(f\"AUC-Roc Score: {round(AUC_roc, 3)}%\")\n",
        "    all_logloss.append(round(log_loss, 3))\n",
        "    all_AUC_roc.append(round(AUC_roc, 3))\n",
        "\n",
        "    del feature_space\n",
        "    del model\n",
        "    del preprocessed_train_ds\n",
        "    del preprocessed_valid_ds\n",
        "    del preprocessed_test_ds\n",
        "    gc.collect()\n",
        "\n",
        "  test_results_df_all[\"Mean\"] = test_results_df_all.mean(axis=1)\n",
        "\n",
        "  test_results_df[\"Exited\"] = test_results_df_all[\"Mean\"].values\n",
        "\n",
        "  print(f\"All Valuation AUC_pr: {all_AUC_roc}\")\n",
        "\n",
        "  return test_results_df_all, test_results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsiWhf1NSoFD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f3247ea-9b8d-44a0-fc97-56884163042a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running CV 0\n",
            "\n",
            "Adapting Features Space....\n",
            "Start training the model...\n",
            "Epoch 1/200\n",
            "516/516 [==============================] - 31s 28ms/step - loss: 0.0520 - auc: 0.8475 - val_loss: 0.0427 - val_auc: 0.8827 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "516/516 [==============================] - 14s 23ms/step - loss: 0.0438 - auc: 0.8766 - val_loss: 0.0422 - val_auc: 0.8835 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "516/516 [==============================] - 14s 23ms/step - loss: 0.0432 - auc: 0.8793 - val_loss: 0.0421 - val_auc: 0.8859 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "516/516 [==============================] - 14s 23ms/step - loss: 0.0428 - auc: 0.8811 - val_loss: 0.0421 - val_auc: 0.8864 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "516/516 [==============================] - 14s 23ms/step - loss: 0.0429 - auc: 0.8815 - val_loss: 0.0420 - val_auc: 0.8876 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0426 - auc: 0.8828 - val_loss: 0.0418 - val_auc: 0.8872 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "516/516 [==============================] - 14s 23ms/step - loss: 0.0425 - auc: 0.8830 - val_loss: 0.0421 - val_auc: 0.8861 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "516/516 [==============================] - 14s 23ms/step - loss: 0.0424 - auc: 0.8838 - val_loss: 0.0426 - val_auc: 0.8878 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "516/516 [==============================] - 14s 23ms/step - loss: 0.0423 - auc: 0.8838 - val_loss: 0.0417 - val_auc: 0.8881 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "516/516 [==============================] - 14s 23ms/step - loss: 0.0421 - auc: 0.8850 - val_loss: 0.0417 - val_auc: 0.8880 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "516/516 [==============================] - 14s 23ms/step - loss: 0.0421 - auc: 0.8850 - val_loss: 0.0415 - val_auc: 0.8883 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0420 - auc: 0.8855 - val_loss: 0.0416 - val_auc: 0.8879 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "516/516 [==============================] - 14s 23ms/step - loss: 0.0419 - auc: 0.8859 - val_loss: 0.0414 - val_auc: 0.8886 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0420 - auc: 0.8860 - val_loss: 0.0415 - val_auc: 0.8883 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "516/516 [==============================] - 13s 22ms/step - loss: 0.0418 - auc: 0.8863 - val_loss: 0.0416 - val_auc: 0.8880 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "516/516 [==============================] - 14s 23ms/step - loss: 0.0419 - auc: 0.8862 - val_loss: 0.0415 - val_auc: 0.8879 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "516/516 [==============================] - 14s 23ms/step - loss: 0.0418 - auc: 0.8868 - val_loss: 0.0426 - val_auc: 0.8888 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "516/516 [==============================] - 14s 23ms/step - loss: 0.0417 - auc: 0.8871 - val_loss: 0.0415 - val_auc: 0.8887 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "516/516 [==============================] - 13s 21ms/step - loss: 0.0418 - auc: 0.8870 - val_loss: 0.0416 - val_auc: 0.8876 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0416 - auc: 0.8879 - val_loss: 0.0414 - val_auc: 0.8882 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "516/516 [==============================] - 14s 23ms/step - loss: 0.0416 - auc: 0.8877 - val_loss: 0.0422 - val_auc: 0.8878 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "516/516 [==============================] - 15s 24ms/step - loss: 0.0416 - auc: 0.8877 - val_loss: 0.0414 - val_auc: 0.8886 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "516/516 [==============================] - 15s 24ms/step - loss: 0.0412 - auc: 0.8894 - val_loss: 0.0413 - val_auc: 0.8889 - lr: 5.0000e-04\n",
            "Epoch 24/200\n",
            "516/516 [==============================] - 16s 25ms/step - loss: 0.0413 - auc: 0.8894 - val_loss: 0.0413 - val_auc: 0.8889 - lr: 5.0000e-04\n",
            "Epoch 25/200\n",
            "516/516 [==============================] - 14s 23ms/step - loss: 0.0412 - auc: 0.8898 - val_loss: 0.0413 - val_auc: 0.8889 - lr: 5.0000e-04\n",
            "Epoch 26/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0411 - auc: 0.8901 - val_loss: 0.0413 - val_auc: 0.8887 - lr: 5.0000e-04\n",
            "Epoch 27/200\n",
            "516/516 [==============================] - 15s 24ms/step - loss: 0.0410 - auc: 0.8906 - val_loss: 0.0413 - val_auc: 0.8889 - lr: 5.0000e-04\n",
            "Epoch 28/200\n",
            "516/516 [==============================] - 14s 23ms/step - loss: 0.0411 - auc: 0.8901 - val_loss: 0.0412 - val_auc: 0.8893 - lr: 5.0000e-04\n",
            "Epoch 29/200\n",
            "516/516 [==============================] - 14s 23ms/step - loss: 0.0411 - auc: 0.8907 - val_loss: 0.0413 - val_auc: 0.8890 - lr: 5.0000e-04\n",
            "Epoch 30/200\n",
            "516/516 [==============================] - 14s 23ms/step - loss: 0.0411 - auc: 0.8905 - val_loss: 0.0416 - val_auc: 0.8889 - lr: 5.0000e-04\n",
            "Epoch 31/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0410 - auc: 0.8911 - val_loss: 0.0413 - val_auc: 0.8885 - lr: 5.0000e-04\n",
            "Epoch 32/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0410 - auc: 0.8911 - val_loss: 0.0413 - val_auc: 0.8888 - lr: 5.0000e-04\n",
            "Epoch 33/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0409 - auc: 0.8912 - val_loss: 0.0413 - val_auc: 0.8887 - lr: 5.0000e-04\n",
            "Epoch 34/200\n",
            "516/516 [==============================] - 13s 22ms/step - loss: 0.0408 - auc: 0.8920 - val_loss: 0.0413 - val_auc: 0.8885 - lr: 2.5000e-04\n",
            "Epoch 35/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0407 - auc: 0.8922 - val_loss: 0.0413 - val_auc: 0.8890 - lr: 2.5000e-04\n",
            "Epoch 36/200\n",
            "516/516 [==============================] - 13s 22ms/step - loss: 0.0407 - auc: 0.8928 - val_loss: 0.0413 - val_auc: 0.8887 - lr: 2.5000e-04\n",
            "Epoch 37/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0407 - auc: 0.8927 - val_loss: 0.0413 - val_auc: 0.8885 - lr: 2.5000e-04\n",
            "Epoch 38/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0406 - auc: 0.8931 - val_loss: 0.0413 - val_auc: 0.8886 - lr: 2.5000e-04\n",
            "Epoch 39/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0405 - auc: 0.8935 - val_loss: 0.0413 - val_auc: 0.8886 - lr: 1.2500e-04\n",
            "Epoch 40/200\n",
            "516/516 [==============================] - 13s 22ms/step - loss: 0.0405 - auc: 0.8937 - val_loss: 0.0413 - val_auc: 0.8887 - lr: 1.2500e-04\n",
            "Epoch 41/200\n",
            "516/516 [==============================] - 13s 22ms/step - loss: 0.0405 - auc: 0.8937 - val_loss: 0.0414 - val_auc: 0.8885 - lr: 1.2500e-04\n",
            "Epoch 42/200\n",
            "516/516 [==============================] - 13s 22ms/step - loss: 0.0404 - auc: 0.8938 - val_loss: 0.0414 - val_auc: 0.8883 - lr: 1.2500e-04\n",
            "Epoch 43/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0405 - auc: 0.8937 - val_loss: 0.0414 - val_auc: 0.8886 - lr: 1.2500e-04\n",
            "Epoch 44/200\n",
            "516/516 [==============================] - 13s 22ms/step - loss: 0.0404 - auc: 0.8944 - val_loss: 0.0414 - val_auc: 0.8885 - lr: 6.2500e-05\n",
            "Epoch 45/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0403 - auc: 0.8943 - val_loss: 0.0414 - val_auc: 0.8885 - lr: 6.2500e-05\n",
            "Epoch 46/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0404 - auc: 0.8939 - val_loss: 0.0414 - val_auc: 0.8883 - lr: 6.2500e-05\n",
            "Epoch 47/200\n",
            "516/516 [==============================] - 14s 23ms/step - loss: 0.0403 - auc: 0.8945 - val_loss: 0.0414 - val_auc: 0.8885 - lr: 6.2500e-05\n",
            "Epoch 48/200\n",
            "516/516 [==============================] - 13s 22ms/step - loss: 0.0404 - auc: 0.8943 - val_loss: 0.0414 - val_auc: 0.8882 - lr: 6.2500e-05\n",
            "Epoch 49/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0404 - auc: 0.8944 - val_loss: 0.0414 - val_auc: 0.8883 - lr: 3.1250e-05\n",
            "Epoch 50/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0402 - auc: 0.8950 - val_loss: 0.0414 - val_auc: 0.8882 - lr: 3.1250e-05\n",
            "Epoch 51/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0403 - auc: 0.8944 - val_loss: 0.0414 - val_auc: 0.8883 - lr: 3.1250e-05\n",
            "Epoch 52/200\n",
            "516/516 [==============================] - 13s 21ms/step - loss: 0.0403 - auc: 0.8946 - val_loss: 0.0414 - val_auc: 0.8883 - lr: 3.1250e-05\n",
            "Epoch 53/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0403 - auc: 0.8945 - val_loss: 0.0414 - val_auc: 0.8882 - lr: 3.1250e-05\n",
            "Epoch 54/200\n",
            "516/516 [==============================] - 13s 22ms/step - loss: 0.0402 - auc: 0.8948 - val_loss: 0.0414 - val_auc: 0.8882 - lr: 1.5625e-05\n",
            "Epoch 55/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0402 - auc: 0.8951 - val_loss: 0.0414 - val_auc: 0.8882 - lr: 1.5625e-05\n",
            "Epoch 56/200\n",
            "516/516 [==============================] - 13s 22ms/step - loss: 0.0403 - auc: 0.8948 - val_loss: 0.0414 - val_auc: 0.8882 - lr: 1.5625e-05\n",
            "Epoch 57/200\n",
            "516/516 [==============================] - 13s 21ms/step - loss: 0.0403 - auc: 0.8948 - val_loss: 0.0414 - val_auc: 0.8882 - lr: 1.5625e-05\n",
            "Epoch 58/200\n",
            "516/516 [==============================] - 13s 21ms/step - loss: 0.0403 - auc: 0.8944 - val_loss: 0.0414 - val_auc: 0.8882 - lr: 1.5625e-05\n",
            "Epoch 59/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0403 - auc: 0.8949 - val_loss: 0.0414 - val_auc: 0.8882 - lr: 7.8125e-06\n",
            "Epoch 60/200\n",
            "516/516 [==============================] - 13s 21ms/step - loss: 0.0402 - auc: 0.8949 - val_loss: 0.0414 - val_auc: 0.8882 - lr: 7.8125e-06\n",
            "Epoch 61/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0403 - auc: 0.8947 - val_loss: 0.0414 - val_auc: 0.8882 - lr: 7.8125e-06\n",
            "Epoch 62/200\n",
            "516/516 [==============================] - 13s 21ms/step - loss: 0.0402 - auc: 0.8951 - val_loss: 0.0414 - val_auc: 0.8883 - lr: 7.8125e-06\n",
            "Epoch 63/200\n",
            "514/516 [============================>.] - ETA: 0s - loss: 0.0403 - auc: 0.8948Restoring model weights from the end of the best epoch: 28.\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0403 - auc: 0.8947 - val_loss: 0.0414 - val_auc: 0.8882 - lr: 7.8125e-06\n",
            "Epoch 63: early stopping\n",
            "Model training finished\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "430/430 [==============================] - 4s 6ms/step\n",
            "129/129 [==============================] - 2s 6ms/step\n",
            "(33007, 1) (33007,)\n",
            "Column sum of precision matrix: [1. 1.]\n",
            "Row sum of recall matrix:       [1. 1.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90     26023\n",
            "           1       0.63      0.69      0.66      6984\n",
            "\n",
            "    accuracy                           0.85     33007\n",
            "   macro avg       0.77      0.79      0.78     33007\n",
            "weighted avg       0.85      0.85      0.85     33007\n",
            "\n",
            "y_hat shape:(110023, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.dense.Dense object at 0x7e4c0c352e00>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.dense.Dense object at 0x7e4c0c341b70>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7e4c0c3401f0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.merging.add.Add object at 0x7e4c0c3407f0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.dense.Dense object at 0x7e4c0c351630>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.dense.Dense object at 0x7e4c0c38a6e0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7e4c0c38b550>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.merging.add.Add object at 0x7e4c0c38bb50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.dense.Dense object at 0x7e4c0c3b43a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.dense.Dense object at 0x7e4c0c3b4a90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7e4c0c3b61d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.merging.add.Add object at 0x7e4c0c3b68f0>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-Roc Score: 0.889%\n",
            "\n",
            "Running CV 1\n",
            "\n",
            "Adapting Features Space....\n",
            "Start training the model...\n",
            "Epoch 1/200\n",
            "516/516 [==============================] - 27s 24ms/step - loss: 0.0520 - auc: 0.8468 - val_loss: 0.0432 - val_auc: 0.8818 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "516/516 [==============================] - 15s 24ms/step - loss: 0.0438 - auc: 0.8761 - val_loss: 0.0433 - val_auc: 0.8849 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0434 - auc: 0.8786 - val_loss: 0.0423 - val_auc: 0.8856 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "516/516 [==============================] - 13s 21ms/step - loss: 0.0429 - auc: 0.8807 - val_loss: 0.0418 - val_auc: 0.8867 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "516/516 [==============================] - 14s 21ms/step - loss: 0.0427 - auc: 0.8815 - val_loss: 0.0424 - val_auc: 0.8865 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "516/516 [==============================] - 13s 21ms/step - loss: 0.0426 - auc: 0.8824 - val_loss: 0.0421 - val_auc: 0.8854 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "516/516 [==============================] - 13s 21ms/step - loss: 0.0425 - auc: 0.8830 - val_loss: 0.0415 - val_auc: 0.8877 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "516/516 [==============================] - 13s 22ms/step - loss: 0.0424 - auc: 0.8835 - val_loss: 0.0421 - val_auc: 0.8866 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "516/516 [==============================] - 13s 22ms/step - loss: 0.0423 - auc: 0.8838 - val_loss: 0.0423 - val_auc: 0.8871 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "516/516 [==============================] - 13s 22ms/step - loss: 0.0422 - auc: 0.8848 - val_loss: 0.0423 - val_auc: 0.8879 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "516/516 [==============================] - 13s 21ms/step - loss: 0.0423 - auc: 0.8840 - val_loss: 0.0417 - val_auc: 0.8877 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "516/516 [==============================] - 13s 22ms/step - loss: 0.0420 - auc: 0.8856 - val_loss: 0.0415 - val_auc: 0.8879 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "516/516 [==============================] - 13s 21ms/step - loss: 0.0419 - auc: 0.8859 - val_loss: 0.0417 - val_auc: 0.8874 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "516/516 [==============================] - 13s 21ms/step - loss: 0.0419 - auc: 0.8860 - val_loss: 0.0416 - val_auc: 0.8873 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "516/516 [==============================] - 13s 21ms/step - loss: 0.0419 - auc: 0.8861 - val_loss: 0.0417 - val_auc: 0.8875 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "516/516 [==============================] - 13s 22ms/step - loss: 0.0416 - auc: 0.8877 - val_loss: 0.0415 - val_auc: 0.8880 - lr: 5.0000e-04\n",
            "Epoch 17/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0415 - auc: 0.8882 - val_loss: 0.0416 - val_auc: 0.8876 - lr: 5.0000e-04\n",
            "Epoch 18/200\n",
            "516/516 [==============================] - 13s 22ms/step - loss: 0.0414 - auc: 0.8883 - val_loss: 0.0415 - val_auc: 0.8882 - lr: 5.0000e-04\n",
            "Epoch 19/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0414 - auc: 0.8885 - val_loss: 0.0414 - val_auc: 0.8883 - lr: 5.0000e-04\n",
            "Epoch 20/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0414 - auc: 0.8886 - val_loss: 0.0415 - val_auc: 0.8883 - lr: 5.0000e-04\n",
            "Epoch 21/200\n",
            "516/516 [==============================] - 14s 21ms/step - loss: 0.0413 - auc: 0.8891 - val_loss: 0.0415 - val_auc: 0.8881 - lr: 5.0000e-04\n",
            "Epoch 22/200\n",
            "516/516 [==============================] - 12s 20ms/step - loss: 0.0414 - auc: 0.8887 - val_loss: 0.0415 - val_auc: 0.8880 - lr: 5.0000e-04\n",
            "Epoch 23/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0413 - auc: 0.8894 - val_loss: 0.0415 - val_auc: 0.8880 - lr: 5.0000e-04\n",
            "Epoch 24/200\n",
            "516/516 [==============================] - 13s 21ms/step - loss: 0.0413 - auc: 0.8893 - val_loss: 0.0416 - val_auc: 0.8879 - lr: 5.0000e-04\n",
            "Epoch 25/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0412 - auc: 0.8897 - val_loss: 0.0415 - val_auc: 0.8881 - lr: 5.0000e-04\n",
            "Epoch 26/200\n",
            "516/516 [==============================] - 13s 21ms/step - loss: 0.0411 - auc: 0.8905 - val_loss: 0.0415 - val_auc: 0.8883 - lr: 2.5000e-04\n",
            "Epoch 27/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0411 - auc: 0.8905 - val_loss: 0.0414 - val_auc: 0.8881 - lr: 2.5000e-04\n",
            "Epoch 28/200\n",
            "516/516 [==============================] - 13s 20ms/step - loss: 0.0410 - auc: 0.8908 - val_loss: 0.0415 - val_auc: 0.8880 - lr: 2.5000e-04\n",
            "Epoch 29/200\n",
            "516/516 [==============================] - 13s 21ms/step - loss: 0.0410 - auc: 0.8909 - val_loss: 0.0415 - val_auc: 0.8880 - lr: 2.5000e-04\n",
            "Epoch 30/200\n",
            "516/516 [==============================] - 13s 21ms/step - loss: 0.0410 - auc: 0.8909 - val_loss: 0.0414 - val_auc: 0.8880 - lr: 2.5000e-04\n",
            "Epoch 31/200\n",
            "516/516 [==============================] - 13s 21ms/step - loss: 0.0408 - auc: 0.8921 - val_loss: 0.0415 - val_auc: 0.8877 - lr: 1.2500e-04\n",
            "Epoch 32/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0408 - auc: 0.8919 - val_loss: 0.0415 - val_auc: 0.8879 - lr: 1.2500e-04\n",
            "Epoch 33/200\n",
            "516/516 [==============================] - 14s 22ms/step - loss: 0.0407 - auc: 0.8921 - val_loss: 0.0414 - val_auc: 0.8879 - lr: 1.2500e-04\n",
            "Epoch 34/200\n",
            "516/516 [==============================] - 14s 21ms/step - loss: 0.0408 - auc: 0.8919 - val_loss: 0.0415 - val_auc: 0.8878 - lr: 1.2500e-04\n",
            "Epoch 35/200\n",
            " 97/516 [====>.........................] - ETA: 8s - loss: 0.0407 - auc: 0.8931"
          ]
        }
      ],
      "source": [
        "test_results_df_all, test_results_df = run_experiment(X,\n",
        "                                                      X_test,\n",
        "                                                      input_format=\"dict\",\n",
        "                                                      experiment_name=\"model_baseline_v0\",\n",
        "                                                      splits=5,\n",
        "                                                      n_repeats=5,\n",
        "                                                      num_epochs=200,\n",
        "                                                      batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpKtyMiAnkk4"
      },
      "source": [
        "### 4.4 Store Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiekBrA3nkk4"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Connect to Colab:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKuejDWqnkk4",
        "outputId": "939d3891-1cfd-44e7-f5d0-9a040dd2f311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S4E1_BankChurn already exists\n",
            "/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S4E1_BankChurn already exists\n",
            "/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S4E1_BankChurn/neural_networks/ already exists\n",
            "/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S4E1_BankChurn/trees_models/ already exists\n"
          ]
        }
      ],
      "source": [
        "folder_data = \"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Data/S4E1_BankChurn\"\n",
        "models_folders = \"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S4E1_BankChurn\"\n",
        "folders_nn = \"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S4E1_BankChurn/neural_networks/\"\n",
        "folders_trees = \"/content/drive/MyDrive/Exercises/Studies_Structured_Data/Models/S4E1_BankChurn/trees_models/\"\n",
        "\n",
        "list_directories = [folder_data,models_folders,folders_nn,folders_trees]\n",
        "\n",
        "for path in list_directories:\n",
        "  try:\n",
        "      os.mkdir(path)\n",
        "  except OSError as error:\n",
        "      print(f\"{path} already exists\")\n",
        "\n",
        "\n",
        "os.chdir(folder_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "GOiNDp1jnkk5",
        "outputId": "9853e659-0f05-449d-e4c0-43097e8df456"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fd4fbcb4-2400-4e4a-9cf7-6759b21f7de4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>165034</th>\n",
              "      <td>0.057956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165035</th>\n",
              "      <td>0.940149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165036</th>\n",
              "      <td>0.087481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165037</th>\n",
              "      <td>0.547713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165038</th>\n",
              "      <td>0.718544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275052</th>\n",
              "      <td>0.110747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275053</th>\n",
              "      <td>0.437689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275054</th>\n",
              "      <td>0.033856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275055</th>\n",
              "      <td>0.423020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275056</th>\n",
              "      <td>0.418291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>110023 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd4fbcb4-2400-4e4a-9cf7-6759b21f7de4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fd4fbcb4-2400-4e4a-9cf7-6759b21f7de4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fd4fbcb4-2400-4e4a-9cf7-6759b21f7de4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-46413aa3-d736-4ec8-9bac-8b59142ed567\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-46413aa3-d736-4ec8-9bac-8b59142ed567')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-46413aa3-d736-4ec8-9bac-8b59142ed567 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          Exited\n",
              "id              \n",
              "165034  0.057956\n",
              "165035  0.940149\n",
              "165036  0.087481\n",
              "165037  0.547713\n",
              "165038  0.718544\n",
              "...          ...\n",
              "275052  0.110747\n",
              "275053  0.437689\n",
              "275054  0.033856\n",
              "275055  0.423020\n",
              "275056  0.418291\n",
              "\n",
              "[110023 rows x 1 columns]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "experiment_name=\"model_cb_v0_new_ds\"\n",
        "\n",
        "sub = pd.read_csv(\"sample_submission.csv\", index_col=0)\n",
        "sub.iloc[:,:] = test_results_df.values\n",
        "sub.to_csv(f\"Results/{experiment_name}.csv\")\n",
        "sub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "n-pbpz5Unkk5",
        "outputId": "c1153284-ec9d-4705-c991-f27294734b65"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6d62febc-db4f-4671-82a9-541967487b94\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>165430</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165722</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165984</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166638</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167218</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272929</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273022</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273075</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273651</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274186</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>398 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d62febc-db4f-4671-82a9-541967487b94')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d62febc-db4f-4671-82a9-541967487b94 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d62febc-db4f-4671-82a9-541967487b94');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-81e1fdb9-73b6-4f00-8217-e88fe2fd177d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-81e1fdb9-73b6-4f00-8217-e88fe2fd177d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-81e1fdb9-73b6-4f00-8217-e88fe2fd177d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        Exited\n",
              "id            \n",
              "165430     1.0\n",
              "165722     0.0\n",
              "165984     1.0\n",
              "166638     0.0\n",
              "167218     0.0\n",
              "...        ...\n",
              "272929     1.0\n",
              "273022     1.0\n",
              "273075     1.0\n",
              "273651     1.0\n",
              "274186     1.0\n",
              "\n",
              "[398 rows x 1 columns]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub.loc[duplicate_results_test_df.index,:] = duplicate_results_test_df.values\n",
        "sub.loc[duplicate_results_test_df.index,:]\n",
        "\n",
        "sub.to_csv(f\"Results/{experiment_name}_with_replacement.csv\")\n",
        "\n",
        "sub.loc[duplicate_results_test_df.index,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEuDC0aQnkk5"
      },
      "outputs": [],
      "source": [
        "train_results = pd.DataFrame(data=oof_results, columns=list(range(25)))\n",
        "train_results[\"mean\"] = train_results.mean(axis=1)\n",
        "train_results_ = train_results[[\"mean\"]]\n",
        "\n",
        "#plt.scatter(train_results[1],train_results[12])\n",
        "#train_results_.plot()\n",
        "train_results_.to_csv((f\"Results_oof/{experiment_name}_with_replacement_train.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_RIQgZyTiRCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K-5hmQmpiQ_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  x = tf.keras.layers.Dense(units_0, activation=activation, name=\"dense_in\")(encoded_features_conc)\n",
        "  x = tf.keras.layers.BatchNormalization(name=\"bn_in\")(x)\n",
        "  x = tf.keras.layers.Dropout(dropout,name=\"do_in\")(x)\n",
        "\n",
        "  x = tf.keras.layers.GaussianNoise(stddev=gn_noise, name=\"gsn\")(x)\n",
        "\n",
        "  for lr in range(hidden_layers):\n",
        "    x = tf.keras.layers.Dense(units_1, activation=activation, name=f\"dense_{lr}\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization(name=f\"bn_{lr}\")(x)\n",
        "    x = tf.keras.layers.Dropout(dropout,name=f\"do_{lr}\")(x)\n",
        "\n",
        "  output = tf.keras.layers.Dense(3, activation=\"softmax\",name=\"output_final\")(x)"
      ],
      "metadata": {
        "id": "p0T-xW4eQBhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "i8V7BoOyT2QN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}