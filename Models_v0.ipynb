{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNPiKA/w1lJgmdtO017CRqJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabriziobasso/kaggle/blob/main/Models_v0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUj4u-dLqBm8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cleRFSI670J6"
      },
      "source": [
        "# **S4E1 BANK CHURN**\n",
        "\n",
        "##### About Dataset\n",
        "The bank customer churn dataset is a commonly used dataset for predicting customer churn in the banking industry. It contains information on bank customers who either left the bank or continue to be a customer. The dataset includes the following attributes:\n",
        "\n",
        "* Customer ID: A unique identifier for each customer\n",
        "* Surname: The customer's surname or last name\n",
        "* Credit Score: A numerical value representing the customer's credit score\n",
        "* Geography: The country where the customer resides (France, Spain or Germany)\n",
        "* Gender: The customer's gender (Male or Female)\n",
        "* Age: The customer's age.\n",
        "* Tenure: The number of years the customer has been with the bank\n",
        "* Balance: The customer's account balance\n",
        "* NumOfProducts: The number of bank products the customer uses (e.g., savings account, credit card)\n",
        "* HasCrCard: Whether the customer has a credit card (1 = yes, 0 = no)\n",
        "* IsActiveMember: Whether the customer is an active member (1 = yes, 0 = no)\n",
        "* EstimatedSalary: The estimated salary of the customer\n",
        "* Exited: Whether the customer has churned (1 = yes, 0 = no)\n",
        "\n",
        "##### Evaluation\n",
        "Submissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\n",
        "\n",
        "\n",
        "The submitted probabilities for a given row are not required to sum to one because they are rescaled prior to being scored (each row is divided by the row sum). In order to avoid the extremes of the log function, predicted probabilities are replaced with\n",
        ".\n",
        "\n",
        "#### **Files:**\n",
        "* train.csv - the training dataset; Hardness is the continuous target\n",
        "* test.csv - the test dataset; your objective is to predict the value of Hardness\n",
        "* sample_submission.csv - a sample submission file in the correct format\n",
        "* Churn_Modelling.csv - Original Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_tuNI_58oDU"
      },
      "source": [
        "## 1.0 Workbook Set-up and Libraries:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiXajJZIpDRW"
      },
      "source": [
        "#### 1.0 Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dbXrH095unC"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install tensorflow-addons\n",
        "#!pip install shap\n",
        "#!pip install eli5\n",
        "#!pip install tf-nightly\n",
        "#!pip install -U scikit-learn==1.2.0\n",
        "!pip install catboost\n",
        "#!pip install haversine\n",
        "#!pip install pytorch-forecasting\n",
        "!pip install umap-learn\n",
        "#!pip install reverse_geocoder\n",
        "#!pip install --upgrade protobuf\n",
        "!pip install colorama\n",
        "!pip install imbalanced-learn\n",
        "!pip install optuna\n",
        "!pip install optuna-integration\n",
        "#!pip install pygam\n",
        "!pip install keras-tuner --upgrade\n",
        "#!pip install pycaret\n",
        "#!pip install lightning==2.0.1\n",
        "!pip install keras-nlp\n",
        "#!pip install MiniSom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "81y_MZuE8zTt",
        "outputId": "b6ccf5f5-2fff-4774-c4e7-08f86c6ed436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importing started...\n",
            "Using TensorFlow backend\n",
            "Done, All the required modules are imported. Time elapsed: 8.763566255569458 sec\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#importing modules\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import time\n",
        "t = time.time()\n",
        "\n",
        "from IPython.display import display_html, clear_output;\n",
        "clear_output();\n",
        "\n",
        "print('Importing started...')\n",
        "\n",
        "# basic moduele\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "#from scipy import stats\n",
        "from random import randint\n",
        "import random\n",
        "import math\n",
        "import os\n",
        "import gc\n",
        "import pickle\n",
        "from glob import glob\n",
        "from IPython import display as ipd\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from joblib import dump, load\n",
        "import sklearn as sk\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from functools import partial\n",
        "import itertools\n",
        "import joblib\n",
        "from itertools import combinations\n",
        "import IPython\n",
        "import statsmodels.api as sm\n",
        "import IPython.display\n",
        "\n",
        "# visualization moduels\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib_venn import venn2_unweighted\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "import imblearn\n",
        "import scipy.stats as stats\n",
        "from scipy.special import boxcox, boxcox1p\n",
        "\n",
        "\n",
        "# Palette Setup\n",
        "colors = ['#FB5B68','#FFEB48','#2676A1','#FFBDB0',]\n",
        "colormap_0 = mpl.colors.LinearSegmentedColormap.from_list(\"\",colors)\n",
        "palette_1 = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
        "palette_2 = sns.color_palette(\"YlOrBr\", as_cmap=True)\n",
        "palette_3 = sns.light_palette(\"red\", as_cmap=True)\n",
        "palette_4 = sns.color_palette(\"viridis\", as_cmap=True)\n",
        "palette_5 = sns.color_palette(\"rocket\", as_cmap=True)\n",
        "palette_6 = sns.color_palette(\"GnBu\", as_cmap=True)\n",
        "palette_7 = sns.color_palette(\"tab20c\", as_cmap=False)\n",
        "palette_8 = sns.color_palette(\"Set2\", as_cmap=False)\n",
        "\n",
        "palette_custom = ['#fbb4ae','#b3cde3','#ccebc5','#decbe4','#fed9a6','#ffffcc','#e5d8bd','#fddaec','#f2f2f2']\n",
        "palette_9 = sns.color_palette(palette_custom, as_cmap=False)\n",
        "\n",
        "sns.set_style(\"whitegrid\",{\"grid.linestyle\":\"--\", 'grid.linewidth':0.2, 'grid.alpha':0.5})\n",
        "#sns.set_theme(style=\"ticks\", context=\"notebook\")\n",
        "sns.despine(left=True, bottom=True, top=False, right=False)\n",
        "\n",
        "mpl.rcParams['axes.spines.left'] = True\n",
        "mpl.rcParams['axes.spines.right'] = False\n",
        "mpl.rcParams['axes.spines.top'] = False\n",
        "mpl.rcParams['axes.spines.bottom'] = True\n",
        "\n",
        "# Style Import\n",
        "from colorama import Style, Fore\n",
        "red = Style.BRIGHT + Fore.RED\n",
        "blu = Style.BRIGHT + Fore.BLUE\n",
        "mgt = Style.BRIGHT + Fore.MAGENTA\n",
        "gld = Style.BRIGHT + Fore.YELLOW\n",
        "res = Style.RESET_ALL\n",
        "\n",
        "# preprocessing modules\n",
        "from sklearn.model_selection import (train_test_split,\n",
        "                                     KFold,\n",
        "                                     StratifiedKFold,\n",
        "                                     cross_val_score,\n",
        "                                     GroupKFold,\n",
        "                                     GridSearchCV,\n",
        "                                     RepeatedStratifiedKFold)\n",
        "\n",
        "from sklearn.preprocessing import (LabelEncoder,\n",
        "                                   StandardScaler,\n",
        "                                   MinMaxScaler,\n",
        "                                   OrdinalEncoder,\n",
        "                                   RobustScaler,\n",
        "                                   PowerTransformer,\n",
        "                                   OneHotEncoder,\n",
        "                                   LabelEncoder,\n",
        "                                   OrdinalEncoder,\n",
        "                                   QuantileTransformer,\n",
        "                                   PolynomialFeatures)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "\n",
        "# metrics\n",
        "from sklearn.metrics import (mean_squared_error,\n",
        "                             r2_score,\n",
        "                             mean_absolute_error,\n",
        "                             mean_absolute_percentage_error,\n",
        "                             classification_report,\n",
        "                             confusion_matrix,\n",
        "                             ConfusionMatrixDisplay,\n",
        "                             multilabel_confusion_matrix,\n",
        "                             accuracy_score,\n",
        "                             roc_auc_score,\n",
        "                             auc,\n",
        "                             roc_curve,\n",
        "                             log_loss)\n",
        "\n",
        "\n",
        "# modeling algos\n",
        "from sklearn.linear_model import (LogisticRegression,\n",
        "                                  Lasso,\n",
        "                                  ridge_regression,\n",
        "                                  LinearRegression,\n",
        "                                  Ridge,\n",
        "                                  RidgeCV,\n",
        "                                  ElasticNet,\n",
        "                                  BayesianRidge,\n",
        "                                  TweedieRegressor,\n",
        "                                  ARDRegression,\n",
        "                                  PoissonRegressor,\n",
        "                                  GammaRegressor)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "\n",
        "from sklearn.ensemble import (AdaBoostRegressor,\n",
        "                              RandomForestRegressor,\n",
        "                              RandomForestClassifier,\n",
        "                              VotingRegressor,\n",
        "                              GradientBoostingRegressor,\n",
        "                              GradientBoostingClassifier,\n",
        "                              StackingRegressor,\n",
        "                              HistGradientBoostingClassifier,\n",
        "                              ExtraTreesClassifier)\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Other Models\n",
        "#from pygam import LogisticGAM, s, te\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from lightgbm import (LGBMRegressor,\n",
        "                      LGBMClassifier,\n",
        "                      early_stopping,\n",
        "                      record_evaluation,\n",
        "                      log_evaluation)\n",
        "\n",
        "#import catboost as cat\n",
        "from catboost import CatBoost, CatBoostRegressor\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "#from catboost.utils import get_roc_curve\n",
        "\n",
        "from lightgbm import early_stopping\n",
        "# check installed version\n",
        "#import pycaret\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#from minisom import MiniSom\n",
        "\n",
        "from sklearn.base import clone ## sklearn base models for stacked ensemble model\n",
        "from sklearn.calibration import CalibratedClassifierCV, CalibrationDisplay\n",
        "\n",
        "#Interpretiability of the model\n",
        "#import shap\n",
        "#import eli5\n",
        "#from eli5.sklearn import PermutationImportance\n",
        "\n",
        "\n",
        "## miss\n",
        "from sklearn.pipeline import (make_pipeline,\n",
        "                              Pipeline)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow_addons as tfa\n",
        "from keras.utils import FeatureSpace\n",
        "import keras_nlp\n",
        "\n",
        "# Import libraries for Hypertuning\n",
        "import kerastuner as kt\n",
        "from kerastuner.tuners import RandomSearch, GridSearch, BayesianOptimization\n",
        "# Model Tuning tools:\n",
        "import optuna\n",
        "from optuna.integration import TFKerasPruningCallback\n",
        "from optuna.trial import TrialState\n",
        "from optuna.visualization import plot_intermediate_values\n",
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.visualization import plot_param_importances\n",
        "from optuna.visualization import plot_contour\n",
        "%matplotlib inline\n",
        "SEED = 1984\n",
        "N_SPLITS = 10\n",
        "\n",
        "print('Done, All the required modules are imported. Time elapsed: {} sec'.format(time.time()-t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXoRiAxUiOlO",
        "outputId": "5419c4a1-b5ae-4f6a-c9a0-bb37ed515d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHECK VERSIONS:\n",
            "sns: 0.12.2\n",
            "mpl: 3.7.1\n",
            "tensorflow: 2.15.0\n",
            "pandas: 1.5.3\n",
            "numpy: 1.23.5\n",
            "scikit-learn: 1.2.2\n",
            "statsmodels: 0.14.1\n",
            "missingno: 0.5.2\n",
            "Inbalance_Learning: 0.10.1\n",
            "XGBoost: 2.0.3\n"
          ]
        }
      ],
      "source": [
        "# Check Versions:\n",
        "print(\"CHECK VERSIONS:\")\n",
        "print(f\"sns: {sns.__version__}\")\n",
        "print(f\"mpl: {mpl.__version__}\")\n",
        "print(f\"tensorflow: {tf.__version__}\")\n",
        "print(f\"pandas: {pd.__version__}\")\n",
        "print(f\"numpy: {np.__version__}\")\n",
        "print(f\"scikit-learn: {sk.__version__}\")\n",
        "print(f\"statsmodels: {sm.__version__}\")\n",
        "print(f\"missingno: {msno.__version__}\")\n",
        "#print(f\"TF-addon: {tfa.__version__}\")\n",
        "print(f\"Inbalance_Learning: {imblearn.__version__}\")\n",
        "print(f\"XGBoost: {xgb.__version__}\")\n",
        "#print(f\"CatBoost: {cat.__version__}\")\n",
        "#print(f\"PyCaret: {pycaret.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C7dVTxMy_Mxd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "292e2a20-8f1c-4b6a-d892-d4290ab6f0f6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'random' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d0977fb48806>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mseed_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtensorflow_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpytorch_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-d0977fb48806>\u001b[0m in \u001b[0;36mseed_everything\u001b[0;34m(seed, tensorflow_init, pytorch_init)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mSeeds\u001b[0m \u001b[0mbasic\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mreproducibility\u001b[0m \u001b[0mof\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \"\"\"\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PYTHONHASHSEED\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
          ]
        }
      ],
      "source": [
        "def seed_everything(seed,\n",
        "                    tensorflow_init=True,\n",
        "                    pytorch_init=True):\n",
        "    \"\"\"\n",
        "    Seeds basic parameters for reproducibility of results\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    if tensorflow_init is True:\n",
        "        tf.random.set_seed(seed)\n",
        "    if pytorch_init is True:\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "seed_everything(42,tensorflow_init=True,pytorch_init=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AkcjLDrdBvBb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}